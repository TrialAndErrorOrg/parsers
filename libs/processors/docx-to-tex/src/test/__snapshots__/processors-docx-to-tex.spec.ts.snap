// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`parses correctly for citationparagraph 1`] = `
" \\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{Saebi2019,
    title       = {Social entrepreneurship research: Past achievements and future promises},
    author      = {Saebi, T. and Foss, N.J. and Linder, S.},
    number      = {1},
    volume      = {45},
    doi         = {10.1177/0149206318793196},
    year        = {2019},
    pages       = {70--95},
    journal     = {Journal of Management}
}


@article{Mair2010,
    title       = {Social entrepreneurship: taking stock and looking ahead},
    author      = {Mair, J.},
    publisher   = {Edward Elgar Publishing Limited},
    year        = {2010},
    pages       = {15--28},
    journal     = {Handbook of Research on Social Entrepreneurship}
}


@article{Choi2014,
    title       = {Social entrepreneurship as an essentially contested concept: Opening a new avenue for systematic future research},
    author      = {Choi, N. and Majumdar, S.},
    number      = {3},
    volume      = {29},
    doi         = {10.1016/j.jbusvent.2013.05.001},
    year        = {2014},
    pages       = {363--376},
    journal     = {Journal of Business Venturing}
}


@article{Alegre2017,
    title       = {Organized Chaos: Mapping the Definitions of Social Entrepreneurship},
    author      = {Alegre, I. and Kislenko, S. and Berbegal-Mirabent, J.},
    number      = {2},
    volume      = {8},
    doi         = {10.1080/19420676.2017.1371631},
    year        = {2017},
    pages       = {248--264},
    journal     = {Journal of Social Entrepreneurship}
}

\\\\end{filecontents}

\\\\begin{document}

  Despite the ongoing public and scholarly attention on social entrepreneurship, definitional debates seem far from settled \\\\parencite{Saebi2019}. On the one hand, some scholars argue that defining social entrepreneurship is problematic because it means different things to different people and differs between contexts \\\\parencite{Mair2010}. Hence making it a ‘fuzzy' \\\\parencite{Choi2014} or an ‘unclear and contested' concept \\\\parencite{Saebi2019}. On the other hand, others argue that a widespread consensus exists within the academic community on what defines social entrepreneurship, social entrepreneur and social enterprise \\\\parencite{Alegre2017}.



\\\\section{References}



Abebe, M. A., \\\\& Alvarado, D. (2018). Blessing in disguise? Social and institutional determinants of entrepreneurial intentions following involuntary job loss. \\\\emph{Journal of Small Business Management, 56}(4), 555-572. doi:10.1111/jsbm.12303

Achterberg, P., Raven, J., \\\\& van der Veen, R. (2013). Individualization: A double-edged sword: Welfare, the experience of social risks and the need for social insurance in the Netherlands. \\\\emph{Current Sociology, 61}(7), 949-965. doi:10.1177/0011392113499738

Acs, Z. (2006). How is entrepreneurship good for economic growth? \\\\emph{Innovations: Technology, Governance, Globalization, 1}(1), 97-107. doi:10.1162/itgg.2006.1.1.97

Agresti, A. (2018). \\\\emph{An introduction to categorical data analysis}. John Wiley \\\\& Sons.

Ajzen, I. (1991). The theory of planned behavior. \\\\emph{Organizational }\\\\emph{Behavior}\\\\emph{ and Human Decision Processes, 50}(2), 179-211. doi:10.1016/0749-5978(91)90020-T

Akerlof, G. A. (1978). The market for “lemons”: Quality uncertainty and the market mechanism. In Diamond, P., \\\\& Rothschild, M. (Eds.) \\\\emph{Uncertainty in economics }(pp. 235-251). Elsevier. doi: 0.1016/B978-0-12-214850-7.50022-X

Alegre, I., Kislenko, S., \\\\& Berbegal-Mirabent, J. (2017). Organized Chaos: Mapping the Definitions of Social Entrepreneurship. \\\\emph{Journal of Social Entrepreneurship, 8}(2), 248-264. doi:10.1080/19420676.2017.1371631

Alter, K. (2007). \\\\emph{Social enterprise typology}. Seattle: Virtue Ventures LLC. 

Álvarez, C., Urbano, D., \\\\& Amorós, J. E. (2014). GEM research: achievements and challenges. \\\\emph{Small Business Economics, 42}(3), 445-465. doi:10.1007\\\\%252Fs11187-013-9517-5

Andersson, F. O., \\\\& Ford, M. (2014). Reframing Social Entrepreneurship Impact: Productive, Unproductive and Destructive Outputs and Outcomes of the Milwaukee School Voucher Programme. \\\\emph{Journal of Social Entrepreneurship, 6}(3), 299-319. doi:10.1080/19420676.2014.981845

Arvidson, M., \\\\& Lyon, F. (2014). Social impact measurement and non-profit organisations: Compliance, resistance, and promotion. \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 25}(4), 869-886. doi:10.1007/s11266-013-9373-6

Arvidson, M., Lyon, F., McKay, S., \\\\& Moro, D. (2013). Valuing the social? The nature and controversies of measuring social return on investment (SROI). \\\\emph{Voluntary Sector Review, 4}(1), 3-18. doi:10.1332/204080513X661554

Audretsch, D. B., Boente, W., \\\\& Tamvada, J. P. (2013). Religion, social class, and entrepreneurial choice. \\\\emph{Journal of Business Venturing, 28}(6), 774-789. doi:10.1016/j.jbusvent.2013.06.002

Austin, J., Stevenson, H., \\\\& Wei-Skillern, J. (2006). Social and commercial entrepreneurship: same, different, or both? \\\\emph{Entrepreneurship Theory and Practice, 30}(1), 1-22. doi:10.1111/j.1540-6520.2006.00107.x

Bacq, S., Hartog, C., \\\\& Hoogendoorn, B. (2013). A Quantitative Comparison of Social and Commercial Entrepreneurship: Toward a More Nuanced Understanding of Social Entrepreneurship Organizations in Context. \\\\emph{Journal of Social Entrepreneurship, 4}(1), 40-68. doi:10.1080/19420676.2012.758653

Bacq, S., Hartog, C., \\\\& Hoogendoorn, B. (2016). Beyond the moral portrayal of social entrepreneurs: An empirical approach to who they are and what drives them. \\\\emph{Journal of Business Ethics, 133}(4), 703-718. doi:10.1007/s10551-014-2446-7

Bacq, S., \\\\& Janssen, F. (2011). The multiple faces of social entrepreneurship: A review of definitional issues based on geographical and thematic criteria. \\\\emph{Entrepreneurship \\\\& Regional Development, 23}(5-6), 373-403. doi:10.1080/08985626.2011.577242

Barraket, J., \\\\& Yousefpour, N. (2013). Evaluation and social impact measurement amongst small to medium social enterprises: Process, purpose and value. \\\\emph{Australian Journal of Public Administration, 72}(4), 447-458. doi:10.1111/1467-8500.12042

Barton, M., Schaefer, R., \\\\& Canavati, S. (2018). To be or not to be a social entrepreneur: Motivational drivers amongst American business students. \\\\emph{Entrepreneurial Business and Economics Review, 6}(1), 9-35. doi:10.15678/EBER.2018.060101

Batson, C. D., Ahmad, N., \\\\& Tsang, J. A. (2002). Four motives for community involvement. \\\\emph{Journal of Social Issues, 58}(3), 429-445. doi:10.1111/1540-4560.00269

Battilana, J., \\\\& Lee, M. (2014). Advancing research on hybrid organizing--Insights from the study of social enterprises. \\\\emph{The Academy of Management Annals, 8}(1), 397-441. doi:10.1080/19416520.2014.893615

Battilana, J., Sengul, M., Pache, A.-C., \\\\& Model, J. (2015). Harnessing productive tensions in hybrid organizations: The case of work integration social enterprises. \\\\emph{Academy of Management Journal, 58}(6), 1658-1685. doi:10.5465/amj.2013.0903

Baum, J. A. C., \\\\& Oliver, C. (1992). Institutional embeddedness and the dynamics of organizational populations. \\\\emph{American Sociological Review}, 540-559. doi:10.2307/2096100

Baum, J. A. C., \\\\& Powell, W. W. (1995). Cultivating an institutional ecology of organizations: Comment on Hannan, Carroll, Dundon, and Torres. \\\\emph{American Sociological Review, 60}(4), 529-538. doi:10.2307/2096292

Baum, J. A. C., \\\\& Shipilov, A. V. (2006). \\\\emph{Ecological Approaches to Organizations}. In Clegg, S. R., Hardy, C., Lawrence, T., \\\\& Nord, W. R. (Eds.). \\\\emph{The SAGE Handbook of Organization Studies}. (pp.55-110). London: SAGE Publications.

Beck, U. (1992). From industrial society to the risk society: Questions of survival, social structure and ecological enlightenment. \\\\emph{Theory, Culture \\\\& Society, 9}(1), 97-123. doi:10.1177/026327692009001006

Becker, S., Kunze, C., \\\\& Vancea, M. (2017). Community energy and social entrepreneurship: Addressing purpose, organisation and embeddedness of renewable energy projects. \\\\emph{Journal of Cleaner Production, 147}, 25-36. doi:10.1016/j.jclepro.2017.01.048

Beisland, L. A., Djan, K. O., Mersland, R., \\\\& Randøy, T. (2020). Measuring Social Performance in Social Enterprises: A Global Study of Microfinance Institutions. \\\\emph{Journal of Business Ethics}, 171, 51-71. doi:10.1007/s10551-019-04417-z

Belmi, P., \\\\& Laurin, K. (2016). Who wants to get to the top? Class and lay theories about power. \\\\emph{Journal of Personality and Social Psychology, 111}(4), 505-529. doi:10.1037/pspi0000060

Benz, M., \\\\& Frey, B. S. (2008). The value of doing what you like: Evidence from the self-employed in 23 countries. \\\\emph{Journal of Economic }\\\\emph{Behavior}\\\\emph{ \\\\& Organization, 68}(3-4), 445-455. doi:10.1016/j.jebo.2006.10.014

Blekesaune, M., \\\\& Quadagno, J. (2003). Public Attitudes toward Welfare State PoliciesA Comparative Analysis of 24 Nations. \\\\emph{European Sociological Review, 19}(5), 415-427. doi:10.1093/esr/19.5.415

Block, J., Thurik, R., Van der Zwan, P., \\\\& Walter, S. (2013). Business takeover or new venture? Individual and environmental determinants from a cross--country study. \\\\emph{Entrepreneurship Theory and Practice, 37}(5), 1099-1121. doi:10.1111/j.1540-6520.2012.00521.x

Boden Jr, R. J. (1999). Flexible working hours, family responsibilities, and female self-employment: Gender differences in self-employment selection. \\\\emph{American Journal of Economics and Sociology, 58}(1), 71-83. doi:10.1111/j.1536-7150.1999.tb03285.x

Borzaga, C., \\\\& Defourny, J. (2001). \\\\emph{Conclusions. Social enterprises in Europe: a diversity of initiatives and prospects}. In Borzaga, C., \\\\& Defourny, J. (Eds). \\\\emph{The Emergence of Social Enterprise. }(pp.350-370). London: Routledge.

Bosma, N. (2013). The Global Entrepreneurship Monitor (GEM) and its impact on entrepreneurship research. \\\\emph{Foundations and Trends in Entrepreneurship, 9}(2). doi:10.1561/0300000033

Bosma, N., \\\\& Levie, J. (2010). Global Entrepreneurship Monitor 2009 Global Report. Retrieved from https://www.gemconsortium.org/report/47107

Bosma, N., Schøtt, T., Terjesen, S. A., \\\\& Kew, P. (2016). \\\\emph{Global Entrepreneurship Monitor 2015 to 2016: Special topic report on social entrepreneurship}. Retrieved from https://www.gemconsortium.org/report/49542

Brady, D. (2009). \\\\emph{Rich democracies, poor people: How politics explain poverty}. New York: Oxford University Press.

Brady, D. (2019). Theories of the Causes of Poverty. \\\\emph{Annual Review of Sociology, 45}, 155-175. doi:10.1146/annurev-soc-073018-022550

Brieger, S. A., Bäro, A., Criaco, G., \\\\& Terjesen, S. A. (2020). Entrepreneurs' age, institutions, and social value creation goals: A multi-country study. \\\\emph{Small Business Economics}, \\\\emph{57}, 425-453. doi:10.1007/s11187-020-00317-z

Brieger, S. A., \\\\& De Clercq, D. (2019). Entrepreneurs' individual-level resources and social value creation goals: The moderating role of cultural context. \\\\emph{International Journal of Entrepreneurial }\\\\emph{Behavior}\\\\emph{ \\\\& Research, 25}(2), 193-216. doi:10.1108/IJEBR-12-2017-0503

Brieger, S. A., Terjesen, S. A., Hechavarría, D. M., \\\\& Welzel, C. (2018). Prosociality in business: A human empowerment framework. \\\\emph{Journal of Business Ethics}, \\\\emph{159}, 361-380. doi:10.1007/s10551-018-4045-5

Brown, M. T., Fukunaga, C., Umemoto, D., \\\\& Wicker, L. (1996). Annual review, 1990--1996: Social class, work, and retirement behavior. \\\\emph{Journal of Vocational }\\\\emph{Behavior}\\\\emph{, 49}(2), 159-189. doi:10.1006/jvbe.1996.0039

Bryan, M. L., \\\\& Jenkins, S. P. (2015). Multilevel modelling of country effects: A cautionary tale. \\\\emph{European Sociological Review, 32}(1), 3-22. doi:10.1093/esr/jcv059

Bryson, J. R., \\\\& Buttle, M. (2005). Enabling inclusion through alternative discursive formations: the regional development of community development loan funds in the United Kingdom. \\\\emph{The Service Industries Journal, 25}(2), 273-288. doi:10.1080/0264206042000305457

Campbell, D. A. (2010). Is constituent feedback living up to its promise? Provider perceptions of feedback practices in nonprofit human service organizations. \\\\emph{Families in Society, 91}(3), 313-320. doi:10.1606/1044-3894.4011

Campbell, D. A., \\\\& Lambright, K. T. (2016). Program performance and multiple constituency theory. \\\\emph{Nonprofit}\\\\emph{ and Voluntary Sector Quarterly, 45}(1), 150-171. doi:10.1177/0899764014564578

Campbell, D. A., Lambright, K. T., \\\\& Bronstein, L. R. (2012). In the eyes of the beholders: Feedback motivations and practices among nonprofit providers and their funders. \\\\emph{Public Performance \\\\& Management Review, 36}(1), 7-30. doi:10.2753/PMR1530-9576360101

Carman, J. G., \\\\& Fredericks, K. A. (2010). Evaluation capacity and nonprofit organizations: Is the glass half-empty or half-full? \\\\emph{American Journal of Evaluation, 31}(1), 84-104. doi:10.1177/1098214009352361

Carroll, G. R. (1985). Concentration and specialization: Dynamics of niche width in populations of organizations. \\\\emph{American Journal of Sociology, 90}(6), 1262 -1283. doi:10.1086/228210

Carter, N. M., Gartner, W. B., Shaver, K. G., \\\\& Gatewood, E. J. (2003). The career reasons of nascent entrepreneurs. \\\\emph{Journal of Business Venturing, 18}(1), 13-39. doi:10.1016/S0883-9026(02)00078-2

Castellano, R., Musella, G., \\\\& Punzo, G. (2017). Structure of the labour market and wage inequality: evidence from European countries. \\\\emph{Quality \\\\& Quantity, 51}(5), 2191-2218. doi:10.1007/s11135-016-0381-7

Castles, F. G. (2009). What welfare states do: a disaggregated expenditure approach. \\\\emph{Journal of Social Policy, 38}(1), 45-62. doi:10.1017/S0047279408002547

Certo, S. T., \\\\& Miller, T. (2008). Social entrepreneurship: Key issues and concepts. \\\\emph{Business Horizons, 51}(4), 267-271. doi:10.1016/j.bushor.2008.02.009

Chan, A., Ryan, S., \\\\& Quarter, J. (2017). Supported Social Enterprise: A Modified Social Welfare Organization. \\\\emph{Nonprofit}\\\\emph{ and Voluntary Sector Quarterly, 46}(2), 261-279. doi:10.1177/0899764016655620

Chell, E., Spence, L. J., Perrini, F., \\\\& Harris, J. D. (2014). Social Entrepreneurship and Business Ethics: Does Social Equal Ethical? \\\\emph{Journal of Business Ethics, 133}(4), 619-625. doi:10.1007/s10551-014-2439-6

Chmelik, E., Musteen, M., \\\\& Ahsan, M. (2016). Measures of performance in the context of international social ventures: An exploratory study. \\\\emph{Journal of Social Entrepreneurship, 7}(1), 74-100. doi:10.1080/19420676.2014.997781

Choi, N., \\\\& Majumdar, S. (2014). Social entrepreneurship as an essentially contested concept: Opening a new avenue for systematic future research. \\\\emph{Journal of Business Venturing, 29}(3), 363-376. doi:10.1016/j.jbusvent.2013.05.001

Christopoulos, D., \\\\& Vogl, S. (2015). The motivation of social entrepreneurs: The roles, agendas and relations of altruistic economic actors. \\\\emph{Journal of Social Entrepreneurship, 6}(1), 1-30. doi:10.1080/19420676.2014.954254

Cohen, B., \\\\& Winn, M. I. (2007). Market imperfections, opportunity and sustainable entrepreneurship. \\\\emph{Journal of Business Venturing, 22}(1), 29-49. doi:10.1016/j.jbusvent.2004.12.001

Coppedge, M., Gerring, J., Knutsen, C. H., Lindberg, S. I., Teorell, J., Altman, D., \\\\& Ziblatt, D. (2021). \\\\emph{V-Dem Country-Year Dataset v11.1}. 

Corner, P. D., \\\\& Ho, M. (2010). How opportunities develop in social entrepreneurship. \\\\emph{Entrepreneurship Theory and Practice, 34}(4), 635-659. doi:10.1111/j.1540-6520.2010.00382.x

Coskun, M. E., Monroe-White, T., \\\\& Kerlin, J. (2019). An updated quantitative analysis of Kerlin's macro-institutional social enterprise framework. \\\\emph{Social Enterprise Journal}, \\\\emph{15}(1), 111-130. doi:10.1108/SEJ-03-2018-0032

Cowling, M., \\\\& Bygrave, W. D. (2006). Entrepreneurship, Welfare Provision, and Unemployment: Relationships between Unemployment, Welfare Provisions, and Entrepreneurship in Thirty-Seven Nations Participating in the Global Entrepreneurship Monitor (GEM) 2002. \\\\emph{Comparative }\\\\emph{Labor}\\\\emph{ Law \\\\& Policy Journal, 28(4)}, 617-638. Retrieved from https://ssrn.com/abstract=1006267

Croson, D. C., \\\\& Minniti, M. (2012). Slipping the surly bonds: The value of autonomy in self-employment. \\\\emph{Journal of Economic Psychology, 33}(2), 355-365. doi:10.1016/j.joep.2011.05.001

Cutt, J., \\\\& Murray, V. (2000). \\\\emph{Accountability and effectiveness evaluation in non-profit organizations}. London: Routledge.Dacin, P., Dacin, M., \\\\& Matear, M. (2010). Social entrepreneurship: Why we don't need a new theory and how we move forward from here. \\\\emph{The Academy of Management Perspectives, 24}(3), 37-57. doi:10.5465/amp.24.3.37

Dart, R. (2004). The legitimacy of social enterprise. \\\\emph{Nonprofit}\\\\emph{ Management \\\\& Leadership, 14}(4), 411-424. doi:10.1002/nml.43

Dawson, C., Henley, A., \\\\& Latreille, P. (2014). Individual motives for choosing self-employment in the UK: Does region matter? \\\\emph{Regional Studies, 48}(5), 804-822. doi:10.1080/00343404.2012.697140

De Clercq, D., Lim, D. S., \\\\& Oh, C. H. (2013). Individual--level resources and new business activity: The contingent role of institutional context. \\\\emph{Entrepreneurship Theory and Practice, 37}(2), 303-330. doi:10.1111/j.1540-6520.2011.00470.x

Dean, T. J., Brown, R. L., \\\\& Stango, V. (2000). Environmental regulation as a barrier to the formation of small manufacturing establishments: A longitudinal examination. \\\\emph{Journal of Environmental Economics and Management, 40}(1), 56-75. doi:10.1006/jeem.1999.1105

Dees, J. G. (1998). The meaning of “social entrepreneurship”. Retrieved from https://web.stanford.edu/class/e145/2007\\\\_fall/materials/dees\\\\_SE.pdf

Dees, J. G., \\\\& Anderson, B. (2006). \\\\emph{Framing a theory of social entrepreneurship: Building on two schools of practice and thought}. In Mosher-Williams, R. (Ed). \\\\emph{Research on social entrepreneurship: Understanding and contributing to an emerging field}. \\\\emph{ARNOVA Occasional Paper Series}, \\\\emph{1}(3), 39-66. 

Defourny, J. (2001). \\\\emph{Introduction: From Third Sector to Social Enterprise}. In Borzaga, C. and Defourny, J. (Eds) \\\\emph{The Emergence of Social Enterprise}. (pp.1-28). London: Routledge.

Defourny, J., \\\\& Nyssens, M. (2008). Social enterprise in Europe: recent trends and developments. \\\\emph{Social Enterprise Journal, 4}(3), 202-228. doi:10.1108/17508610810922703

Defourny, J., \\\\& Nyssens, M. (2010a). Conceptions of Social Enterprise and Social Entrepreneurship in Europe and the United States: Convergences and Divergences. \\\\emph{Journal of Social Entrepreneurship, 1}(1), 32-53. doi:10.1080/19420670903442053

Defourny, J., \\\\& Nyssens, M. (2010b). Social enterprise in Europe: At the crossroads of market, public policies and third sector. \\\\emph{Policy and Society, 29}(3), 231-242. doi:10.1016/j.polsoc.2010.07.002

Defourny, J., \\\\& Nyssens, M. (2017). Fundamentals for an international typology of social enterprise models. \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 28}(6), 2469-2497. doi:10.1007/s11266-017-9884-7

Dentchev, N. A. (2020). Meer sociaal ondernemerschap in tijden van COVID-19. In Brengman, M. (Ed.), \\\\emph{Post viraal}\\\\emph{ naar een nieuw normaal: VUB-stemmen over de impact van corona op onze samenleving} (pp.217-223). Brussel: VUBPRESS.

Dewilde, C. (2006). Becoming poor in Belgium and Britain: the impact of demographic and labour market events. \\\\emph{Sociological Research Online, 11}(1), 87-103. doi:10.5153/sro.1206

Dickel, P., Sienknecht, M., \\\\& Hörisch, J. (2021). The early bird catches the worm: an empirical analysis of imprinting in social entrepreneurship. \\\\emph{Journal of Business Economics, 91}(2), 127-150. doi:10.1007/s11573-020-00969

Dileo, I., \\\\& Pereiro, T. G. (2019). Assessing the impact of individual and context factors on the entrepreneurial process. A cross-country multilevel approach. \\\\emph{International Entrepreneurship and Management Journal, 15}(4), 1393-1441. doi:10.1007/s11365-018-0528-1

DiMaggio, P. J., \\\\& Powell, W. W. (1983). The iron cage revisited: Institutional isomorphism and collective rationality in organizational fields. \\\\emph{American Sociological Review}, 147-160. doi:10.2307/2095101

Doherty, B., Haugh, H., \\\\& Lyon, F. (2014). Social enterprises as hybrid organizations: A review and research agenda. \\\\emph{International Journal of Management Reviews, 16}(4), 417-436. doi:10.1111/ijmr.12028

Douglas, H. (2010). Divergent orientations of social entrepreneurship organisations. In K. Hockerts, J. Mair, \\\\& J. Robinon (Eds.), \\\\emph{Values and opportunities in social entrepreneurship} (pp.71-90). New York: Palgrave Macmillan.

Dvouletý, O. (2018). Determinants of self-employment with and without employees: Empirical findings from Europe. \\\\emph{International Review of Entrepreneurship, 16}(3). 

Ebrahim, A. (2003). Accountability in practice: Mechanisms for NGOs. \\\\emph{World Development, 31}(5), 813-829. doi:10.1016/S0305-750X(03)00014-7

Ebrahim, A. (2005). Accountability myopia: Losing sight of organizational learning. \\\\emph{Nonprofit}\\\\emph{ and Voluntary Sector Quarterly, 34}(1), 56-87. doi: 10.1177/0899764004269430

Ebrahim, A., Battilana, J., \\\\& Mair, J. (2014). The governance of social enterprises: Mission drift and accountability challenges in hybrid organizations. \\\\emph{Research in Organizational }\\\\emph{Behavior}\\\\emph{, 34}, 81-100. doi:10.1016/j.riob.2014.09.001

Ebrahim, A., \\\\& Rangan, V. K. (2014). What impact? A framework for measuring the scale and scope of social performance. \\\\emph{California Management Review, 56}(3), 118-141. doi:10.1525/cmr.2014.56.3.118

Emerson, J. (2003). The blended value proposition: Integrating social and financial returns. \\\\emph{California Management Review, 45}(4), 35-51. doi:10.2307/41166187

Erdiaw-Kwasie, M. O., Alam, K., \\\\& Shahiduzzaman, M. (2017). Towards understanding stakeholder salience transition and relational approach to ‘better' corporate social responsibility: A case for a proposed model in practice. \\\\emph{Journal of Business Ethics, 144}(1), 85-101. doi:10.1007/s10551-015-2805-z

Erikson, R., \\\\& Goldthorpe, J. H. (1992). \\\\emph{The constant flux: A study of class mobility in industrial societies.} Oxford University Press.

Esping-Andersen, G. (1990a). 4 The three political economies of the welfare state. \\\\emph{International Journal of Sociology, 20}(3), 92-123. doi:10.1080/15579336.1990.11770001

Esping-Andersen, G. (1990b). The three worlds of welfare capitalism. Princeton: Princeton University Press.

Esping-Andersen, G. (1999). \\\\emph{Social foundations of }\\\\emph{postindustrial}\\\\emph{ economies.} Oxford University Press.

Estrin, S., Mickiewicz, T., \\\\& Stephan, U. (2013). Entrepreneurship, social capital, and institutions: Social and commercial entrepreneurship across nations. \\\\emph{Entrepreneurship Theory and Practice, 37}(3), 479-504. doi:10.1111/etap.12019

European Commission. (2011). \\\\emph{Flash Eurobarometer 283 (Entrepreneurship in the EU and beyond)}. \\\\emph{GESIS Data Archive, Cologne. ZA5439 Data file Version 1.0.0, }doi:10.4232/1.10210

European Commission. (2013). \\\\emph{Flash Eurobarometer 354 (Entrepreneurship in the EU and beyond)}. \\\\emph{GESIS Data Archive, Cologne. ZA5789 Data file Version 1.0.0, }doi:10.4232/1.11590

EVS. (2016). \\\\emph{European Values Study 2008: Integrated Dataset (EVS 2008). GESIS Data Archive, Cologne. ZA4800 Data file Version 4.0.0}\\\\emph{, }. 

Fagan, E. J., Jones, B. D., \\\\& Wlezien, C. (2017). Representative systems and policy punctuations. \\\\emph{Journal of European Public Policy, 24}(6), 809-831. doi:10.1080/13501763.2017.1296483

Fairlie, R. W., \\\\& Fossen, F. M. (2020). \\\\emph{Defining opportunity versus necessity entrepreneurship: two components of business creation}. Emerald Publishing Limited.

Fauchart, E., \\\\& Gruber, M. (2011). Darwinians, communitarians, and missionaries: The role of founder identity in entrepreneurship. \\\\emph{Academy of Management Journal, 54}(5), 935-957. doi:10.5465/amj.2009.0211

Fitzgerald, T., \\\\& Shepherd, D. (2018). Emerging structures for social enterprises within nonprofits: An institutional logics perspective. \\\\emph{Nonprofit}\\\\emph{ and Voluntary Sector Quarterly, 47}(3), 474-492. doi:10.1177/0899764018757024

Folmer, E., Rebmann, A. S., \\\\& Stephan, U. (2016). The welfare state and social entrepreneurship: insights from a multi-level study of European regions. \\\\emph{Frontiers of Entrepreneurship Research, 36}(15). Retrieved from https://digitalknowledge.babson.edu/fer/vol36/iss15/1

Fowler, E. A., Coffey, B. S., \\\\& Dixon-Fowler, H. R. (2017). Transforming good intentions into social impact: A case on the creation and evolution of a social enterprise. \\\\emph{Journal of Business Ethics, 159}(3), 665-678. doi:10.1007/s10551-017-3754-5

Franzen, A. (2003). Environmental attitudes in international comparison: An analysis of the ISSP surveys 1993 and 2000. \\\\emph{Social Science Quarterly, 84}(2), 297-308. doi:10.1111/1540-6237.8402005

Franzen, A., \\\\& Vogl, D. (2013). Acquiescence and the Willingness to Pay for Environmental Protection: A Comparison of the ISSP, WVS, and EVS. \\\\emph{Social Science Quarterly, 94}(3), 637-659. doi:10.1111/j.1540-6237.2012.00903.x

Freeman, R. E. (2010). \\\\emph{Strategic management: A stakeholder approach}. New York: Cambridge University Press.

Fukuyama, F. (2001). Social capital, civil society and development. \\\\emph{Third World Quarterly, 22}(1), 7-20. doi:10.1080/713701144

Gelissen, J. P., Van Oorschot, W. J., \\\\& Finsveen, E. (2012). HOW DOES THE WELFARE STATE INFLUENCE INDIVIDUALS' SOCIAL CAPITAL? Eurobarometer evidence on individuals' access to informal help. \\\\emph{European Societies, 14}(3), 416-440. doi:10.1080/14616696.2012.676660

Germak, A. J., \\\\& Robinson, J. A. (2014). Exploring the motivation of nascent social entrepreneurs. \\\\emph{Journal of Social Entrepreneurship, 5}(1), 5-21. doi:10.1080/19420676.2013.820781

Giddens, A. (1998). \\\\emph{The third way}. Cambridge: Polity Press.

Gidron, B., Kramer, R., \\\\& Salamon, L. (1992). \\\\emph{Government and the third sector in comparative perspective: Experience in modern welfare states}. San Francisco: Jossey-Bass.

Gidron, B., \\\\& Monnickendam-Givon, Y. (2017). A social welfare perspective of market-oriented social enterprises. \\\\emph{International Journal of Social Welfare, 26}(2), 127-140. doi:10.1111/ijsw.12232

Gilbert, N. (2002). \\\\emph{Transformation of the welfare state: The silent surrender of public responsibility.} Oxford University Press.

Glänzel, G., \\\\& Scheuerle, T. (2015). Social Impact Investing in Germany: Current Impediments from Investors' and Social Entrepreneurs' Perspectives. \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 27}(4), 1638-1668. doi:10.1007/s11266-015-9621-z

Goldthorpe, J. H., \\\\& McKnight, A. (2006). \\\\emph{The economic basis of social class}. Stanford University Press.

Goodin, R. E., Headey, B., Muffels, R., \\\\& Dirven, H.-J. (1999). \\\\emph{The real worlds of welfare capitalism}. Cambridge University Press.

Granovetter, M. (1985). Economic action and social structure: The problem of embeddedness. \\\\emph{American Journal of Sociology, 91}(3), 481-510. doi:10.1086/228311

Gras, D., Moss, T. W., \\\\& Lumpkin, G. T. (2014). The Use of Secondary Data in Social Entrepreneurship Research: Assessing the Field and Identifying Future Opportunities. In Short, J., Ketchen Jr., D. J., \\\\& Bergh, D. D. \\\\emph{Social Entrepreneurship and Research Methods.} (pp.49-75). Emerald Group Publishing Limited.

Greve, A., \\\\& Salaff, J. W. (2003). Social networks and entrepreneurship. \\\\emph{Entrepreneurship Theory and Practice, 28}(1), 1-22. doi:10.1111/1540-8520.00029

Greve, B. (2008). What is welfare? \\\\emph{Central European Journal of Public Policy, 2}(1), 50-73. 

Greve, B. (2018a). Future of the welfare state? In Grave, B. (Ed). \\\\emph{The Routledge Handbook of the Welfare State.} (pp.525-533). London: Routledge.

Greve, B. (2018b). What is welfare and public welfare? In Greve, B. (Ed.). \\\\emph{The Routledge Handbook of the Welfare State.} (pp.512). London: Routledge.

Grieco, C. (2015). \\\\emph{Assessing social impact of social enterprises: Does one size really fit all?} Springer.

Grieco, C. (2018). What do social entrepreneurs need to walk their talk? Understanding the attitude--behavior gap in social impact assessment practice. \\\\emph{Nonprofit}\\\\emph{ Management \\\\& Leadership, 29}(1), 105-122. doi:10.1002/nml.21310

Griffiths, M. D., Henry, C., Gundry, L. K., \\\\& Kickul, J. R. (2013). The socio-political, economic, and cultural determinants of social entrepreneurship activity. \\\\emph{Journal of Small Business and Enterprise Development, 20}(2), 341-357. doi:10.1108/14626001311326761

Grimes, M. (2010). Strategic sensemaking within funding relationships: The effects of performance measurement on organizational identity in the social sector. \\\\emph{Entrepreneurship Theory and Practice, 34}(4), 763-783. doi:10.1111/j.1540-6520.2010.00398.x

Haigh, N., Walker, J., Bacq, S., \\\\& Kickul, J. (2015). Hybrid organizations: origins, strategies, impacts, and implications. \\\\emph{California Management Review, 57}(3), 5-12. doi:10.1525/cmr.2015.57.3.5

Hannan, M. T., \\\\& Freeman, J. (1977). The population ecology of organizations. \\\\emph{American Journal of Sociology, 82}(5), 929-964. doi:10.1086/226424

Hannan, M. T., \\\\& Freeman, J. (1989). \\\\emph{Organizational ecology}. Cambridge, MA: Harvard University Press.

Hayhurst, L. M. C. (2013). The ‘Girl Effect' and martial arts: social entrepreneurship and sport, gender and development in Uganda. \\\\emph{Gender, Place \\\\& Culture, 21}(3), 297-315. doi:10.1080/0966369x.2013.802674

Hechavarría, D. M. (2016). The impact of culture on national prevalence rates of social and commercial entrepreneurship. \\\\emph{International Entrepreneurship and Management Journal, 12}(4), 1025-1052. doi:10.1007/s11365-015-0376-1

Hechavarría, D. M., Terjesen, S. A., Ingram, A. E., Renko, M., Justo, R., \\\\& Elam, A. (2017). Taking care of business: the impact of culture and gender on entrepreneurs' blended value creation goals. \\\\emph{Small Business Economics, 48}(1), 225-257. doi:10.1007/s11187-016-9747-4

Heck, R. H., Tabata, L., \\\\& Thomas, S. L. (2013). \\\\emph{Multilevel and longitudinal }\\\\emph{modeling}\\\\emph{ with IBM SPSS.} Routledge.

Heck, R. H., Thomas, S., \\\\& Tabata, L. (2013). \\\\emph{Multilevel }\\\\emph{modeling}\\\\emph{ of categorical outcomes using IBM SPSS.} Routledge.

Henley, A. (2004). Self-employment status: The role of state dependence and initial circumstances. \\\\emph{Small Business Economics, 22}(1), 67-82. doi:10.1023/B:SBEJ.0000011573.84746.04

Henrekson, M. (2005). Entrepreneurship: a weak link in the welfare state? \\\\emph{Industrial and Corporate Change, 14}(3), 437-467. doi:10.1093/icc/dth060

Henrekson, M., \\\\& Roine, J. (2006). \\\\emph{Promoting entrepreneurship in the welfare state.} In Audretsch, D. B., Grilo, I., \\\\& Thurik, R. (Eds.). \\\\emph{Handbook of Research on Entrepreneurship Policy}. (pp.64-93). Edward Elgar Publishing Limited.

Henrekson, M., \\\\& Stenkula, M. (2010). Entrepreneurship and public policy. In Acs, Z. J., \\\\& Audretsch, D. B. (Eds). \\\\emph{Handbook of Entrepreneurship Research} (pp.595-637). New York: Springer.

Hessels, J., Arampatzi, E., van der Zwan, P., \\\\& Burger, M. (2018). Life satisfaction and self-employment in different types of occupations. \\\\emph{Applied}\\\\emph{ }\\\\emph{Economics}\\\\emph{ Letters, 25}(11), 734-740. doi:10.1080/13504851.2017.1361003

Hessels, J., van Gelderen, M., \\\\& Thurik, R. (2008). Drivers of entrepreneurial aspirations at the country level: the role of start-up motivations and social security. \\\\emph{International Entrepreneurship and Management Journal, 4}(4), 401-417. doi:10.1007/s11365-008-0083-2 

Hillman, J., Axon, S., \\\\& Morrissey, J. (2018). Social enterprise as a potential niche innovation breakout for low carbon transition. \\\\emph{Energy Policy, 117}, 445-456. doi:10.1016/j.enpol.2018.03.038

Hockerts, K. (2015). How hybrid organizations turn antagonistic assets into complementarities. \\\\emph{California Management Review, 57}(3), 83-106. doi:10.1525/cmr.2015.57.3.83

Hockerts, K. (2018). The effect of experiential social entrepreneurship education on intention formation in students. \\\\emph{Journal of Social Entrepreneurship, 9}(3), 234-256. doi:10.1080/19420676.2018.1498377

Hoogendoorn, B. (2016). The Prevalence and Determinants of Social Entrepreneurship at the Macro Level. \\\\emph{Journal of Small Business Management, 54(S1)}, 278-296. doi:10.1111/jsbm.12301

Horemans, J., \\\\& Marx, I. (2017). \\\\emph{Poverty and material deprivation among the self-employed in Europe: An exploration of a relatively uncharted landscape.} Bonn: IZA - Institute of Labor Economics. Retrieved from https://ssrn.com/abstract=3041803 

Hörisch, J., Kollat, J., \\\\& Brieger, S. A. (2017). What influences environmental entrepreneurship? A multilevel analysis of the determinants of entrepreneurs' environmental orientation. \\\\emph{Small Business Economics, 48}(1), 47-69. doi:10.1007/s11187-016-9765-2

Hox, J. (2002). \\\\emph{Multilevel analysis: Techniques and applications. }Mahwah, NJ: Lawrence Erlbaum Associates Publishers.

Hox, J. (2010). \\\\emph{Multilevel analysis: Techniques and applications. }New York: Routledge.

Hughes, K. D. (2003). Pushed or pulled? Women's entry into self-employment and small business ownership. \\\\emph{Gender, Work \\\\& Organization, 10}(4), 433-454. doi:10.1111/1468-0432.00205

Hummels, G. (2018). The 18th Sustainable Development Goal: Social entrepreneurship in a global society. \\\\emph{USE Working Paper series, 18}(01). 

Huysentruyt, M., Mair, J., Le Coq, C., Rimac, T., \\\\& Stephan, U. (2016). Cross-country report: a first cross-country analysis and profiling of social enterprises prepared by the SEFORÏS research consortium. Retrieved from https://kclpure.kcl.ac.uk/portal/files/102015287/Cross\\\\_country\\\\_report\\\\_6.pdf

Ilmakunnas, P., \\\\& Kanniainen, V. (2001). Entrepreneurship, Economic Risks, and Risk Insurance in the Welfare State: Results with OECD Data 1978±93. \\\\emph{German Economic Review, 2}(3), 195-218. doi:10.1111/1468-0475.00034

Inglehart, R. (1977). \\\\emph{The silent revolution: Changing values and political styles in advanced industrial society}. Princeton, NJ: Princeton University Press.

Inglehart, R. (1981). Post-materialism in an environment of insecurity. \\\\emph{The American Political Science Review}, \\\\emph{75}(4), 880-900. doi:10.2307/1962290

Inglehart, R. (1995). Public support for environmental protection: Objective problems and subjective values in 43 societies. \\\\emph{PS: Political Science \\\\& Politics, 28}(1), 57-72. doi:10.2307/420583

Inglehart, R. (1997). \\\\emph{Modernization and }\\\\emph{postmodernization}\\\\emph{: Cultural, economic, and political change in 43 societies}. Princeton university press.

IPCC. (2021). \\\\emph{Climate Change 2021: The Physical Science Basis. }Retrieved from https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC\\\\_AR6\\\\_WGI\\\\_Full\\\\_Report.pdf

Islam, A. (2015). Entrepreneurship and the allocation of government spending under imperfect markets. \\\\emph{World Development, 70}, 108-121. doi:10.1016/j.worlddev.2015.01.002

Iversen, T. (2005). \\\\emph{Capitalism, democracy, and welfare.} Cambridge University Press.

Jack, S. L. (2005). The role, use and activation of strong and weak network ties: A qualitative analysis. \\\\emph{Journal of Management Studies, 42}(6), 1233-1259. doi:10.1111/j.1467-6486.2005.00540.x

Kautonen, T., Van Gelderen, M., \\\\& Fink, M. (2015). Robustness of the theory of planned behavior in predicting entrepreneurial intentions and actions. \\\\emph{Entrepreneurship Theory and Practice, 39}(3), 655-674. doi:10.1111/etap.12056

Kerlin, J. A. (2006). Social enterprise in the United States and Europe: Understanding and learning from the differences. \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 17}(3), 246. doi:10.1007/s11266-006-9016-2

Kerlin, J. A. (2009). \\\\emph{Social enterprise: A global comparison}. London: University Press of New England

Kerlin, J. A. (2013). Defining social enterprise across different contexts: A conceptual framework based on institutional factors. \\\\emph{Nonprofit}\\\\emph{ and Voluntary Sector Quarterly, 42}(1), 84-108. doi:10.1177/0899764011433040

Kerlin, J. A. (2017). The Macro-Institutional Social Enterprise Framework: Introduction and Theoretical Underpinnings. In Kerlin, J.A. (Ed.). \\\\emph{Shaping Social }\\\\emph{Enterprise: Understanding Institutional Context and Influence. }(pp.1-26). Emerald Publishing Limited.

Kerlin, J. A., Monroe-White, T., \\\\& Zook, S. (2016). \\\\emph{Habitats in the zoo}. In Young, D. R., Searing, E. A. M., \\\\& Brewer, C. V. (Eds.). (pp67-92). Edward Elgar Publishing.

Kibler, E., Salmivaara, V., Stenholm, P., \\\\& Terjesen, S. (2018). The evaluative legitimacy of social entrepreneurship in capitalist welfare systems. \\\\emph{Journal of World Business, 53}(6), 944-957. doi:10.1016/j.jwb.2018.08.002

Kickul, J., Gundry, L., Mitra, P., \\\\& Berçot, L. (2018). Designing with purpose: advocating innovation, impact, sustainability, and scale in social entrepreneurship education. \\\\emph{Entrepreneurship Education and Pedagogy, 1}(2), 205-221. doi:10.1177/2515127418772177

Koellinger, P., \\\\& Minniti, M. (2009). Unemployment benefits crowd out nascent entrepreneurial activity. \\\\emph{Economics letters, 103}(2), 96-98. doi:10.1016/j.econlet.2009.02.002

Kolvereid, L. (1996). Organizational employment versus self-employment: Reasons for career choice intentions. \\\\emph{Entrepreneurship Theory and Practice, 20}(3), 23-31. doi:10.1177/104225879602000302

Kolvereid, L. (2016). Preference for self-employment: Prediction of new business start-up intentions and efforts. \\\\emph{The International Journal of Entrepreneurship and Innovation, 17}(2), 100-109. doi:10.1177/1465750316648576

Korndörfer, M., Egloff, B., \\\\& Schmukle, S. C. (2015). A large scale test of the effect of social class on prosocial behavior. \\\\emph{PloS}\\\\emph{ ONE, 10}(7). doi:10.1371/journal.pone.0133193

Korpi, W., \\\\& Palme, J. (2003). New Politics and Class Politics in the Context of Austerity and Globalization: Welfare State Regress in 18 Countries, 1975--95. \\\\emph{American Political Science Review, 97}(03). doi:10.1017/s0003055403000789

Kraus, M. W., Piff, P. K., Mendoza-Denton, R., Rheinschmidt, M. L., \\\\& Keltner, D. (2012). Social class, solipsism, and contextualism: how the rich are different from the poor. \\\\emph{Psychological Review, 119}(3), 546-572. doi:10.1037/a0028756

Krueger, N., Reilly, M. D., \\\\& Carsrud, A. L. (2000). Competing models of entrepreneurial intentions. \\\\emph{Journal of Business Venturing, 15}(5-6), 411-432. doi:10.1016/S0883-9026(98)00033-0

Kulin, J., \\\\& Meuleman, B. (2015). Human values and welfare state support in Europe: An east--west divide? \\\\emph{European Sociological Review, 31}(4), 418-432. doi:10.1093/esr/jcv001

Lall, S. (2017). Measuring to improve versus measuring to prove: Understanding the adoption of social performance measurement practices in nascent social enterprises. \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 28}(6), 2633-2657. doi:10.1007/s11266-017-9898-1

Lall, S. (2019). From Legitimacy to Learning: How Impact Measurement Perceptions and Practices Evolve in Social Enterprise--Social Finance Organization Relationships. \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 30}(3), 562-577. doi:10.1007/s11266-018-00081-5

Laville, J-L., Lemaître, A., \\\\& Nyssens, M. (2006). \\\\emph{Public policies and social enterprises in Europe: the challenge of institutionalization}. In Nyssens, M. (Ed.) \\\\emph{Social Enterprise: At the crossroads of market, public policies and civil society}. (pp.272-295). London: Routledge.

Lepoutre, J., Justo, R., Terjesen, S., \\\\& Bosma, N. (2013). Designing a global standardized methodology for measuring social entrepreneurship activity: the Global Entrepreneurship Monitor social entrepreneurship study. \\\\emph{Small Business Economics, 40}(3), 693-714. doi:10.1007/s11187-011-9398-4

Liket, K., \\\\& Maas, K. (2016). Strategic philanthropy: Corporate measurement of philanthropic impacts as a requirement for a “happy marriage” of business and society. \\\\emph{Business \\\\& Society, 55}(6), 889-921. doi:10.1177/0007650314565356

Liket, K. C., \\\\& Maas, K. (2015). Nonprofit organizational effectiveness: Analysis of best practices. \\\\emph{Nonprofit}\\\\emph{ and Voluntary Sector Quarterly, 44}(2), 268-296. doi:10.1177/0899764013510064

Lindbeck, A. (1994). The welfare state and the employment problem. \\\\emph{The American Economic Review, 84}(2), 71-75. 

Lindbeck, A., \\\\& Nyberg, S. (2006). Raising children to work hard: altruism, work norms, and social insurance. \\\\emph{The Quarterly Journal of Economics, 121}(4), 1473-1503. doi:10.1093/qje/121.4.1473

Littlewood, D., \\\\& Holt, D. (2018). Social entrepreneurship in South Africa: Exploring the influence of environment. \\\\emph{Business \\\\& Society, 57}(3), 525-561. doi:10.1177/0007650315613293

Maas, C. J., \\\\& Hox, J. J. (2005). Sufficient sample sizes for multilevel modeling. \\\\emph{Methodology: European Journal of Research Methods for the }\\\\emph{Behavioral}\\\\emph{ and Social Sciences, 1}(3), 86-92. \\\\emph{doi:10.1027/1614-2241.1.3.86}

Maas, K., \\\\& Boons, F. (2010). CSR as a strategic activity: Value creation, redistribution and integration. In Louche, C., Idowu, S. O., \\\\& Filho, W. L. (Eds.). \\\\emph{Innovative CSR: From risk management to value creation. }(pp.154-172). London: Routledge. 

Maas, K., \\\\& Grieco, C. (2017). Distinguishing game changers from boastful charlatans: Which social enterprises measure their impact? \\\\emph{Journal of Social Entrepreneurship, 8}(1), 110-128. doi:10.1080/19420676.2017.1304435

Maas, K., \\\\& Liket, K. (2011). Talk the Walk: Measuring the impact of strategic philanthropy. \\\\emph{Journal of Business Ethics, 100}, 445-464. doi:10.1007/s10551-010-0690-z

Mair, J. (2010). \\\\emph{Social entrepreneurship: taking stock and looking ahead}. In Fayolle, A., \\\\& Matlay, H. (Eds.). \\\\emph{Handbook of Research on Social Entrepreneurship}. (pp.15-28). Edward Elgar Publishing Limited.

Mair, J., Battilana, J., \\\\& Cardenas, J. (2012). Organizing for society: A typology of social entrepreneuring models. \\\\emph{Journal of Business Ethics, 111}(3), 353-373. doi:10.1007/s10551-012-1414-3

Mair, J., \\\\& Marti, I. (2009). Entrepreneurship in and around institutional voids: A case study from Bangladesh. \\\\emph{Journal of Business Venturing, 24}(5), 419-435. doi:10.1016/j.jbusvent.2008.04.006

Mair, J., \\\\& Martí, I. (2006). Social entrepreneurship research: A source of explanation, prediction, and delight. \\\\emph{Journal of World Business, 41}(1), 36-44. doi:10.1016/j.jwb.2005.09.002

Mair, J., Martí, I., \\\\& Ventresca, M. J. (2012). Building inclusive markets in rural Bangladesh: How intermediaries work institutional voids. \\\\emph{Academy of Management Journal, 55}(4), 819-850. doi:10.5465/amj.2010.0627

Mair, J., \\\\& Noboa, E. (2006). \\\\emph{Social entrepreneurship: How intentions to create a social venture are formed}. In Mair, J., Robinson, J. , \\\\& Hockerts, K. (Eds.). \\\\emph{Social entrepreneurship.} (pp. 121-135). Palgrave MacMillan.

Mascini, P., Achterberg, P., \\\\& Houtman, D. (2013). Neoliberalism and work-related risks: Individual or collective responsibilization? \\\\emph{Journal of Risk Research, 16}(10), 1209-1224. doi:10.1080/13669877.2012.761274

Maslow, A. H. (1970). New introduction: Religions, values, and peak-experiences. \\\\emph{Journal of Transpersonal Psychology, 2}(2), 83-90. 

Mc Intyre, K., Lanting, P., Deelen, P., Wiersma, H. H., Vonk, J. M., Ori, A. P., . . . Boulogne, F. (2021). Lifelines COVID-19 cohort: investigating COVID-19 infection and its health and societal impacts in a Dutch population-based cohort. \\\\emph{BMJ Open, 11}(3), 1-22. doi:10.1136/bmjopen-2020-044474

McMullen, J. S. (2011). Delineating the domain of development entrepreneurship: A market--based approach to facilitating inclusive economic growth. \\\\emph{Entrepreneurship Theory and Practice, 35}(1), 185-215. doi:10.1111/j.1540-6520.2010.00428.x

Meek, W. R., Pacheco, D. F., \\\\& York, J. G. (2010). The impact of social norms on entrepreneurial action: Evidence from the environmental entrepreneurship context. \\\\emph{Journal of Business Venturing, 25}(5), 493-509. doi:10.1016/j.jbusvent.2009.09.007

Meyer, J. W., \\\\& Rowan, B. (1977). Institutionalized organizations: Formal structure as myth and ceremony. \\\\emph{American Journal of Sociology, 83}(2), 340-363. doi:10.1086/226550

Millán, J. M., Hessels, J., Thurik, R., \\\\& Aguado, R. (2013). Determinants of job satisfaction: a European comparison of self-employed and paid employees. \\\\emph{Small Business Economics, 40}(3), 651-670. doi:10.1007/s11187-011-9380-1

Monge, C. B. (2018). Identifying Cross-Country Key Drivers of Social Entrepreneurial Activity. \\\\emph{Journal of Social Entrepreneurship, 9}(3), 181-199. doi:10.1080/19420676.2018.1467333

Monroe-White, T., Kerlin, J. A., \\\\& Zook, S. (2015). A quantitative critique of Kerlin's macro-institutional social enterprise framework. \\\\emph{Social Enterprise Journal}, \\\\emph{11}(2), 178-201. doi:10.1108/SEJ-03-2015-0008

Moore, C. S., \\\\& Mueller, R. E. (2002). The transition from paid to self-employment in Canada: the importance of push factors. \\\\emph{Applied Economics, 34}(6), 791-801. doi:10.1080/00036840110058473

Moran, P. (2005). Structural vs. relational embeddedness: social capital and managerial performance. \\\\emph{Strategic Management Journal}, \\\\emph{26}(12), 1129-1151. doi: 10.1002/smj.486

Moulick, A. G., Alexiou, K., Kennedy, E. D., \\\\& Parris, D. L. (2020). A total eclipse of the heart: compensation strategies in entrepreneurial nonprofits. \\\\emph{Journal of Business Venturing, 35}(4), 105950. doi:10.1016/j.jbusvent.2019.105950

Mühlböck, M., Warmuth, J.-R., Holienka, M., \\\\& Kittel, B. (2018). Desperate entrepreneurs: no opportunities, no skills. \\\\emph{International Entrepreneurship and Management Journal, 14}(4), 975-997. doi:10.1007/s11365-017-0472-5

Muuri, A. (2010). The impact of the use of the social welfare services or social security benefits on attitudes to social welfare policies. \\\\emph{International Journal of Social Welfare, 19}(2), 182-193. doi:10.1111/j.1468-2397.2009.00641.x

Nahapiet, J., \\\\& Ghoshal, S. (1998). Social capital, intellectual capital and the organizational advantage. \\\\emph{Academy of Management Review}, \\\\emph{38}(2), 242-266. doi: 10.5465/amr.1998.533225

Newcomer, K., Baradei, L. E., \\\\& Garcia, S. (2013). Expectations and capacity of performance measurement in NGOs in the development context. \\\\emph{Public Administration and Development, 33}(1), 62-79. doi:10.1002/pad.1633

Nga, J. K. H., \\\\& Shamuganathan, G. (2010). The influence of personality traits and demographic factors on social entrepreneurship start up intentions. \\\\emph{Journal of Business Ethics, 95}(2), 259-282. doi:10.1007/s10551-009-0358-8

Nguyen, L., Szkudlarek, B., \\\\& Seymour, R. G. (2015). Social impact measurement in social enterprises: An interdependence perspective. \\\\emph{Canadian Journal of Administrative Sciences/Revue Canadienne des Sciences de }\\\\emph{l'Administration}\\\\emph{, 32}(4), 224-237. doi:10.1002/cjas.1359

Nicholls, A. (2009). ‘We do good things, don't we?': 'Blended Value Accounting' in social entrepreneurship. \\\\emph{Accounting, Organizations and Society, 34}(6-7), 755-769. doi:10.1016/j.aos.2009.04.008

Nicholls, A. (2010a). The institutionalization of social investment: The interplay of investment logics and investor rationalities. \\\\emph{Journal of Social Entrepreneurship, 1}(1), 70-100. doi:10.1080/19420671003701257

Nicholls, A. (2010b). The legitimacy of social entrepreneurship: Reflexive isomorphism in a pre--paradigmatic field. \\\\emph{Entrepreneurship Theory and Practice, 34}(4), 611-633. doi:10.1111/j.1540-6520.2010.00397.x

Nicholls, A., \\\\& Cho, A. (2006). \\\\emph{Social Entrepreneurship: The Structuration of a field}. In Nicholls, A. (Ed.). \\\\emph{Social entrepreneurship: }\\\\emph{New}\\\\emph{ paradigms of sustainable social change.} (pp.99-118). Oxford: Oxford University Press.

Nyssens, M. (2006). \\\\emph{Social enterprise: At the crossroads of market, public policies and} \\\\emph{civil} \\\\emph{society}. Routledge. 

Oesch, D. (2008). The changing shape of class voting: An individual-level analysis of party support in Britain, Germany and Switzerland. \\\\emph{European Societies, 10}(3), 329-355. doi:10.1080/14616690701846946

Ormiston, J. (2019). Blending practice worlds: Impact assessment as a transdisciplinary practice. \\\\emph{Business Ethics: A European Review, 28}(4), 423-440. doi:10.1111/beer.12230 

Ormiston, J., Charlton, K., Donald, M. S., \\\\& Seymour, R. G. (2015). Overcoming the challenges of impact investing: Insights from leading investors. \\\\emph{Journal of Social Entrepreneurship, 6}(3), 352-378. doi:10.1080/19420676.2015.1049285

Ormiston, J., \\\\& Seymour, R. (2011). Understanding value creation in social entrepreneurship: The importance of aligning mission, strategy and impact measurement. \\\\emph{Journal of Social Entrepreneurship, 2}(2), 125-150. doi:10.1080/19420676.2011.606331

Pampel, F. C. (2000). \\\\emph{Logistic regression: A primer}. Sage.

Parker, S. C. (2006). \\\\emph{Entrepreneurship, self-employment and the labour market}. In Basu, A., Casson, M., Wadeson, N., \\\\& Yeung, B. (Eds.). \\\\emph{The} \\\\emph{Oxford handbook of entrepreneurship. }(pp.435-460). Springer. 

Parker, S. C. (2009). \\\\emph{The economics of entrepreneurship}. Cambridge: Cambridge University Press.

Pathak, S., \\\\& Muralidharan, E. (2016). Informal institutions and their comparative influences on social and commercial entrepreneurship: The role of in-group collectivism and interpersonal Trust. \\\\emph{Journal of Small Business Management, 54}(S1), 168-188. doi:10.1111/jsbm.12289

Pathak, S., \\\\& Muralidharan, E. (2018). Economic inequality and social entrepreneurship. \\\\emph{Business \\\\& Society, 57}(6), 1150-1190. doi:10.1177/0007650317696069

Peredo, A. M., \\\\& McLean, M. (2006). Social entrepreneurship: A critical review of the concept. \\\\emph{Journal of World Business, 41}(1), 56-65. doi:10.1016/j.jwb.2005.10.007

Phillips, S. D., \\\\& Johnson, B. (2019). Inching to Impact: The Demand Side of Social Impact Investing. \\\\emph{Journal of Business Ethics}, \\\\emph{168}, 615-629. doi:10.1007/s10551-019-04241-5

Pierson, P. (1996). The new politics of the welfare state. \\\\emph{World Politics, 48}(2), 143-179. doi:10.1353/wp.1996.0004

Piff, P. K., Stancato, D. M., Martinez, A. G., Kraus, M. W., \\\\& Keltner, D. (2012). Class, chaos, and the construction of community. \\\\emph{Journal of Personality and Social Psychology, 103}(6), 949-962. doi:10.1037/a0029673

Priya, S. S., Cuce, E., \\\\& Sudhakar, K. (2021). A perspective of COVID 19 impact on global economy, energy and environment. \\\\emph{International Journal of Sustainable Engineering, 14}(6), 1290-1305. doi:10.1080/19397038.2021.1964634

Rahdari, A., Sepasi, S., \\\\& Moradi, M. (2016). Achieving sustainability through Schumpeterian social entrepreneurship: The role of social enterprises. \\\\emph{Journal of Cleaner Production, 137}, 347-360. doi:10.1016/j.jclepro.2016.06.159

Ramus, T., \\\\& Vaccaro, A. (2017). Stakeholders matter: How social enterprises address mission drift. \\\\emph{Journal of Business Ethics, 143}(2), 307-322. doi:10.1007/s10551-014-2353-y

Rapp, C., Shore, J., \\\\& Tosun, J. (2018). Not so risky business? How social policies shape the perceived feasibility of self-employment. \\\\emph{Journal of European Social Policy, 28}(2), 143-160. doi:10.1177/0958928717711973

Rawhouser, H., Cummings, M., \\\\& Newbert, S. L. (2019). Social impact measurement: Current approaches and future directions for social entrepreneurship research. \\\\emph{Entrepreneurship Theory and Practice, 43}(1), 82-115. doi:10.1177/1042258717727718

Reeskens, T., \\\\& van Oorschot, W. (2014). European feelings of deprivation amidst the financial crisis: Effects of welfare state effort and informal social relations. \\\\emph{Acta }\\\\emph{Sociologica}\\\\emph{, 57}(3), 191-206. doi:10.1177/0001699313504231

Rey-Martí, A., Ribeiro-Soriano, D., \\\\& Sánchez-García, J. L. (2016). Giving back to society: Job creation through social entrepreneurship. \\\\emph{Journal of Business Research, 69}(6), 2067-2072. doi:10.1016/j.jbusres.2015.12.010

Reynolds, P., Bosma, N., Autio, E., Hunt, S., De Bono, N., Servais, I., . . . Chin, N. (2005). Global entrepreneurship monitor: Data collection design and implementation 1998--2003. \\\\emph{Small Business Economics, 24}(3), 205-231. doi:10.1007/s11187-005-1980-1

Roller, E. (1995). \\\\emph{The welfare state: The equality dimension}. New York/Oxford: Oxford University Press.

Roosma, F., Gelissen, J., \\\\& Van Oorschot, W. (2013). The multidimensionality of welfare state attitudes: A European cross-national study. \\\\emph{Social Indicators Research, 113}(1), 235-255. doi:10.1007/s11205-012-0099-4

Roosma, F., \\\\& Jeene, M. (2017). The deservingness logic applied to public opinions concerning work obligations for benefit claimants. In Van Oorschot, W., Roosma, F., Meuleman, B., \\\\& Reeskens, T. (Eds.). \\\\emph{The Social Legitimacy of Targeted Welfare: Attitudes to welfare deservingness} (pp. 189 -- 206). Cheltenham: Edward Elgar Publishing.

Roosma, F., Van Oorschot, W., \\\\& Gelissen, J. (2016). The Achilles' heel of welfare state legitimacy: perceptions of overuse and underuse of social benefits in Europe. \\\\emph{Journal of European Public Policy, 23}(2), 177-196. doi:10.1080/13501763.2015.1031157

Rose, D., \\\\& Harrison, E. (2007). The European socio-economic classification: a new social class schema for comparative European research. \\\\emph{European Societies, 9}(3), 459-490. doi:10.1080/14616690701336518

Rothstein, B. (2001). Social capital in the social democratic welfare state. \\\\emph{Politics \\\\& Society, 29}(2), 207-241. doi:10.1177/0032329201029002003

Roy, M. J., Donaldson, C., Baker, R., \\\\& Kay, A. (2013). Social enterprise: new pathways to health and well-being? \\\\emph{Journal of Public Health }\\\\emph{Holicy}\\\\emph{, 34}(1), 55-68. doi:10.1057/jphp.2012.61

Saebi, T., Foss, N. J., \\\\& Linder, S. (2019). Social entrepreneurship research: Past achievements and future promises. \\\\emph{Journal of Management, 45}(1), 70-95. doi:10.1177/0149206318793196

Salamon, L. M. (2002). The tools of government. A guide to the New Governance. \\\\emph{New York: Oxford University Press}. 

Salamon, L. M., \\\\& Anheier, H. K. (1998). Social origins of civil society: Explaining the nonprofit sector cross-nationally. \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 9}(3), 213-248. 

Salamon, L. M., \\\\& Sokolowski, S. W. (2003). Institutional roots of volunteering: Toward a macro-structural theory of individual voluntary action. In Dekker, P., \\\\& Halman, L. (Eds.). \\\\emph{The values of volunteering}. (pp. 71-90). Springer.

Salamon, L. M., Sokolowski, S. W., \\\\& Anheier, H. K. (2000). Social origins of civil society: An overview. \\\\emph{Working Papers of the Johns Hopkins Comparative }\\\\emph{Nonprofit}\\\\emph{ Sector Project}, no. 38. Baltimore: The Johns Hopkins Center for Civil Society Studies.

Salamon, L. M., \\\\& Toepler, S. (2015). Government--nonprofit cooperation: Anomaly or necessity? \\\\emph{VOLUNTAS: International Journal of Voluntary and }\\\\emph{Nonprofit}\\\\emph{ Organizations, 26}(6), 2155-2177. doi:10.1007/s11266-015-9651-6

Salazar, J., Husted, B. W., \\\\& Biehl, M. (2012). Thoughts on the evaluation of corporate social performance through projects. \\\\emph{Journal of Business Ethics, 105}(2), 175-186. doi:10.1007/s10551-011-0957-z

Sandfort, J., Selden, S. C., \\\\& Sowa, J. E. (2008). Do government tools influence organizational performance? Examining their implementation in early childhood education. \\\\emph{The American Review of Public Administration, 38}(4), 412-438. doi:10.1177/0275074007310488

Santos, F. M. (2012). A positive theory of social entrepreneurship. \\\\emph{Journal of Business Ethics, 111}(3), 335-351. doi:10.1007/s10551-012-1413-4

Santos, H. C., Varnum, M. E., \\\\& Grossmann, I. (2017). Global increases in individualism. \\\\emph{Psychological Science, 28}(9), 1228-1239. doi:10.1177/0956797617700622

Sarracino, F., \\\\& Fumarco, L. (2018). Assessing the non-financial outcomes of social enterprises in Luxembourg. \\\\emph{Journal of Business Ethics}, 1-27. doi:10.1007/s10551-018-4086-9

Scherer, A. G., \\\\& Palazzo, G. (2011). The new political role of business in a globalized world: A review of a new perspective on CSR and its implications for the firm, governance, and democracy. \\\\emph{Journal of Management Studies, 48}(4), 899-931. doi:10.1111/j.1467-6486.2010.00950.x

Schjoedt, L. (2009). Entrepreneurial job characteristics: An examination of their effect on entrepreneurial satisfaction. \\\\emph{Entrepreneurship Theory and Practice, 33}(3), 619-644. doi:10.1111/j.1540-6520.2009.00319.x

Schlaegel, C., \\\\& Koenig, M. (2014). Determinants of entrepreneurial intent: A meta--analytic test and integration of competing models. \\\\emph{Entrepreneurship Theory and Practice, 38}(2), 291-332. doi:10.1111/etap.12087

Schumpeter, J. A. (1934). \\\\emph{The theory of economic development. }Cambridge, MA: Harvard University Press.

Schumpeter, J. A. (1942). \\\\emph{Capitalism, socialism and democracy}. New York Harper \\\\& Bros.

Schwab, K., \\\\& Porter, M. (2008). \\\\emph{The global competitiveness report 2008--2009} (9295044118). Retrieved from https://www3.weforum.org/docs/WEF\\\\_GlobalCompetitivenessReport\\\\_2008-09.pdf

Scott, W. R. (2005). Institutional theory: Contributing to a theoretical research program. In Smith, K. G., Hitt, M. A. (Eds.). \\\\emph{Great minds in management: The process of theory development}, (pp.460-484). Oxford: Oxford University Press. 

Scott, W. R. (2013). \\\\emph{Institutions and organizations: Ideas, interests, and identities}. London: Sage publications.

Scruggs, L., \\\\& Allan, J. (2006). Welfare-state decommodification in 18 OECD countries: a replication and revision. \\\\emph{Journal of European Social Policy, 16}(1), 55-72. doi:10.1177/0958928706059833

Seelos, C., \\\\& Mair, J. (2005). Social entrepreneurship: Creating new business models to serve the poor. \\\\emph{Business Horizons, 48}(3), 241-246. doi:10.1016/j.bushor.2004.11.006

Segal, G., Borgia, D., \\\\& Schoenfeld, J. (2005). The motivation to become an entrepreneur. \\\\emph{International Journal of Entrepreneurial }\\\\emph{Behavior}\\\\emph{ \\\\& Research}, \\\\emph{11}(1), 42-57. doi:10.1108/13552550510580834

Short, J. C., Moss, T. W., \\\\& Lumpkin, G. T. (2009). Research in social entrepreneurship: past contributions and future opportunities. \\\\emph{Strategic Entrepreneurship Journal, 3}(2), 161-194. doi:10.1002/sej.69

Smith, B. R., \\\\& Stevens, C. E. (2010). Different types of social entrepreneurship: The role of geography and embeddedness on the measurement and scaling of social value. \\\\emph{Entrepreneurship and regional development, 22}(6), 575-598. doi:10.1080/08985626.2010.488405

Snijders, T. A. B., \\\\& Bosker, R. J. (2012). \\\\emph{Multilevel analysis: An introduction to basic and advanced multilevel }\\\\emph{modeling}. Sage Publications.

Solomon, S., Bendickson, J. S., Liguori, E. W., \\\\& Marvel, M. R. (2021). The effects of social spending on entrepreneurship in developed nations. \\\\emph{Small Business Economics}, \\\\emph{58}, 1595-1607. doi:10.1007/s11187-021-00458-9

Sommet, N., \\\\& Morselli, D. (2017). Keep calm and learn multilevel logistic modeling: A simplified three-step procedure using Stata, R, Mplus, and SPSS. \\\\emph{International Review of Social Psychology, 30}(1). doi:10.5334/irsp.90

Spear, R., \\\\& Bidet, E. (2005). Social enterprise for work integration in 12 European countries: a descriptive analysis. \\\\emph{Annals of public and cooperative economics, 76}(2), 195-231. doi:10.1111/j.1370-4788.2005.00276.x

Stadelmann-Steffen, I. (2011). Social volunteering in welfare states: Where crowding out should occur. \\\\emph{Political Studies, 59}(1), 135-155. doi:10.1111/j.1467-9248.2010.00838.x

Steenbergen, M. R., \\\\& Jones, B. S. (2002). Modeling multilevel data structures. \\\\emph{American Journal of Political Science}, \\\\emph{46}(1), 218-237. doi:10.2307/3088424 

Stegmueller, D. (2013). How many countries for multilevel modeling? A comparison of frequentist and Bayesian approaches. \\\\emph{American Journal of Political Science, 57}(3), 748-761. doi:10.1111/ajps.12001

Stephan, U., \\\\& Drencheva, A. (2017). \\\\emph{The person in social entrepreneurship: A systematic review of research on the social entrepreneurial personality}. In Ahmetoglu, G., Chamorro-Premuzic, T., Klinger, B., \\\\& Karcisky, T. (Eds.). \\\\emph{The Wiley handbook of entrepreneurship}. (pp205-229). Chichester: Wiley. 

Stephan, U., \\\\& Folmer, E. (2017). Context and social enterprises: which environments enable social entrepreneurship? \\\\emph{European Policy Brief. }Retrieved from https://publications.aston.ac.uk/id/eprint/31317/1/SEFORIS\\\\_POLICY\\\\_BRIEF\\\\_WP7\\\\_context\\\\_and\\\\_social\\\\_enterprise\\\\_part\\\\_1.pdf

Stephan, U., Patterson, M., Kelly, C., \\\\& Mair, J. (2016). Organizations driving positive social change: A review and an integrative framework of change processes. \\\\emph{Journal of Management, 42}(5), 1250-1281. doi:10.1177/0149206316633268

Stephan, U., Uhlaner, L. M., \\\\& Stride, C. (2015). Institutions and social entrepreneurship: The role of institutional voids, institutional support, and institutional configurations. \\\\emph{Journal of International Business Studies, 46}(3), 308-331. doi:doi:10.1057/jibs.2014.38

Stevens, R., Moray, N., \\\\& Bruneel, J. (2014). The Social and Economic Mission of Social Enterprises: Dimensions, Measurement, Validation, and Relation. \\\\emph{Entrepreneurship Theory and Practice, 39}(5), 1-32. doi:10.1111/etap.12091

Stirzaker, R., Galloway, L., Muhonen, J., \\\\& Christopoulos, D. (2021). The drivers of social entrepreneurship: agency, context, compassion and opportunism. \\\\emph{International Journal of Entrepreneurial }\\\\emph{Behavior}\\\\emph{ \\\\& Research}. \\\\emph{27}(6), 1381-1402. doi:10.1108/IJEBR-07-2020-0461

Sud, M., VanSandt, C. V., \\\\& Baugous, A. M. (2009). Social entrepreneurship: The role of institutions. \\\\emph{Journal of Business Ethics, 85}(1), 201-216. doi:10.1007/s10551-008-9939-1

Sunley, P., \\\\& Pinch, S. (2012). Financing social enterprise: social bricolage or evolutionary entrepreneurialism? \\\\emph{Social Enterprise Journal}, \\\\emph{8}(2), 108-122. doi:10.1108/17508611211252837

Tan, L. P., Le, A. N. H., \\\\& Xuan, L. P. (2020). A systematic literature review on social entrepreneurial intention. \\\\emph{Journal of Social Entrepreneurship, 11}(3), 241-256. doi:10.1080/19420676.2019.1640770

Terjesen, S., Bosma, N., \\\\& Stam, E. (2016). Advancing public policy for high-growth, female, and social entrepreneurs. \\\\emph{Public Administration Review, 76}(2), 230-239. doi:10.1111/puar.12472

Thompson, J., Alvy, G., \\\\& Lees, A. (2000). Social entrepreneurship--a new look at the people and the potential. \\\\emph{Management decision, 38}(5), 328-338. doi:10.1108/00251740010340517

Thompson, N., Kiefer, K., \\\\& York, J. G. (2011). \\\\emph{Distinctions not dichotomies: Exploring social, sustainable, and environmental entrepreneurship}. In Lumpkin, G. T., \\\\& Katz, J. A. (Eds.). \\\\emph{Social and sustainable entrepreneurship (Advances in entrepreneurship, firm emergence and growth)}. (pp.201-229). Emerald Group Publishing Limited.

Townsend, D. M., \\\\& Hart, T. A. (2008). Perceived institutional ambiguity and the choice of organizational form in social entrepreneurial ventures. \\\\emph{Entrepreneurship Theory and Practice, 32}(4), 685-700. doi:10.1111/j.1540-6520.2008.00248.x

Uzzi, B. (1997). Social structure and competition in interfirm networks: The paradox of embeddedness. \\\\emph{Administrative}\\\\emph{ }\\\\emph{Science}\\\\emph{ }\\\\emph{Quarterly}, \\\\emph{42}(1), 35-67. doi:10.2307/2393808

Van Den Groenendaal, S. M. E., Rossetti, S., Van Den Bergh, M., Kooij, T. D., \\\\& Poell, R. F. (2021). Motivational profiles and proactive career behaviors among the solo self-employed. \\\\emph{Career}\\\\emph{ Development International, 26}(2), 309-330. doi:10.1108/CDI-06-2020-0149

Van der Wel, K. A., \\\\& Halvorsen, K. (2015). The bigger the worse? A comparative study of the welfare state and employment commitment. \\\\emph{Work, Employment and Society, 29}(1), 99-118. doi:10.1177/0950017014542499

Van Oorschot, W. (2010). Public perceptions of the economic, moral, social and migration consequences of the welfare state: An empirical analysis of welfare state legitimacy. \\\\emph{Journal of European Social Policy, 20}(1), 19-31. doi:10.1177/0958928709352538

Van Oorschot, W., \\\\& Arts, W. (2005). The social capital of European welfare states: the crowding out hypothesis revisited. \\\\emph{Journal of European Social Policy, 15}(1), 5-26. doi:10.1177/0958928705049159 

Van Oorschot, W., Arts, W., \\\\& Halman, L. (2005). Welfare state effects on social capital and informal solidarity in the European Union: evidence from the 1999/2000 European Values Study. \\\\emph{Policy \\\\& Politics, 33}(1), 33-54. doi:10.1332/0305573052708474

Van Oorschot, W., Reeskens, T., \\\\& Meuleman, B. (2012). Popular perceptions of welfare state consequences: A multilevel, cross-national analysis of 25 European countries. \\\\emph{Journal of European Social Policy, 22}(2), 181-197. doi:10.1177/0958928711433653

van Oorschot, W., Roosma, F., Meuleman, B., \\\\& Reeskens, T. (2017). \\\\emph{The social legitimacy of targeted welfare: Attitudes to welfare deservingness}: Edward Elgar Publishing.

van Rijn, M., Raab, J., Roosma, F., \\\\& Achterberg, P. (2021). To Prove and Improve: An Empirical Study on Why Social Entrepreneurs Measure Their Social Impact. \\\\emph{Journal of Social Entrepreneurship}, 1-23. doi:10.1080/19420676.2021.1975797

Verheul, I., Wennekers, S., Audretsch, D., \\\\& Thurik, R. (2002). \\\\emph{An eclectic theory of entrepreneurship: policies, institutions and culture}. In Audretsch, D., Thurik, R., Verheul, I., \\\\& Wennekers, S. (Eds.). \\\\emph{Entrepreneurship: Determinants and policy in a European-US comparison} (pp.11-81). Kluwer Academic Publishers.

Vervoort, M. (2012). Ethnic concentration in the neighbourhood and ethnic minorities' social integration: Weak and strong social ties examined. \\\\emph{Urban Studies, 49}(4), 897-915. doi:10.1177/0042098011408141

Visser, M., Gesthuizen, M., \\\\& Scheepers, P. (2018). The crowding in hypothesis revisited: new insights into the impact of social protection expenditure on informal social capital. \\\\emph{European Societies, 20}(2), 257-280. doi:10.1080/14616696.2018.1442928

Wang, Z., Jetten, J., \\\\& Steffens, N. K. (2019). The more you have, the more you want? Higher social class predicts a greater desire for wealth and status. \\\\emph{European Journal of Social Psychology, 50}(2), 360-375. doi:10.1002/ejsp.2620

Warner, R. M. (2012). \\\\emph{Applied statistics: From bivariate through multivariate techniques}. Sage Publications.

Warr, P. G. (1982). Pareto optimal redistribution and private charity. \\\\emph{Journal of Public Economics, 19}(1), 131-138. doi:10.1016/0047-2727(82)90056-1

Weerawardena, J., \\\\& Mort, G. S. (2006). Investigating social entrepreneurship: A multidimensional model. \\\\emph{Journal of World Business, 41}(1), 21-35. doi:10.1016/j.jwb.2005.09.001

Welzel, C. (2013). \\\\emph{Freedom rising: Human empowerment and the quest for emancipation}. New York, NY: Cambridge University Press.

Wendling, Z. A., Emerson, J. W., Esty, D. C., Levy, M. A., De Sherbinin, A., \\\\& Emerson, J. (2018). Environmental performance index. \\\\emph{Yale }\\\\emph{Center}\\\\emph{ for Environmental Law \\\\& Policy: New Haven, CT, USA}. 

Wennekers, S., Van Wennekers, A., Thurik, R., \\\\& Reynolds, P. (2005). Nascent entrepreneurship and the level of economic development. \\\\emph{Small Business Economics, 24}(3), 293-309. doi:10.1007/s11187-005-1994-8

Wilkinson, C., Medhurst, J., Henry, N., Wihlborg, M., \\\\& Braithwaite, B. W. (2015). \\\\emph{A map of social enterprises and their eco-systems in Europe: Synthesis Report}. Retrieved from https://ec.europa.eu/social/BlobServlet?docId=12987\\\\&langId=en

WVS. (2014). \\\\emph{World Values Survey: Round Five - Country-Pooled Datafile Version: www.worldvaluessurvey.org/WVSDocumentationWV5.jsp. Madrid: JD Systems Institute.} 

Yitshaki, R., \\\\& Kropp, F. (2016). Motivations and opportunity recognition of social entrepreneurs. \\\\emph{Journal of Small Business Management, 54}(2), 546-565. doi:10.1111/jsbm.12157

Young, D. R. (2000). Alternative models of government-nonprofit sector relations: Theoretical and international perspectives. \\\\emph{Nonprofit}\\\\emph{ and Voluntary Sector Quarterly, 29}(1), 149-172. doi:10.1177/0899764000291009

Young, D. R. (2008). \\\\emph{A unified theory of social enterprise}. In Shockley, G. E., Frank, P. M., \\\\& Stough, R. R. (Eds.). \\\\emph{Non-market entrepreneurship. }(pp.175-191). Edward Elgar Publishing Limited. 

Zahra, S., Gedajlovic, E., Neubaum, D., \\\\& Shulman, J. (2009). A typology of social entrepreneurs: Motives, search processes and ethical challenges. \\\\emph{Journal of Business Venturing, 24}(5), 519-532. doi:10.1016/j.jbusvent.2008.04.007

Zahra, S., Newey, L., \\\\& Li, Y. (2014). On the frontiers: The implications of social entrepreneurship for international entrepreneurship. \\\\emph{Entrepreneurship Theory and Practice, 38}(1), 137-158. doi:10.1111/etap.12061

Zahra, S., Rawhouser, H. N., Bhawe, N., Neubaum, D. O., \\\\& Hayton, J. C. (2008). Globalization of social entrepreneurship opportunities. \\\\emph{Strategic Entrepreneurship Journal, 2}(2), 117-131. doi:10.1002/sej.43

Zahra, S., \\\\& Wright, M. (2011). Entrepreneurship's next act. \\\\emph{The Academy of Management Perspectives, 25}(4), 67-83. doi:10.5465/amp.2010.0149





\\\\end{document}
"
`;

exports[`parses correctly for citavi 1`] = `
" \\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{Schwarz2001,
    author      = {Schwarz and Oyserman},
    year        = {2001}
}


@article{Dutcher2015,
    author      = {Dutcher},
    year        = {2015}
}


@article{Charness2018,
    author      = {Charness},
    year        = {2018}
}


@article{Andersen2018,
    author      = {Andersen},
    year        = {2018}
}


@article{Gneezy2006,
    author      = {Gneezy and List},
    year        = {2006}
}


@article{Converse1984,
    author      = {Converse},
    year        = {1984}
}


@article{Greenfield2006,
    author      = {Greenfield},
    year        = {2006}
}


@article{Schuman1979,
    author      = {Schuman and Presser},
    year        = {1979}
}


@article{Schwarz1999,
    author      = {Schwarz},
    year        = {1999}
}


@article{Christensen-Szalanski1980,
    author      = {Christensen-Szalanski},
    year        = {1980}
}


@article{Paulin2012,
    author      = {Paulin and Suneson},
    year        = {2012}
}


@article{Wang2011,
    author      = {Wang},
    year        = {2011}
}


@article{Witherspoon2013,
    author      = {Witherspoon},
    year        = {2013}
}


@article{Gwet2014,
    author      = {Gwet},
    year        = {2014}
}

\\\\end{filecontents}

\\\\begin{document}

  \\\\textbf{Real-effort survey designs: Open-ended questions to overcome the challenge of measuring behavior in surveys}



\\\\textbf{}

\\\\textbf{Keywords}

Survey design, survey experiment, real-effort design, human behavior, order effect 

\\\\textbf{}

\\\\textbf{Take-home message}

It is not possible to measure actual behavior in surveys and stated behavior is not always valid. Real-effort designs use real tasks in experiments to imitate real-world behavior and measure behavior more validly. This study combines both approaches, surveys and real-effort designs, and uses open-ended questions to measure effort in answering behavior as a proxy for actual instead of stated behavior. However, an order effect appears when this strategy is used to measure behavior in within-subject designs and, therefore, results are misleading.

\\\\textbf{}

\\\\textbf{Abstract}

Based on data triangulation, open-ended questions can be used to overcome a typical problem with data collection using surveys: Human behavior can only be captured as stated or intended but not as real behavior. In this study on knowledge sharing in the workplace, a quantitative measure of behavioral intention was accompanied by such a qualitative, open-ended measure of behavior. The latter was used as a proxy for real instead of stated behavior. This item was coded according to the effort a participant made in answering. It is assumed that the greater the effort put into answering the open-ended question, the more likely it is that the described behavior will be performed in reality. A factorial experimental design was used to analyze the effect of rewards on employees' knowledge-sharing behavior. As a within-subject design was used, participants had to answer three open-ended questions referring to different vignettes. A strong order effect appeared, leading to longer answers on average for the first vignette (baseline) compared to subsequent vignettes, independent of treatment. Therefore, this approach to operationalizing behavior in surveys might not be useful in within-subject designs. However, it can be used in between-subject comparisons when participants are asked to answer to a single vignette.

\\\\textbf{Purpose}

This study aimed at testing a more valid way to study human behavior in surveys. I tried to overcome the limited validity of self-reported behavior in surveys. I wanted to adapt experimental real-effort tasks to a survey design by using open-ended questions and analyzing the effort participants' put into answering them.

\\\\textbf{}

\\\\textbf{Real-Effort Survey Designs: Open-Ended Questions to Overcome the Challenge of Measuring Behavior in Surveys}

Measuring human behavior is an ongoing challenge for social scientists \\\\parencite{Schwarz2001}. In ideal circumstances, human behavior should be observed either in the field or in the lab. However, field trips and lab experiments are often both time- and resource-consuming. Observing behavior can also be prohibited in some cases, for instance if the behavior occurs too infrequently to be observed in a timely manner, or is not possible for others to observe (Schwarz \\\\& Oyserman, 2001, p. 128). Additionally, in the field of public administration and other fields using sensitive target groups, it is often difficult to recruit participants for a lab experiment or to even be allowed to observe them in the field. If lab experiments are conducted, they usually rely on students as participants. However, student samples are not externally valid, especially when a special population is being studied, such as public employees,. 

Therefore, self-reported behavior in surveys and survey experiments is an often-used alternative (James et al., 2017, p. 120). Surveys are “quick and cheap” (Friborg \\\\& Rosenvinge, 2013, p. 1398) and can easily reach an intended population. However, these approaches to data collection come with other disadvantages, such as not measuring real behavior. One solution could be to integrate open-ended questions as a measure of answering effort, and thus a proxy for real behavior, into quantitative surveys. This kind of method and data triangulation could help to overcome limitations of surveys related to the measurement of behavior. 

Real-effort designs assume that greater effort in fulfilling a task makes it more likely that participants actually perform what they have stated \\\\parencite{Dutcher2015}. Fulfilling real-effort tasks are typically cognitively, creatively, or physically costly for participants \\\\parencite{Charness2018}. These costs are higher when more effort is put into fulfilling a task. In some studies, for example, participants are asked to count errors in real-effort tasks, thereby increasing the cognitive cost of the task \\\\parencite{Andersen2018, Gneezy2006}. Hence, it can be assumed that the more extensive, accurate, and fitting an answer to a question about future behavior is, the more likely it is that the described behavior will actually be performed in the future. 

To test this approach to measuring behavior, a survey experiment was conducted on the effect of rewards on public employees' knowledge-sharing behavior. An open-ended measure of behavior accompanied a closed-ended question measuring behavioral intention. However, it turned out that differences in answers to the open-ended measure were determined by their order. Earlier answers were longer and more accurate, whereas subsequent answers were significantly shorter and, therefore, represented less effort. This unforeseen order effect made the qualitative data unusable for studying within-subject differences. Between-subject differences and differences between rotated questions did not suffer from this order effect. 

This paper is organized as follows. Firstly, the state of research on the use of open-ended questions in surveys and real-effort experimental designs is described. Secondly, the results of the study are presented. Problems with the approach used to measure behavior with open-ended questions are highlighted. Subsequently, these issues are discussed, and recommendations are made for future research. 

\\\\textbf{Open-Ended Questions in Quantitative Surveys as a Measure of Effort }

Combining open-ended and closed-ended questions in a survey requires a pragmatic approach of method and data triangulation (Rossman \\\\& Wilson, 1985, p. 631). Quantitative and qualitative methods not only succeed one another, but are integrated within a single study. Due to this triangulation, \\"researchers are allowed to improve the accuracy of conclusions by relying on data from more than one method\\" (Rossman \\\\& Wilson, 1985, p. 632). Hence, the combination of qualitative and quantitative data is used here to offset weaknesses of the latter, draw on the strengths of the former, and enhance the validity of the findings (Bryman, 2006, p. 105; Dewasiri et al., 2018).

Several studies use this approach and compare answers to open-ended and closed-ended questions. Most of these studies report substantial discrepancies regarding answering behavior \\\\parencite{Converse1984, Greenfield2006, Schuman1979, Schwarz1999}. For example, open-ended questions usually produce a more diverse set of answers. In a study reported by Schuman and Presser (1979), 60\\\\% of answers to an open question fell outside of the pre-coded answer categories of a related closed-ended question in the control group. Additionally, new types of responses occurred in a frequency that justified additional answer categories. In contrast, some answer options were less likely to be spontaneously produced in open-ended questions than they were to be chosen when explicitly offered as an option in closed questions (Schuman \\\\& Presser, 1979, p. 365). Similarly, in a study on the quantity of alcohol consumption, Greenfield et al. (2006) found that the answers on the quantity of consumed alcohol of around 30\\\\% of respondents differed significantly between answers on open-ended and closed questions. They found that the combination of both an open-ended and a closed measure of the quantity of alcohol consumption was a stronger predictor of alcohol-related consequences than the individual measures \\\\parencite{Greenfield2006}.

The aim of studies using open-ended and closed-ended questions in combination is usually to measure attitudes, feelings, or past behavior. However, self-reports, especially on past behavior, are a complex cognitive task that are highly context-dependent, and data are often seen as unreliable (Schwarz \\\\& Oyserman, 2001, p. 128). Some authors state that it is easier for participants to understand questions and recall relevant behavior when closed-ended questions are used (Schwarz \\\\& Oyserman, 2001, p. 131). In contrast, it is usually agreed that open-ended questions are more suited to asking about sensitive or stigmatizing information or when more in-depth information is needed (Friborg \\\\& Rosenvinge, 2013).

However, I argue that the advantages of closed-ended questions only apply to questions on past instead of future behavior, where more emphasis lies on “editing” the answer. Hence, it is more important to get an accurate answer than a correct recall of past behavior. Accordingly, Singer and Couper (2017) suggest using open-ended questions in quantitative surveys more often to “encourage more truthful answers […] [and use them] as an indicator of response quality” (p. 3).

Real-effort experimental designs rely on the assumption that greater effort in fulfilling a task makes it more likely that participants actually perform what they have stated \\\\parencite{Dutcher2015}. This assumption is based on the costs connected to fulfilling a real-effort task: The higher the costs an individual is willing to invest in answering, the more likely it is that these costs will also be invested in performing the actual behavior. Results based on real-effort designs are more externally valid when \\"the cost function of that task shares important characteristics with the field task\\" (Dutcher et al., 2015, p. 3). In surveys and survey experiments, open-ended questions can be used to measure effort in answering a question and, ultimately, we can use this as a proxy to measure real instead of stated behavior. Hence, the effort is for the most part cognitive and creative, but typing answers might also cost physical effort (Charness \\\\& Grieco, 2018, p. 75). Such a real-effort design might be a better estimator of actual behavior because \\"simply choosing a number may not capture the field environment and the psychological forces involved in putting forth actual effort\\" (Charness et al., 2018, p. 75). Greater effort can be operationalized with an extensive, accurate, and fitting answer. This is based on different assumptions: 

One dimension of effort is the \\\\emph{length of time} during which cognitive resources are used \\\\parencite{Christensen-Szalanski1980}. Accordingly, the length of a written answer is an approximator of the duration of the effort. Similarly, the length of answers to open-ended questions are often used as indicators of data quality (Galesic \\\\& Bosnjak, 2009, p. 350). 

\\\\emph{Accuracy and errors} can also be used to capture effort (Charness et al., 2018, p. 78). Such a procedure was used by Gneezy and List (2006), who conducted an experiment in which participants had to enter library data into a database. They counted the number of errors in these entries as a measure of effort. Similarly, Andersen et al. (2018) registered an experiment in public administration research using this approach to compare work effort between public and private organizations. They asked participants to transcribe handwritten timesheets and checked their accuracy. 

Furthermore, participants may not only be asked to transfer existing information into a database but also to be \\\\emph{creative}. Similarly, Charness and Grieco (2018) asked participants in an experiment to write a story about a predefined topic or by using specified words, and used this story as a measure for the real effort put forth in creative tasks. As it is difficult to rate creativity, the details provided in such an answer can be used to measure effort.

In such settings, participants' skills and abilities may strongly confound the results (Charness et al., 2018, p. 82). Longer answers, for example, may indicate that some participants can write quickly. Unfitting answers may indicate that some participants are unable to understand the question or articulate themselves. Charness et al. (2018, p. 82) recommend using larger samples to capture this treatment effect. Furthermore, within-subjects designs might be useful to overcome these between-subjects differences.

\\\\textbf{Putting a Real-Effort Survey Design into Practice: The Effect of Rewards on Knowledge-Sharing Behavior}

A survey experiment on knowledge-sharing behavior was conducted to analyze whether tangible or intangible incentives can foster that behavior. Knowledge sharing is the exchange of knowledge among individuals, teams, units, or organizations \\\\parencite{Paulin2012}. It is the basis of and a subprocess in an organization's knowledge management. In this article, the term “knowledge sharing” describes the behavior of donating knowledge from one person to another or to a medium. Multiple determinants influence knowledge sharing. Among others, tangible and intangible rewards are considered to foster knowledge-sharing behavior. Tangible rewards are material incentives, such as financial bonuses, and usually enhance extrinsic motivation. In contrast, intangible rewards, such as praise from a colleague or supervisor, usually influences intrinsic motivation. On the one hand, it has been shown that monitoring (e.g., controlling with performance measures) and rewards increase the knowledge-sharing activity of employees in an organization \\\\parencite{Wang2011, Witherspoon2013}. On the other hand, Bock and Kim's (2002) results suggest that expected rewards do not affect knowledge sharing.

A 2x3 factorial survey experiment was designed to observe the within-subjects and between-subjects effects of the rewards offered. The research design was preregistered on the Open Science Framework (Fischer, 2018). Data were collected from German public employees in the core administration and health sector (\\\\emph{N} = 623) in 2018 using a self-administered questionnaire. As can be seen from Appendix A, most participants were female (61\\\\%). The mean age was 45 years, and participants had a tenure of 20 years on average.

Each participant was randomly assigned a set of three vignettes from a pool of six. Randomization was done after participants started to answer the survey, based on their respondent ID. The vignettes incorporated all independent variables (Appendix B). Each set contained vignettes on either explicit or implicit knowledge (between-subject design). The first vignette in each set was a baseline vignette, while the two following vignettes presented a tangible and an intangible reward for knowledge sharing in a randomly assigned order (within-subjects design).

Performance appraisals were used as the \\\\emph{tangible reward }treatment (Participants were given this reminder: “You know that all shared information improves your performance appraisal”). Performance appraisals served as a proxy for later rewards because it seemed unrealistic in the public sector to offer bonuses or other tangible rewards directly based on a person's knowledge-sharing behavior. This decision should address the problem that vignette experiments are frequently criticized for being unrealistic and lacking external validity (Aguinis \\\\& Bradley, 2014, p. 361).

The \\\\emph{intangible reward} treatment was operationalized by offering explicit appreciation from co-workers without further illustrating how this appreciation would occur (Participants were given this reminder: “You know, your co-workers appreciate your knowledge sharing”). A rather superficial description was chosen because every team shows appreciation in a different way (e.g., good team climate, respectful interactions) and the vignette was thought to be not too restrictive.

\\\\emph{Knowledge-sharing behavior} (KSB) was measured with an open-ended question as a proxy for real behavior. The item reads: “If you decided to share your knowledge, please briefly describe how exactly you will share your knowledge.” Thus, participants were not asked to actually share their knowledge, but it was assumed that the cost function of answering the open-ended question on KSB was similar to the cost function of performing the described behavior in reality, for instance, when individuals share knowledge by writing an e-mail to a co-worker. 

Additionally, \\\\emph{knowledge-sharing intention} (KSI) was measured in a closed-ended way to compare results to the verbatim responses. A measure of KSI was formed by taking the mean of two items, which were rated on 5-point Likert scales. The items read: \\"I will share this knowledge with my co-workers\\" and \\"I would like to share this knowledge with my co-workers.\\" The former item represents the future-oriented and behavioral part of intention and the latter represents the motivational part of intention. Both items were based on scales on KSI used by, for example, Bock and Kim (2002) and Lin (2007). Both were adapted to the experimental context. The items correlate highly (depending on the vignette: \\\\emph{b }= .66-.96, \\\\emph{p} < .001) and were therefore compiled into one index for further analysis. 

To code the open-ended answers, three dimensions were defined preliminarily, based on the literature, to rate the quality of the answer: the description's length, accuracy, and fit with the vignette. Two dimensions were added inductively during the coding process. Firstly, some participants answered the question with few words and therefore did not score in the quantity dimension, but were considered separately from participants who did not answer because they at least put some effort into answering the question. Secondly, some participants answered very elaborately in terms of length and content, and this effort was assigned a bonus point. Each dimension was coded as a dummy variable and an additive index was formed, ranging from zero to five. 

Coding was done by two independent raters.\\\\footnote{I want to thank Lisa-Sophia Preller for serving as the second coder of this study. Both raters were asked to use different coding strategies, to avoid effects of the coding procedure: (1) one rater coded the cases one by one in order to have an eye on the complete answer, (2) another rater coded each dimension across all cases one by one in order to have an eye on the comparability of the ratings. The fifth dimension (high effort in answering) was not coded by both raters but added afterward and coded by a single rater, therefore no interrater reliability is calculated here.} Interrater reliability was calculated using Gwet's Agreement Coefficient \\\\parencite[][AC]{Gwet2014}. Due to the fact that there was only partial agreement in the ratings of some dimensions (see Appendix C), the raters discussed differences in coding and specified coding rules. In a second step, both raters agreed on a rating. This “negotiated” rating was used for further analysis.



\\\\textbf{Results and Discussion of Issues Emerging from the Open-Ended Question Approach}

Table 1 and Table 2 give a short overview of the descriptive statistics for the dependent variables. Examples of verbatim answers to the open-ended question on KSB and their coding are provided in Appendix D.

\\\\textbf{Table 1}

\\\\emph{Descriptive Statistics of KSI After Treatment}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c}

  Variable & N & M & SD & Min & Max\\\\\\\\
KSI (vig. 1) & 319 & 4.23 & .80 & 1 & 5\\\\\\\\
KSI (vig. 2) & 318 & 4.31 & .81 & 1 & 5\\\\\\\\
KSI (vig. 3) & 318 & 4.27 & .83 & 1 & 5\\\\\\\\
KSI (vig. 4) & 310 & 4.29 & .78 & 1 & 5\\\\\\\\
KSI (vig. 5) & 307 & 4.24 & .83 & 1 & 5\\\\\\\\
KSI (vig. 6) & 309 & 4.29 & .78 & 1 & 5\\\\\\\\
KSI (without treatment) & 629 & 4.26 & .79 & 1 & 5\\\\\\\\
KSI (intangible reward) & 625 & 4.27 & .82 & 1 & 5\\\\\\\\
KSI (tangible reward) & 627 & 4.28 & .80 & 1 & 5\\\\\\\\


\\\\end{tabular}


\\\\end{table}


\\\\textbf{}

\\\\textbf{Table 2}

\\\\emph{Descriptive Statistics of KSB After Treatment}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c}

  Variable & N & M & SD & Min & Max\\\\\\\\
KSB (vig. 1) & 261 & 2.75 & .91 & 1 & 5\\\\\\\\
KSB (vig. 2) & 239 & 2.36 & .70 & 1 & 5\\\\\\\\
KSB (vig. 3) & 243 & 2.47 & .77 & 1 & 5\\\\\\\\
KSB (vig. 4) & 286 & 2.66 & .86 & 1 & 5\\\\\\\\
KSB (vig. 5) & 262 & 2.40 & .68 & 1 & 5\\\\\\\\
KSB (vig. 6) & 257 & 2.46 & .71 & 1 & 5\\\\\\\\
KSB (without treatment) & 547 & 2.70 & .89 & 1 & 5\\\\\\\\
KSB (intangible reward) & 501 & 2.38 & .69 & 1 & 5\\\\\\\\
KSB (tangible reward) & 500 & 2.47 & .74 & 1 & 5\\\\\\\\


\\\\end{tabular}


\\\\end{table}


The descriptive statistics already show that when open-ended questions (knowledge-sharing \\\\emph{behavior}) were presented later in the survey, there were more missing answers, whereas such a high rate of missing answers was not observed with the closed-ended question (knowledge-sharing \\\\emph{intention}). Furthermore, in the second and third open-ended questions, participants often referred to their previous answers (e.g., \\"see above\\", \\"as just described\\") or answered in a significantly shorter way. Means for knowledge-sharing \\\\emph{behavior} were, therefore, significantly smaller in the second and third vignettes than in the first, which does not measure knowledge-sharing \\\\emph{intention}.

Data were analyzed using Wilcoxon signed-rank tests (within-analysis) and Wilcoxon rank-sum tests (between-analysis) because the data were not normally distributed. Using the closed-ended measure of knowledge-sharing \\\\emph{intention} as the dependent variable led to a slightly greater intention to share when explicit knowledge is shared and a benefit is offered (\\\\emph{M} = 4.31, \\\\emph{SD} = 0.80) than without an offered benefit (\\\\emph{M} = 4.23, \\\\emph{SD} = 0.79; \\\\emph{Z }= 3.23, \\\\emph{p} < .001, \\\\emph{d} = 0.09, bootstrapped 95\\\\% CIs [0.03, 0.16]).

However, using knowledge-sharing \\\\emph{behavior} as the dependent variable led to contradictory results, which might have been caused by a methodological problem. This issue was already identified while coding the data and inspecting the descriptive statistics: There was an order effect leading to longer answers on average for the first presented vignette compared to subsequent vignettes, independent of treatment. This result fits with the literature, as, for example, Galesic and Bosnjak (2009, p. 357) showed that open-ended questions asked later in a questionnaire were associated with shorter answers. 

Accordingly, correlations between the stated knowledge-sharing \\\\emph{intention} and the coded answers related to knowledge-sharing \\\\emph{behavior} were not pronounced (Table 3). While knowledge-sharing \\\\emph{intention} and \\\\emph{behavior} were significantly but still only moderately correlated without an incentive treatment, the correlation was weaker and insignificant when incentives were induced. As the baseline vignette was always presented as the first vignette, this result supports the assumption of an order effect. 

\\\\textbf{}

\\\\textbf{Table 3}

\\\\emph{Correlation Matrix of KSI and KSB}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c  c  c}

   & KSI &   & without treatment & KSI &  appreciation & KSI &  achievement\\\\\\\\
KSB &  without treatment & .120** &  & \\\\\\\\
KSB &  intang. reward &  & .052  & \\\\\\\\
KSB &  tang. reward &  &  & .083 \\\\\\\\


\\\\end{tabular}


\\\\end{table}
\\\\emph{Note.} \\\\emph{N} baseline = 547, \\\\emph{N} intang. Reward = 501, \\\\emph{N} tang. Reward = 500. 

*p < .05. **p < .01.

Analyzing knowledge-sharing \\\\emph{behavior} as the dependent variable, Wilcoxon signed-rank tests indicate significant differences between the treatment groups and the control group (explicit knowledge: appreciation vs. control group: \\\\emph{Z} = -5.86, \\\\emph{p} < .001; achievement vs. control group: \\\\emph{Z} = -4.40, \\\\emph{p} < .001; implicit knowledge: appreciation vs. control group:\\\\emph{ Z} = -6.83, \\\\emph{p} < .001; achievement vs. control group: \\\\emph{Z} = -4.89, \\\\emph{p} < .001). Contradicting the hypothesized relationships, the data show that knowledge-sharing \\\\emph{behavior} is significantly higher in the control group, and thus in the answer to the first vignette (baseline without treatment).

However, the comparison of the two treatments might not suffer from this methodological problem as they were presented in a randomly rotated order, thus either as the second or third vignette. Comparing the two treatments regardless of the kind of knowledge shared yields a significant difference. The tangible reward treatment (\\\\emph{M} = 2.47, \\\\emph{SD} = 0.74) triggered more knowledge-sharing behavior than the intangible reward treatment (\\\\emph{M} = 2.38, \\\\emph{SD} = 0.69; \\\\emph{Z} = 2.40, \\\\emph{p} = .017, \\\\emph{d} = 0.10, bootstrapped 95\\\\% CIs [0.02, 0.18]).

These results show that open-ended measures in surveys are exposed to strong order and fatigue effects. Open-ended questions presented later in the survey result in more missing answers, shorter answers, or answers referring to previous statements. Therefore, behavior reflecting minimal instead of satisficing answers was observed. Hence, these results could not be used in this study to analyze within-subject differences. However, the open-ended measure could be used as a proxy for real behavior in analyzing between-subjects differences and within-subjects comparisons between rotated vignettes (tangible and intangible rewards).

\\\\textbf{}

\\\\textbf{Conclusion: Recommendations for Future Research}

Using open-ended questions to measure effort as a proxy for real instead of stated behavior was not useful in a within-subjects research design. Due to an order effect, open answers could not serve as a reliable estimator of the likelihood of actual behavior. However, an advantage of verbatim answers is that they can still be used to identify behavioral patterns and modes of KSB. In further research, this strength of qualitative data should be taken into account more instead of merely quantifying qualitative data.

While this approach toward operationalizing behavior in surveys might not be useful in within-subject designs, it can be used in between-subject comparisons if participants are asked to answer to a single vignette. However, as participants' knowledge and competencies might influence answers on questions designed as real-effort tasks, attention must be paid to the sampling strategy when solely using between-subjects designs. When a baseline answer for an individual is missing or not taken into account, which is the idea behind a within-subjects design, an individual cannot be matched to their own standard.The order effect that occurred in this study was not expected by the author in that magnitude. It is known in the literature that, especially regarding open-ended questions, questions asked later in a questionnaire are associated with fatigue and shorter answers (Galesic \\\\& Bosnjak, 2009). However, it was expected that questions directly succeeding each other within a survey would not suffer that strongly from such an order effect. Additionally, the survey was rather short and took participants between 10 and 15 minutes to complete. The author expected that fatigue effects were more likely to occur in longer surveys. Also, the study's pretest with students and public sector professionals did not reveal such order and fatigue effects. Hence, this outcome might be due to characteristics of participants from online panels, who might be motivated to answer a questionnaire in an efficient and quick manner. 

Due to the state of research on order effects in surveys, the treatment vignettes were randomized. However, I decided to exclude the baseline vignette from this randomization to avoid misunderstandings among the participants and to ensure the vignettes and questions were presented in a logical order. Future studies should, however, be aware of the occurrence of order effects in such an experimental setting, especially when data are collected with a sample of merely extrinsically motivated participants. To prevent order effects, between-subjects designs could be used instead of relying on within-subjects analyses. Apart from that, a combination of open-ended and closed questions allows one to detect order effects and should be included in case of uncertainty. Using both measures together also gives the option to analyze at least a part of the dependent variable and, therefore, minimizes risks of failure based on poor research designs. 

Further research in this area may want to further consider the above-mentioned order and fatigue effects in answering open questions in survey experiments and how these might be prevented. Studies could, for example, experiment with rotating all vignettes instead of only rotating those with treatments to avoid an order effect. However, if the baseline vignette is not presented first, participants may have difficulties understanding the vignettes.

Furthermore, open-ended questions might be distributed throughout the survey instead of directly after one another in order to prevent participants from referring to earlier answers. However, questions asked in between may induce other treatments and thereby affect the answers. By reporting the failure of the research strategy used in this study, this article intends to serve as a step in further testing the possibility of using open-ended questions as valid measures of effort in surveys and survey experiments.



\\\\section{\\\\textbf{References}}

Aguinis, H., \\\\& Bradley, K. J. (2014). Best practice recommendations for designing and implementing experimental vignette methodology studies. \\\\emph{Organizational Research Methods}, \\\\emph{17}(4), 351--371. https://doi.org/10.1177/1094428114547952

Andersen, S., James, O., \\\\& Jilke, S. (2018). Does work effort for public versus private organizations differ? Evidence from an online work task experiment: Pre-registration. Retrieved from https://www.socialscienceregistry.org/trials/3361

Bock, G. W., \\\\& Kim, Y. G. (2002). Breaking the myths of rewards: An exploratory study of attitudes about knowledge sharing. \\\\emph{Information Resources Management Journal, 15}(2), 14--21.

Bryman, A. (2006). Integrating quantitative and qualitative research: How is it done? \\\\emph{Qualitative Research}, \\\\emph{6}(1), 97--113. https://doi.org/10.1177/1468794106058877

Charness, G., Gneezy, U., \\\\& Henderson, A. (2018). Experimental methods: Measuring effort in economics experiments. \\\\emph{Journal of Economic Behavior \\\\& Organization}, \\\\emph{149}, 74--87. https://doi.org/10.1016/j.jebo.2018.02.024

Charness, G., \\\\& Grieco, D. (2018). Creativity and incentives. \\\\emph{Journal of the European Economic Association}, \\\\emph{134}(1), 48. https://doi.org/10.1093/jeea/jvx055

Christensen-Szalanski, J. J. J. (1980). A further examination of the selection of problem-solving strategies: The effects of deadlines and analytic aptitudes. \\\\emph{Organizational Behavior and Human Performance}, \\\\emph{25}(1), 107--122. https://doi.org/10.1016/0030-5073(80)90028-8

Converse, J. M. (1984). Strong arguments and weak evidence: The open/closed questioning controversy of the 1940s. \\\\emph{Public Opinion Quarterly}, \\\\emph{48}(1B), 267--282. https://doi.org/10.1093/poq/48.1B.267

Dewasiri, N. J., Weerakoon, Y. K. B., \\\\& Azeez, A. A. (2018). Mixed methods in finance research. \\\\emph{International Journal of Qualitative Methods}, \\\\emph{17}(1), 160940691880173. https://doi.org/10.1177/1609406918801730

Dutcher, G., Salmon, T., \\\\& Saral, K. J. (2015). Is 'real' effort more real? \\\\emph{SSRN Electronic Journal. }Advance online publication. https://doi.org/10.2139/ssrn.2701793

Fischer, C. (2018). Fostering Knowledge Sharing Behavior: preregistration. https://osf.io/r5jws/

Friborg, O., \\\\& Rosenvinge, J. H. (2013). A comparison of open-ended and closed questions in the prediction of mental health. \\\\emph{Quality \\\\& Quantity}, \\\\emph{47}(3), 1397--1411. https://doi.org/10.1007/s11135-011-9597-8

Galesic, M., \\\\& Bosnjak, M. (2009). Effects of questionnaire length on participation and indicators of response quality in a web survey. \\\\emph{Public Opinion Quarterly}, \\\\emph{73}(2), 349--360. https://doi.org/10.1093/poq/nfp031

Gneezy, U., \\\\& List, J. A. (2006). Putting behavioral economics to work: Testing for gift exchange in labor markets using field experiments. \\\\emph{Econometrica}, \\\\emph{74}(5), 1365--1384. https://doi.org/10.1111/j.1468-0262.2006.00707.x

Greenfield, T. K., Nayak, M. B., Bond, J., Ye, Y., \\\\& Midanik, L. T. (2006). Maximum quantity consumed and alcohol-related problems: Assessing the most alcohol drunk with two measures. \\\\emph{Alcoholism, Clinical and Experimental Research}, \\\\emph{30}(9), 1576--1582. https://doi.org/10.1111/j.1530-0277.2006.00189.x

Gwet, K. L. [Kilem Li]. (2014). \\\\emph{Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters} (4th ed.). Advanced Analytics, LLC. 

James, O., Jilke, S. R., \\\\& van Ryzin, G. G. (Eds.). (2017). \\\\emph{Experiments in public management research: Challenges and contributions}. Cambridge University Press. 

Lin, H. F. 2007. ‘Effects of extrinsic and intrinsic motivation on employee knowledge sharing intentions', Journal of Information Science, 33 (2), 135--49.Paulin, D., \\\\& Suneson, K. (2012). Knowledge transfer, knowledge sharing and knowledge barriers--three blurry terms in KM. \\\\emph{The Electronic Journal of Knowledge Management}, \\\\emph{10}(1), 81--91.

Rossman, G. B., \\\\& Wilson, B. L. (1985). Numbers and words. \\\\emph{Evaluation Review}, \\\\emph{9}(5), 627--643. https://doi.org/10.1177/0193841X8500900505

Schuman, H., \\\\& Presser, S. (1979). The open and closed question. \\\\emph{American Sociological Review}, \\\\emph{44}(5), 692. https://doi.org/10.2307/2094521

Schwarz, N. (1999). Self-reports: How the questions shape the answers. \\\\emph{American Psychologist}, \\\\emph{54}(2), 93--105. https://doi.org/10.1037/0003-066X.54.2.93

Schwarz, N., \\\\& Oyserman, D. (2001). Asking questions about behavior: Cognition, communication, and questionnaire construction. \\\\emph{The American Journal of Evaluation}, \\\\emph{22}(2), 127--160. https://doi.org/10.1016/S1098-2140(01)00133-3

Singer, E., \\\\& Couper, M. P. (2017). Some methodological uses of responses to open questions and other verbatim comments in quantitative surveys. \\\\emph{Methods, Data, Analyses}, \\\\emph{11}(2), 1--19. https://doi.org/10.12758/mda.2017.01

Wang, S., Noe, R. A., \\\\& Wang, Z. M. (2011). Motivating knowledge sharing in knowledge management systems. \\\\emph{Journal of Management}, \\\\emph{40}(4), 978--1009. https://doi.org/10.1177/0149206311412192

Witherspoon, C. L., Bergner, J., Cockrell, C., \\\\& Stone, D. N. (2013). Antecedents of organizational knowledge sharing: A meta-analysis and critique. \\\\emph{Journal of Knowledge Management}, \\\\emph{17}(2), 250--277. https://doi.org/10.1108/13673271311315204



\\\\textbf{}

\\\\textbf{}

\\\\textbf{Appendix A}

\\\\emph{Sample Description}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c}

  Variable & N & M & SD & Min & Max\\\\\\\\
age & 609 & 45.10 & 10.29 & 22 & 80\\\\\\\\
female & 618 & 0.61 & 0.49 & 0 & 1\\\\\\\\
supervisor & 615 & 0.29 & 0.45 & 0 & 1\\\\\\\\
tenure & 615 & 20.20 & 11.23 & 0 & 47\\\\\\\\
fixed-term employm. & 613 & 0.05 & 0.23 & 0 & 1\\\\\\\\


\\\\end{tabular}


\\\\end{table}
\\\\textbf{}

\\\\textbf{}

\\\\textbf{Appendix B}

\\\\textbf{Vignette Plan}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c}

   & Explicit knowledge  & Implicit knowledge \\\\\\\\
Without treatment & Vignette 1 &   & During a daily routine at your workplace, you gathered  & information &  from several sources. This could also improve the work of your co-workers. &  & Please decide whether you will share this information with your co-workers. & ( & N &  = 319) & Vignette 4 &   & During a daily routine at your workplace, you had an  & experience &  that improved your work process. This experience could also help your co-workers. &  & Please decide whether you will share your knowledge with your co-workers.  & ( & N &  = 310)\\\\\\\\
Intangible reward & Vignette 2 &   & During a daily routine at your workplace, you gathered  & information &  from several sources. This could also improve the work of your co-workers. &  & You know that your co-workers appreciate your knowledge sharing. &  & Please decide whether you will share this information with your co-workers. & ( & N &  = 319) & Vignette 5 &   & During a daily routine at your workplace, you had an  & experience &  that improved your work process. This experience could also help your co-workers. &  & You know that your co-workers appreciate your knowledge sharing. &  & Please decide whether you will share your knowledge with your co-workers. & ( & N &  = 307)\\\\\\\\
Tangible reward & Vignette 3 & During a daily routine at your workplace, you gathered  & information &  from several sources. This could also improve the work of your co-workers. &  & You know that all shared information improves your performance appraisal. &  & Please decide whether you will share this information with your co-workers. & ( & N &  = 317) & Vignette 6 &   & During a daily routine at your workplace, you had an  & experience &  that improved your work process. This experience could also help your co-workers. &  & You know that all shared information improves your performance appraisal. &  & Please decide whether you will share your knowledge with your co-workers.  & ( & N &  = 309)\\\\\\\\


\\\\end{tabular}


\\\\end{table}
\\\\textbf{Appendix C}

\\\\emph{Initial Interrater Reliability Open Answers on Knowledge-Sharing Behavior (KSB)}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c  c}

    &  Vignette order &   & Gwet's AC & Cohen's Kappa & Extent of Agreement\\\\\\\\
Vignette 1 & First vignette (v28) & answer provided & .9856*** & .7430*** & substantial\\\\\\\\
 &  & quantity of the answer & .4674*** & .4586*** & moderate\\\\\\\\
 &  & accuracy of the answer & .7522*** & .6225*** & moderate\\\\\\\\
 &  & fit with vignette & .9090*** & .5805*** & moderate\\\\\\\\
Vignette 1 & First vignette (v34) & answer provided & 1.0000*** & 1.0000*** & perfect\\\\\\\\
 &  & quantity of the answer & .4943*** & .3995*** & fair\\\\\\\\
 &  & accuracy of the answer & .8426*** & .6480*** & substantial\\\\\\\\
 &  & fit with vignette & .8726*** & .5010*** & perfect\\\\\\\\
Vignette 2 & Second vignette & (v30) & answer provided & .9753*** & .8308*** & perfect\\\\\\\\
 &  & quantity of the answer & .5041*** & .3075*** & fair\\\\\\\\
 &  & accuracy of the answer & .7646*** & .3530*** & substantial\\\\\\\\
 &  & fit with vignette & .9170*** & .7075*** & perfect\\\\\\\\
Vignette 2 & Third vignette (v38) & answer provided & .9918*** & .9332*** & perfect\\\\\\\\
 &  & quantity of the answer & .7475*** & .4645*** & substantial\\\\\\\\
 &  & accuracy of the answer & .9087*** & .3802* & perfect\\\\\\\\
 &  & fit with vignette & .7888*** &  .4652*** & substantial\\\\\\\\
Vignette 3 & Third vignette (v32) & answer provided & .9642*** & .8022*** & perfect\\\\\\\\
 &  & quantity of the answer & .5584*** & .3438*** & moderate\\\\\\\\
 &  & accuracy of the answer & .7813*** & .4196*** & substantial\\\\\\\\
 &  & fit with vignette & .8627*** & .6546*** & substantial\\\\\\\\
Vignette 3 & Second vignette (v36) & answer provided & 1.0000 *** & 1.0000 *** & perfect\\\\\\\\
 &  & quantity of the answer & .5302*** & .2667*** & moderate\\\\\\\\
 &  & accuracy of the answer & .7887*** & .3119** & substantial\\\\\\\\
 &  & fit with vignette & .8417*** & .5005*** & substantial\\\\\\\\
Vignette 4 & First vignette (v16) & answer provided & 1.0000*** & 1.0000 *** & perfect\\\\\\\\
 &  & quantity of the answer & .6097*** & .5835*** & moderate\\\\\\\\
 &  & accuracy of the answer & .7829*** & .6836*** & substantial\\\\\\\\
 &  & fit with vignette & .9360*** & .6932*** & perfect\\\\\\\\
Vignette 4 & First vignette (v22) & answer provided & 1.0000*** & 1.0000*** & perfect\\\\\\\\
 &  & quantity of the answer & .5520*** & .5479*** & moderate\\\\\\\\
 &  & accuracy of the answer & .7015*** & .5903*** & moderate\\\\\\\\
 &  & fit with vignette & .9149*** & .6533*** & perfect\\\\\\\\
Vignette 5 & Second vignette v18 & answer provided & .9830*** & .7921*** & perfect\\\\\\\\
 &  & quantity of the answer & .6968*** & .5625*** & moderate\\\\\\\\
 &  & accuracy of the answer & .7793*** & .4512*** & substantial\\\\\\\\
 &  & fit with vignette & .8637*** & .5912*** & substantial\\\\\\\\
Vignette 5 & Third vignette v26 & answer provided & .9727*** & .7570*** & perfect\\\\\\\\
 &  & quantity of the answer & .6613*** & .4585*** & moderate\\\\\\\\
 &  & accuracy of the answer & .8328*** & .3934** & substantial\\\\\\\\
 &  & fit with vignette & .8888*** & .6908*** & perfect\\\\\\\\
Vignette 6 & Third vignette v20 & answer provided & 1.0000*** & 1.0000*** & perfect\\\\\\\\
 &  & quantity of the answer & .6357*** & .5394*** & moderate\\\\\\\\
 &  & accuracy of the answer & .5394*** & .5487*** & substantial\\\\\\\\
 &  & fit with vignette & .8653*** & .6624*** & substantial\\\\\\\\
Vignette 6 & Second vignette v24 & answer provided & 1.0000*** & 1.0000*** & perfect\\\\\\\\
 &  & quantity of the answer & .6873*** & .5738*** & moderate\\\\\\\\
 &  & accuracy of the answer & .7614*** & .4624*** & substantial\\\\\\\\
 &  & fit with vignette & .9132*** & .6010*** & perfect\\\\\\\\


\\\\end{tabular}


\\\\end{table}
***p < 0.001, **p < 0.01, *p < 0.05 





\\\\textbf{}

\\\\textbf{Appendix D}

\\\\textbf{Selected Open Answers on Knowledge-Sharing Behavior (KSB)}

Note: Own translation of German answers

\\\\emph{Core public administration}

\\\\textbf{KSB-Index = 1 (does not fit the question)}

Everybody benefits from it.

In my job, information and collegiality are the foundations of our conduct. It wouldn't work any other way. 

It pushes the team forward.

\\\\textbf{KSB-Index = 2}

In a one-on-one conversation

Very precise 

1: jour fixe 2: mailing list 

\\\\textbf{KSB-Index = 3}

New information is transferred personally. 

A written report or e-mail

Via e-mail or during coffee break time

\\\\textbf{KSB-Index = 4}

A group e-mail addressed to the department to inform about the outcome of the issue.

Orally in conversation, and in some circumstances by looking at the file. 

I announce this experience within the team, so everyone can decide for himself or herself whether they can or want to use this information.

\\\\textbf{KSB-Index = 5}

If it is something very interesting in my point of view, I would forward an e-mail with the necessary documents to my colleagues. If it is an issue under the category “…just so you have heard about it…”, I would seek direct talks and elaborate on the case.

An electronic submission such as an appendix via e-mail, or a written submission such as copies distributed or an offer to approach me if required, depending on relevance.

I prepare to address the issue in the next meeting and to share the new information with my co-workers. 

\\\\emph{Health sector}

\\\\textbf{KSB-Index = 1 (does not fit the question)}

Leads to shorter working hours

Because the simplification of work is good

Improvement within the team 

\\\\textbf{KSB-Index = 2}

In a team meeting

In conversations 

By demonstration 

\\\\textbf{KSB-Index = 3}

Not sure, it depends on the co-workers and their mood.

I show them my approach. 

I address it briefly within the team and wait to see if somebody is interested. 

\\\\textbf{KSB-Index = 4}

In a conversation/ team meeting I make suggestions to restructure work processes and ask for opinions of others, after which the team has to decide.

I would post it in our company network or speak about it in a team meeting. 

I gather co-workers, who work in a similar task field, and tell them about my experiences. 

\\\\textbf{KSB-Index = 5}

I will share this experience in personal conversion and will passionately talk about my findings. Hopefully, they will keep thi\\\\textbf{s }knowledge in mind when they are doing their job. 

I would share this with my co-workers in the first situation possible and not wait for the next team meeting. I always get excited when I discover something new that simplifies my work and I want to share this joy with others instantly. 

I inform my manager and ask for permission to change something actively. When it comes to random things, which don't require official procedure instructions, I would train the new co-workers directly, which is the better way of doing things.









\\\\end{document}
"
`;

exports[`parses correctly for complete 1`] = `
" \\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{Breivik2006,
    title       = {Survey of chronic pain in Europe: Prevalence, impact on daily life, and treatment.},
    author      = {Breivik, Harald and Collett, Beverly and Ventafridda, Vittorio and Cohen, Rob and Gallacher, Derek},
    number      = {4},
    volume      = {10},
    doi         = {10.1016/j.ejpain.2005.06.009},
    place       = {England},
    year        = {2006-05},
    pages       = {287-333},
    journal     = {European journal of pain (London, England)}
}


@article{Tsang2008,
    title       = {Common chronic pain conditions in developed and developing countries: Gender and age differences and comorbidity with depression-anxiety disorders.},
    author      = {Tsang, Adley and Von Korff, Michael and Lee, Sing and Alonso, Jordi and Karam, Elie and Angermeyer, Matthias C and Borges, Guilherme Luiz Guimaraes and Bromet, Evelyn J and Demytteneare, K and de Girolamo, Giovanni and de Graaf, Ron and Gureje, Oye and Lepine, Jean-Pierre and Haro, Josep Maria and Levinson, Daphna and Oakley Browne, Mark A and Posada-Villa, Jose and Seedat, Soraya and Watanabe, Makoto},
    number      = {10},
    volume      = {9},
    doi         = {10.1016/j.jpain.2008.05.005},
    place       = {United States},
    year        = {2008-10},
    pages       = {883-891},
    journal     = {The Journal of Pain}
}


@article{Costa2009,
    title       = {Prognosis for patients with chronic low back pain: Inception cohort study},
    author      = {Costa, Luciola da C Menezes and Maher, Christopher G and McAuley, James H and Hancock, Mark J and Herbert, Robert D and Refshauge, Kathryn M and Henschke, Nicholas},
    volume      = {339},
    doi         = {10.1136/bmj.b3829},
    year        = {2009-10-06},
    pages       = {b3829},
    journal     = {BMJ}
}


@article{Foster2018,
    title       = {Prevention and treatment of low back pain: Evidence, challenges, and promising directions},
    author      = {Foster, Nadine E and Anema, Johannes R and Cherkin, Dan and Chou, Roger and Cohen, Steven P and Gross, Douglas P and Ferreira, Paulo H and Fritz, Julie M and Koes, Bart W and Peul, Wilco and Turner, Judith A and Maher, Chris G and Buchbinder, Rachelle and Hartvigsen, Jan and Cherkin, Dan and Foster, Nadine E and Maher, Chris G and Underwood, Martin and van Tulder, Maurits and Anema, Johannes R and Chou, Roger and Cohen, Stephen P and Menezes Costa, Lucíola and Croft, Peter and Ferreira, Manuela and Ferreira, Paulo H and Fritz, Julie M and Genevay, Stéphane and Gross, Douglas P and Hancock, Mark J and Hoy, Damian and Karppinen, Jaro and Koes, Bart W and Kongsted, Alice and Louw, Quinette and Öberg, Birgitta and Peul, Wilco C and Pransky, Glenn and Schoene, Mark and Sieper, Joachim and Smeets, Rob J and Turner, Judith A and Woolf, Anthony},
    number      = {10137},
    volume      = {391},
    doi         = {10.1016/S0140-6736(18)30489-6},
    publisher   = {Elsevier},
    year        = {2018-06-09},
    pages       = {2368-2383},
    journal     = {The Lancet}
}


@article{Treede2019,
    title       = {Chronic pain as a symptom or a disease: The IASP classification of chronic pain for the International Classification of Diseases (ICD-11)},
    author      = {Treede, Rolf Detlef and Rief, Winfried and Barke, Antonia and Aziz, Qasim and Bennett, Michael I. and Benoliel, Rafael and Cohen, Milton and Evers, Stefan and Finnerup, Nanna B. and First, Michael B. and Giamberardino, Maria Adele and Kaasa, Stein and Korwisi, Beatrice and Kosek, Eva and Lavand'Homme, Patricia and Nicholas, Michael and Perrot, Serge and Scholz, Joachim and Schug, Stephan and Smith, Blair H. and Svensson, Peter and Vlaeyen, Johan W.S. and Wang, Shuu Jiun},
    number      = {1},
    volume      = {160},
    doi         = {10.1097/j.pain.0000000000001384},
    year        = {2019},
    pages       = {19-27},
    journal     = {Pain}
}


@article{Woolf1983,
    title       = {Evidence for a central component of post-injury pain hypersensitivity},
    author      = {Woolf, Clifford J},
    number      = {5944},
    volume      = {306},
    doi         = {10.1038/306686a0},
    place       = {England},
    year        = {1983-12},
    pages       = {686-688},
    journal     = {Nature}
}


@article{Woolf2011,
    title       = {Central sensitization: Implications for the diagnosis and treatment of pain},
    author      = {Woolf, Clifford J},
    number      = {3 Suppl},
    volume      = {152},
    doi         = {10.1016/j.pain.2010.09.030},
    year        = {2011-03},
    pages       = {S2-S15},
    journal     = {Pain}
}


@article{Vlaeyen2000,
    title       = {Fear-avoidance and its consequences in chronic musculoskeletal pain: A state of the art},
    author      = {Vlaeyen, Johan W.S. and Linton, Steven J.},
    number      = {3},
    volume      = {85},
    doi         = {10.1016/s0304-3959(99)00242-0},
    place       = {United States},
    year        = {2000-04},
    pages       = {317-332},
    journal     = {Pain}
}


@article{Vlaeyen2012,
    title       = {Fear-avoidance model of chronic musculoskeletal pain: 12 years on},
    author      = {Vlaeyen, Johan W S and Linton, Steven J},
    number      = {6},
    volume      = {153},
    doi         = {10.1016/j.pain.2011.12.009},
    place       = {United States},
    year        = {2012-06},
    pages       = {1144-1147},
    journal     = {Pain}
}


@article{Moseley2015,
    title       = {Beyond nociception: The imprecision hypothesis of chronic pain},
    author      = {Moseley, G Lorimer and Vlaeyen, Johan W S},
    number      = {1},
    volume      = {156},
    doi         = {10.1016/j.pain.0000000000000014},
    place       = {United States},
    year        = {2015-01},
    pages       = {35-38},
    journal     = {Pain}
}


@article{Madden2016,
    title       = {Pain by association? Experimental modulation of human pain thresholds using classical conditioning},
    author      = {Madden, Victoria J. and Bellan, Valeria and Russek, Leslie N. and Camfferman, Danny and Vlaeyen, Johan W.S. and Moseley, G. Lorimer},
    number      = {10},
    volume      = {17},
    doi         = {10.1016/j.jpain.2016.06.012},
    publisher   = {Elsevier Inc},
    year        = {2016},
    pages       = {1105-1115},
    journal     = {Journal of Pain}
}


@article{Traxler2019,
    title       = {Modulating pain thresholds through classical conditioning},
    author      = {Traxler, Juliane and Madden, Victoria J. and Moseley, G. Lorimer and Vlaeyen, Johan W.S.},
    number      = {3},
    volume      = {2019},
    doi         = {10.7717/peerj.6486},
    year        = {2019},
    pages       = {1-20},
    journal     = {PeerJ}
}


@book{Pavlov1928,
    title       = {Lectures on conditioned reflexes: Twenty-five years of objective study of the higher nervous activity (behaviour) of animals.},
    author      = {Pavlov, Ivan Petrovitch},
    doi         = {10.1037/11081-000},
    publisher   = {Liverwright Publishing Corporation},
    place       = {New York, NY, US},
    year        = {1928}
}


@book{Barlow2009,
    title       = {Single case experimental designs: Strategies for studying behavior change},
    author      = {Barlow, D H and Nock, M K and Hersen, M},
    publisher   = {Pearson/Allyn and Bacon},
    place       = {Boston, MA},
    year        = {2009}
}


@book{Kazdin2011,
    title       = {Single-case research designs: Methods for clinical and applied settings},
    author      = {Kazdin, Alan E},
    publisher   = {Oxford University Press},
    place       = {New York, NY},
    year        = {2011}
}


@article{Heyvaert2014,
    title       = {Randomization tests for single-case experiments: State of the art, state of the science, and state of the application},
    author      = {Heyvaert, Mieke and Onghena, Patrick},
    number      = {1},
    volume      = {3},
    doi         = {10.1016/j.jcbs.2013.10.002},
    year        = {2014},
    pages       = {51-64},
    journal     = {Journal of Contextual Behavioral Science}
}


@article{Vlaeyen2020,
    title       = {From Boulder to Stockholm in 70 years: Single case experimental designs in clinical research},
    author      = {Vlaeyen, Johan W S and Wicksell, Rikard K and Simons, Laura E and Gentili, Charlotte and De, Tamal Kumar and Tate, Robyn L and Vohra, Sunita and Punja, Salima and Linton, Steven J and Sniehotta, Falko F and Onghena, Patrick},
    volume      = {70},
    doi         = {10.1007/s40732-020-00402-5},
    year        = {2020},
    pages       = {659--670},
    journal     = {The Psychological Record}
}


@article{Kratochwill2010,
    title       = {Enhancing the scientific credibility of single-case intervention research: Randomization to the rescue},
    author      = {Kratochwill, T. R. and Levin, Joel R},
    number      = {2},
    volume      = {15},
    doi         = {10.1037/a0017736},
    year        = {2010},
    pages       = {124-144},
    journal     = {Psychological Methods}
}


@article{Edgington1975,
    title       = {Randomization tests for one-subject operant experiments},
    author      = {Edgington, Eugene S},
    number      = {1},
    volume      = {90},
    doi         = {10.1080/00223980.1975.9923926},
    publisher   = {Journal Press, etc.},
    place       = {Provincetown, Mass., etc.},
    year        = {1975-05-01},
    pages       = {57},
    journal     = {Journal of Psychology}
}


@article{Horner2005,
    title       = {The use of single-subject research to identify evidence-based practice in special education},
    author      = {Horner, Robert H. and Carr, Edward G. and Halle, James and Mcgee, Gail and Odom, Samuel and Wolery, Mark},
    number      = {2},
    volume      = {71},
    doi         = {10.1177/001440290507100203},
    year        = {2005},
    pages       = {165-179},
    journal     = {Exceptional Children}
}


@article{Molenaar2009,
    title       = {The new person-specific paradigm in psychology},
    author      = {Molenaar, Peter C M and Campbell, Cynthia G},
    number      = {2},
    volume      = {18},
    doi         = {10.1111/j.1467-8721.2009.01619.x},
    publisher   = {SAGE Publications Inc},
    year        = {2009-04-01},
    pages       = {112-117},
    journal     = {Current Directions in Psychological Science}
}


@article{Fisher2018,
    title       = {Lack of group-to-individual generalizability is a threat to human subjects research},
    author      = {Fisher, Aaron J and Medaglia, John D and Jeronimus, Bertus F},
    number      = {27},
    volume      = {115},
    doi         = {10.1073/pnas.1711978115},
    year        = {2018-07-03},
    pages       = {E6106 LP - E6115},
    journal     = {Proceedings of the National Academy of Sciences}
}


@article{Ferron1995,
    title       = {Analyzing single-case data: The power of randomization tests},
    author      = {Ferron, John and Ware, William},
    number      = {2},
    volume      = {63},
    year        = {1995},
    pages       = {167-178},
    journal     = {The Journal of Experimental Education}
}


@article{Ferron1996,
    title       = {The power of randomization tests for single-case phase designs},
    author      = {Ferron, John and Onghena, Patrick},
    number      = {3},
    volume      = {64},
    doi         = {10.1080/00220973.1996.9943805},
    year        = {1996},
    pages       = {231-239},
    journal     = {Journal of Experimental Education}
}


@article{Busk1988,
    title       = {Autocorrelation in single-subject research: A counterargument to the myth of no autocorrelation.},
    author      = {Busk, Patricia L and Marascuilo, Leonard A},
    number      = {3},
    volume      = {10},
    publisher   = {Pergamon Press, Inc.},
    place       = {US},
    year        = {1988},
    pages       = {229-242},
    journal     = {Behavioral Assessment}
}


@article{Solomon2014,
    title       = {Violations of assumptions in school-based single-case data: Implications for the selection and interpretation of effect sizes},
    author      = {Solomon, Benjamin George},
    number      = {4},
    volume      = {38},
    doi         = {10.1177/0145445513510931},
    year        = {2014},
    pages       = {477-496},
    journal     = {Behavior Modification}
}


@article{Adams1996,
    title       = {Using randomization techniques to analyse behavioural data},
    author      = {Adams, Dean C and Anthony, Carl D},
    number      = {4},
    volume      = {51},
    doi         = {https://doi.org/10.1006/anbe.1996.0077},
    year        = {1996},
    pages       = {733-738},
    journal     = {Animal Behaviour}
}


@article{Smith2012,
    title       = {Single-case experimental designs: A systematic review of published research and current standards},
    author      = {Smith, Justin D.},
    number      = {4},
    volume      = {17},
    doi         = {10.1037/a0029312},
    year        = {2012},
    pages       = {510-550},
    journal     = {Psychological Methods}
}


@article{Ottenbacher1990,
    title       = {When is a picture worth a thousand p values? A comparison of visual and quantitative methods to analyze single subject data},
    author      = {Ottenbacher, Kenneth J},
    number      = {4},
    volume      = {23},
    doi         = {10.1177/002246699002300407},
    publisher   = {SAGE Publications Inc},
    year        = {1990-01-01},
    pages       = {436-449},
    journal     = {The Journal of Special Education}
}


@article{Matyas1990,
    title       = {Visual analysis of single-case time series: Effects of variability, serial dependence, and magnitude of intervention effects},
    author      = {Matyas, T A and Greenwood, K M},
    number      = {3},
    volume      = {23},
    doi         = {10.1901/jaba.1990.23-341},
    year        = {1990},
    pages       = {341-351},
    journal     = {Journal of applied behavior analysis}
}


@article{Kratochwill2010a,
    title       = {Single-case design technical documentation},
    author      = {Kratochwill, T. R. and Hitchcock, J and Horner, Robert H and Levin, J R and Odom, S L and Rindskopf, D M and Shadish, W R},
    year        = {2010}
}


@article{Manolov2018,
    title       = {Analytical options for single-case experimental designs: Review and application to brain impairment},
    author      = {Manolov, Rumen and Solanas, Antonio},
    number      = {1},
    volume      = {19},
    doi         = {10.1017/BrImp.2017.17},
    year        = {2018},
    pages       = {18-32},
    journal     = {Brain Impairment}
}


@article{Manolov2017,
    title       = {Recommendations for choosing single-case data analytical techniques},
    author      = {Manolov, Rumen and Moeyaert, Mariola},
    number      = {1},
    volume      = {48},
    doi         = {10.1016/j.beth.2016.04.008},
    publisher   = {Elsevier B.V.},
    year        = {2017},
    pages       = {97-114},
    journal     = {Behavior Therapy}
}


@book{Edgington2007,
    title       = {Randomization tests},
    author      = {Edgington, Eugene S and Onghena, Patrick},
    publisher   = {Chapman \\\\& Hall/CRC},
    place       = {Boca Raton, FL},
    year        = {2007}
}


@article{Michiels2020,
    title       = {A randomization test wrapper for synthesizing single-case experiments using multilevel models: A Monte Carlo simulation study},
    author      = {Michiels, Bart and Tanious, René and De, Tamal Kumar and Onghena, Patrick},
    number      = {2},
    volume      = {52},
    doi         = {10.3758/s13428-019-01266-6},
    year        = {2020},
    pages       = {654-666},
    journal     = {Behavior Research Methods}
}


@article{Heyvaert2014a,
    title       = {Analysis of single-case data: Randomisation tests for measures of effect size},
    author      = {Heyvaert, Mieke and Onghena, Patrick},
    number      = {3-4},
    volume      = {24},
    doi         = {10.1080/09602011.2013.818564},
    year        = {2014},
    pages       = {507-527},
    journal     = {Neuropsychological Rehabilitation}
}


@book{Cohen1988,
    title       = {Statistical power analysis for the behavioral sciences},
    author      = {Cohen, Jacob},
    doi         = {10.4324/9780203771587},
    publisher   = {Routledge},
    place       = {New York, NY},
    year        = {1988}
}


@article{Vohra2015,
    title       = {CONSORT extension for reporting N-of-1 trials (CENT) 2015 statement},
    author      = {Vohra, Sunita and Shamseer, Larissa and Sampson, Margaret and Bukutu, Cecilia and Schmid, Christopher H. and Tate, Robyn and Nikles, Jane and Zucker, Deborah R. and Kravitz, Richard and Guyatt, Gordon and Altman, Douglas G. and Moher, David},
    volume      = {350},
    doi         = {10.1136/bmj.h1738},
    year        = {2015},
    pages       = {h1738},
    journal     = {BMJ (Clinical research ed.)}
}


@article{Willkinson1999,
    title       = {Statistical methods in psychology journals: Guidelines and explanations},
    author      = {Willkinson, Leland},
    number      = {8},
    volume      = {54},
    doi         = {10.1037/0003-066X.54.8.594},
    year        = {1999},
    pages       = {594-604},
    journal     = {American Psychologist}
}


@article{Onghena1992,
    title       = {Randomization tests for extensions and variations of ABAB single-case experimental designs: A rejoinder},
    author      = {Onghena, Patrick},
    number      = {2},
    volume      = {14},
    year        = {1992},
    pages       = {153-171},
    journal     = {Behavioral Assessment}
}


@article{Michiels2018,
    title       = {The conditional power of randomization tests for single-case effect sizes in designs with randomized treatment order: A Monte Carlo simulation study},
    author      = {Michiels, Bart and Heyvaert, Mieke and Onghena, Patrick},
    number      = {2},
    volume      = {50},
    doi         = {10.3758/s13428-017-0885-7},
    publisher   = {Behavior Research Methods},
    year        = {2018},
    pages       = {557-575},
    journal     = {Behavior Research Methods}
}


@article{Bouwmeester2020,
    title       = {Power of a randomization test in a single case multiple baseline AB design},
    author      = {Bouwmeester, Samantha and Jongerling, Joran},
    number      = {2},
    volume      = {15},
    doi         = {10.1371/journal.pone.0228355},
    year        = {2020},
    pages       = {1-21},
    journal     = {PLoS ONE}
}


@article{Ferron2002,
    title       = {Statistical power of randomization tests used with multiple-baseline designs},
    author      = {Ferron, John and Sentovich, Chris},
    number      = {2},
    volume      = {70},
    doi         = {10.1080/00220970209599504},
    year        = {2002},
    pages       = {165-178},
    journal     = {Journal of Experimental Education}
}


@article{De2020,
    title       = {Handling missing data in randomization tests for single-case experiments: A simulation study},
    author      = {De, Tamal Kumar and Michiels, Bart and Tanious, René and Onghena, Patrick},
    number      = {3},
    volume      = {52},
    doi         = {10.3758/s13428-019-01320-3},
    year        = {2020},
    pages       = {1355-1370},
    journal     = {Behavior Research Methods}
}


@article{Madden2019,
    title       = {Was that painful or nonpainful? The Sensation and Pain Rating Scale performs well in the experimental context},
    author      = {Madden, Victoria J. and Kamerman, Peter R. and Bellan, Valeria and Catley, Mark J. and Russek, Leslie N. and Camfferman, Danny and Moseley, G. Lorimer},
    number      = {4},
    volume      = {20},
    doi         = {10.1016/j.jpain.2018.10.006},
    publisher   = {Elsevier Inc.},
    year        = {2019},
    pages       = {472.e1-472.e12},
    journal     = {Journal of Pain}
}


@article{Spruyt2009,
    title       = {Affect 4.0: A free software package for implementing psychological and psychophysiological experiments},
    author      = {Spruyt, Adriaan and Clarysse, Jeroen and Vansteenwegen, Debora and Baeyens, Frank and Hermans, Dirk},
    number      = {1},
    volume      = {57},
    doi         = {10.1027/1618-3169/a000005},
    year        = {2009},
    pages       = {36-45},
    journal     = {Experimental Psychology}
}


@article{bib0,
    title       = {Tactor},
    author      = {Dancer Design},
    place       = {St. Helens, UK},
    year        = {00}
}


@article{bib0,
    title       = {DS7A High Voltage Constant Current Stimulator},
    author      = {Digitimer Limited},
    place       = {Hertfordshire, UK},
    year        = {00}
}


@article{Madden2017,
    title       = {Classical conditioning fails to elicit allodynia in an experimental study with healthy humans},
    author      = {Madden, Victoria J. and Russek, Leslie N. and Harvie, Daniel S. and Vlaeyen, Johan W.S. and Moseley, G. Lorimer},
    number      = {7},
    volume      = {18},
    doi         = {10.1093/pm/pnw221},
    year        = {2017},
    pages       = {1314-1325},
    journal     = {Pain Medicine}
}


@article{Onghena2005,
    title       = {Single-case designs},
    author      = {Onghena, Patrick},
    volume      = {4},
    doi         = {10.1002/0470013192.bsa625},
    publisher   = {John Wiley \\\\& Sons, Ltd},
    place       = {Hoboken, NJ},
    year        = {2005-04-15},
    pages       = {1850-1854},
    journal     = {Encyclopedia of statistics in behavioral science}
}


@article{Michiels2019,
    title       = {Randomized single-case AB phase designs: Prospects and pitfalls},
    author      = {Michiels, Bart and Onghena, Patrick},
    number      = {6},
    volume      = {51},
    doi         = {10.3758/s13428-018-1084-x},
    publisher   = {Behavior Research Methods},
    year        = {2019},
    pages       = {2454-2476},
    journal     = {Behavior Research Methods}
}


@article{De2020a,
    title       = {Shiny SCDA},
    author      = {De, Tamal Kumar and Michiels, Bart and Vlaeyen, Johan W S and Onghena, Patrick},
    number      = {Version 2.7},
    year        = {2020}
}


@article{Levin2018,
    title       = {Comparison of randomization-test procedures for single-case multiple-baseline designs},
    author      = {Levin, Joel R. and Ferron, John M. and Gafurov, Boris S.},
    number      = {5},
    volume      = {21},
    doi         = {10.1080/17518423.2016.1197708},
    publisher   = {Taylor \\\\& Francis},
    year        = {2018},
    pages       = {290-311},
    journal     = {Developmental Neurorehabilitation}
}


@article{Edgington1969,
    title       = {Approximate randomization tests},
    author      = {Edgington, Eugene S},
    number      = {2},
    volume      = {72},
    doi         = {10.1080/00223980.1969.10543491},
    publisher   = {Routledge},
    year        = {1969-07-01},
    pages       = {143-149},
    journal     = {The Journal of Psychology}
}


@article{Hope1968,
    title       = {A simplified Monte Carlo significance test procedure},
    author      = {Hope, Adery C A},
    number      = {3},
    volume      = {30},
    publisher   = {[Royal Statistical Society, Wiley]},
    year        = {1968},
    pages       = {582-598},
    journal     = {Journal of the Royal Statistical Society. Series B (Methodological)}
}

\\\\end{filecontents}

\\\\begin{document}

  

Classical Conditioning for Pain: The Development of a Customized Single-Case Experimental Design









\\\\textbf{Keywords}: single-case, classical conditioning, pain, randomization test, statistical power.

\\\\section{Take-Home Message}

We wanted to design a single-case experiment to test whether classical conditioning can influence pain thresholds. We settled on a customized AB phase design for which we ran pilot tests and a power study. The results indicated that this single-case design can be used to test our hypothesis.

\\\\section{Abstract}

Single-case experiments are increasingly popular in the behavioral sciences. Due to their flexibility, single-case designs can be customized to test a variety of experimental hypotheses. We were interested in using a single-case experimental approach to test whether pain thresholds can be influenced by Pavlovian classical conditioning. Following the example of earlier studies into this topic, we planned to measure whether participants would more frequently report specific electrocutaneous stimuli as painful when they were presented with specific vibrotactile stimuli that had previously been associated with painful electrocutaneous stimuli. First, we decided on a mean difference effect size measure derived from the Sensation and Pain Rating Scale ratings for the electrocutaneous stimuli provided by the participants. Next, we discussed several possible single-case designs and evaluated their benefits and shortcomings. Then, we ran pilot tests with a few participants based on the possible single-case designs. We also conducted a simulation study to estimate the power of a randomization test to test our hypothesis using different values for effect size, number of participants, and number of measurements. Finally, we decided on a sequentially replicated AB phase design with 30 participants based on the results from the pilot tests and the power study. We plan to implement this single-case design in a future experiment to test our hypothesis. 

\\\\section{Purpose}

In this manuscript, our purpose is to describe how we used a trial and error approach to design a customized single-case experiment (SCE) to test the effect of classical conditioning on pain thresholds. We hope that this information helps readers who plan to implement an SCE in better understanding the steps involved and possible challenges. We wish to focus on using the flexible nature of SCEs to adapt to the requirements of the experiment. We also wish to highlight the necessity of exploring various available statistical methods and statistical power requirements for these methods prior to starting the experiment. Finally, we demonstrate how SCEs can serve as a viable avenue for pilot-testing new therapies and treatments at a small scale before implementing larger scale studies.

\\\\section{Introduction}

\\\\subsection{Classical Conditioning}

Persistent pain—pain that is still felt after bodily tissue has healed—is a major healthcare problem that is poorly understood and, consequently, difficult to treat effectively \\\\parencite{Breivik2006, Tsang2008, Costa2009, Foster2018, Treede2019}. While there are key models that go some way towards explaining how pain can persist without active tissue damage \\\\parencite{Woolf1983, Woolf2011, Vlaeyen2000, Vlaeyen2012}, certain pain presentations remain unexplained. The imprecision hypothesis was proposed to address these unexplained presentations, and is founded on the idea that pain can be modulated by pain-associated cues—specifically, via “classical conditioning” \\\\parencite{Moseley2015}. 

Our study design builds on two previous experiments \\\\parencite{Madden2016, Traxler2019}, which followed a Pavlovian or “classical” conditioning design \\\\parencite{Pavlov1928} to test whether neutral but pain-associated cues can bias a participant's decision about whether a stimulus is painful or non-painful. In the differential classical conditioning design used here, one neutral cue is paired with a painful electrocutaneous stimulus, while another neutral cue is paired with a non-painful electrocutaneous stimulus. It is expected that participants form associations between each cue and painfulness, such that subsequent perception of an ambiguous electrical stimulus is modified, dependent on the simultaneous presentation of one of the neutral cues.

We set out to design an SCE to test this hypothesis. Due to the before (conditioning) and after (conditioning) structure of multiple observations required for each participant, SCE designs are perfectly suited for testing this hypothesis.

\\\\subsection{Single-Case Experiments}

SCEs are experiments in which the effect of manipulating an independent variable is observed in a single entity \\\\parencite{Barlow2009, Kazdin2011}. Variables of interest in the entity, which is often a single participant, are measured repeatedly over a period of time with the purpose of establishing a causal relationship between the independent variable, commonly referred to as the treatment condition, and the observed entity. SCEs are increasingly popular in behavioral and educational sciences due to their flexibility, low cost, and focus on effects of the intervention in individual participants \\\\parencite{Heyvaert2014}. SCEs may be preferable to group-based designs, where the existence or magnitude of the effect \\\\emph{within} an individual is more relevant than the average effect \\\\emph{across} a group of individuals. The lower cost and flexibility of SCEs also make them ideal for studying new theories and interventions, as is the case in this study \\\\parencite{Vlaeyen2020}.

In SCEs, assignment of the treatment conditions to measurement occasions can be randomized to strengthen internal validity \\\\parencite{Kratochwill2010, Edgington1975}. Additionally, replication using multiple participants strengthens external validity and generalizability of the results \\\\parencite{Kratochwill2010, Horner2005}. In our study design, we incorporated both randomization and replication to enhance internal and external validity of the experiment. 

\\\\subsection{Advantages of SCEs for Classical Conditioning}

SCEs are well suited to research questions about within-individual processes. Although group designs are historically respected, they are typically analyzed in a way that aggregates data from all individuals to estimate an effect at the group level—an effect that may be non-existent in any of the individuals within the group \\\\parencite{Molenaar2009}. This aggregation approach obscures the true, within-individual effect, and the between-individual variability of that effect (which, itself, is typically worthy of attention; \\\\parencite{Fisher2018}. Of course, it is possible to consider within-individual changes in some group designs, but an SCE offers a superior approach to achieving a sufficiently powered (> 80\\\\%) examination of within-subject effects \\\\parencite{Ferron1995, Ferron1996}. Whereas traditional group-based designs generate knowledge on the population level only, SCEs generate knowledge at the level of the individual. Finally, findings from group-based designs cannot be generalized towards individuals, while SCEs can be aggregated for insights on populations.

\\\\subsection{Analyzing SCEs}

SCEs are often difficult to analyze due to the presence of serial correlation in observed data and nonadherence to distributional assumptions \\\\parencite{Busk1988, Solomon2014, Adams1996, Smith2012}. Traditionally, visual analysis was the preferred method for analyzing SCE data, but researchers now recommend quantitative statistical analysis to complement visual analysis \\\\parencite{Ottenbacher1990, Matyas1990, Kratochwill2010a, Manolov2018, Manolov2017}. Specifically, for experiments involving user-reported ordinal data, such as the current experiment, nonparametric statistical methods may be best suited for analysis, as the observed data may not adhere to distributional assumptions required for popular parametric methods. 

Randomization tests (RTs) are nonparametric hypothesis tests recommended for analyzing SCEs \\\\parencite{Edgington1975, Adams1996, Heyvaert2014}. RTs derive their validity from the random assignment of treatment conditions to experimental units, which in the case of SCEs, are measurement occasions \\\\parencite{Edgington2007}. RTs do not require any distributional assumptions for the observed data. Additionally, RTs are immensely flexible, and can be adapted for any SCE design, randomization scheme, and effect size measure as the test statistic \\\\parencite{Michiels2020, Heyvaert2014a, Heyvaert2014}. In our study design, we implemented a customized RT using a mean difference effect size measure as the test statistic. 

\\\\subsection{Statistical Power of SCE RTs }

Power analysis is an essential part of statistical hypothesis testing, particularly for determining sample size \\\\parencite{Cohen1988}. Several guidelines recommend a power analysis or at least a methodical description of how sample size was determined \\\\parencite{Vohra2015, Willkinson1999}. In the context of SCEs, power analysis can be used to determine the number of measurements necessary, and for studies with replication, the number of participants.

For RTs, the randomization distribution is calculated empirically, and hence statistical power can only be estimated using computer-intensive simulations \\\\parencite{Onghena1992, Ferron1995}. Several studies have estimated the power of SCE RTs for various design conditions \\\\parencite{Ferron1996, Ferron1995, Michiels2018, Bouwmeester2020, Ferron2002, De2020}. Although the results from these studies can be used as a reference, they are true only for the design parameters and simulated data distributions considered. Since we acquired unusual ordinal observed data, power ideally needed to be estimated using simulated data of the same type as this study would generate.

\\\\section{Methods}

\\\\subsection{Experimental Setup}

In this experiment, participants receive two different types of stimuli: a vibrotactile stimulation as the conditioned stimulus (CS) and an electrocutaneous stimulation as the unconditioned stimulus (US). At first, one neutral stimulus (a vibrotactile stimulus, denoted as CS+) is paired with a painful stimulus (a high-intensity electrocutaneous stimulus, denoted as US\\\\textsubscript{high}), whereas a different neutral stimulus (a vibrotactile stimulus, denoted as CS-, applied to a different location) is paired with a non-painful stimulus (a low-intensity electrocutaneous stimulus, denoted as US\\\\textsubscript{low}). This procedure is expected to form an association between the CS+ and painfulness, in contrast to the CS- and non-painfulness. Later, each CS is paired with a “test stimulus” (denoted as US\\\\textsubscript{test}), an electrocutaneous stimulus of an intensity calibrated such that there is a 50\\\\% chance that the participant judges it to be painful or non-painful at baseline (i.e., before the pairing). Participants are then requested to judge each trial on a scale that distinguishes painful from non-painful events \\\\parencite{Madden2019}. The trials of interest are the CS/US\\\\textsubscript{test} pairs, as the primary hypothesis is that, due to the pairings learned early in the experiment, the participant will come to judge the US\\\\textsubscript{test} stimuli to be painful more often when they are paired with the CS+ (previously paired with a painful stimulus) than when they are paired with the CS- (previously paired with a non-painful stimulus).

\\\\subsection{Laboratory Setup}

The participants receive two types of stimuli at the same time, replicating the procedure in Traxler et al. \\\\parencite{Traxler2019}. Stimulus onset and timing are controlled using Affect 4.0 \\\\parencite{Spruyt2009}. A vibrotactile stimulus is delivered to the skin using tactors manufactured by Dancer Design taped to the participant's skin \\\\parencite{Dancer Design0}(Dancer Design, n.d.). This stimulus is of fixed duration and a clearly perceptible intensity. Three tactors are used in the arrangement as the source of a CS (see Figure 1). The SIDE tactor is allocated to CS\\\\textsubscript{neutral}, whereas the ABOVE and BELOW tactors are assigned to CS+ and CS- in a counterbalanced way across participants.

\\\\textbf{Figure 1}

\\\\emph{Arrangement of Tactors and Electrodes on the Back (Adapted From Traxler et al. , Traxler2019}\\\\emph{).}

[INSERT FIGURE 1 HERE]

An electrocutaneous stimulation is delivered by passing a current across two surface electrodes located at the midpoint between the tactors to serve as the US (Figure 1). The current is delivered using a DS7A constant current stimulator \\\\parencite{Digitimer Limited0}(Digitimer Limited, n.d.). The stimulation intensity is calibrated individually. The number of pulses delivered on each stimulation occasion is varied to provide a US\\\\textsubscript{high} that is usually painful, a US\\\\textsubscript{low} that is usually non-painful, and a US\\\\textsubscript{test} that is calibrated to lie close to the pain threshold, the boundary between non-painful and painful.

\\\\subsection{Tactor and Electrode Preparation}

On arrival, participants are seated straddling a chair in front of a desk with a computer monitor, mouse, and keyboard. Participants are asked to bend backwards to identify the point at which the greatest bend is seen. A point in the upper lumbar region is marked on the back, 2cm to the left of the spine, where the electrodes are placed such that the mark lies exactly between them. Three other points—4cm above, below, and to the left side of the electrodes—are marked, and the tactors are taped in place such that the closest border of each tactor lies at a tactor mark (Figure 1). Calibration is performed by the procedure described in Traxler et al. \\\\parencite{Traxler2019}, with the CS\\\\textsubscript{neutral} paired with each electrocutaneous stimulus. The CS\\\\textsubscript{neutral} is used to provide vibratory stimulation consistent with the CS+/CS- stimuli that are later presented in the experimental trials to ensure that any modulation of pain by the vibration itself is consistent across calibration and experimental trials. Ratings of CS\\\\textsubscript{neutral} trials from the experimental phase are not relevant to the research question and are therefore not analyzed.

\\\\subsection{Experimental Trials}

Based on the experimental setup discussed previously, and given the pairing of CSs and USs, the experiment for a participant can theoretically consist of five different types of trials:

Training trials: Each training trial consists of one CS, with each of the three CS types used in different trials. There is no electrocutaneous stimulation (i.e., US) presented. These trials are conducted to familiarize the participants with the locations of the CS tactors. 

Baseline trials: The baseline trials consist of two combinations of stimulations: a CS+ with a simultaneous US\\\\textsubscript{test} and a CS- with a simultaneous US\\\\textsubscript{test}. These trials are used to record baseline pain ratings of participants before they are conditioned to associate the painful US with a particular CS.

Acquisition or learning trials: These trials consist of two combinations of stimulations: a CS+ with an US\\\\textsubscript{high} and a CS- with an US\\\\textsubscript{low}, and are meant to condition participants to associate painful US to CS+ and vice versa.

Test trials: These trials are the same as the two baseline trials: a CS+ with an US\\\\textsubscript{test} and a CS- with an US\\\\textsubscript{test}, and are meant to record pain ratings of participants to test whether they have associated the painful US with CS+ and vice versa.

Irrelevant trials: These trials consist of a CS\\\\textsubscript{neutral} combined with an US\\\\textsubscript{test} stimuli. These trials are noninformative and are included to satisfy the assumptions of the analytical approach; they are included only to achieve consistency in the time gaps between baseline or test trials. 

\\\\subsection{Observed Variables}

The participants are requested to provide two reports on each trial. First, they rate the stimulation event on the Sensation and Pain Rating Scale \\\\parencite[][SPARS; previously known as FESTNRS;]{Madden2017, Madden2019}. The SPARS is anchored at -50 (no sensation), 0 (the exact point at which the feeling transitions to pain), and 50 (worst pain imaginable). The two distinct ranges for non-painful (-50 to -1) and painful (1 to 50) are clearly marked and explained to the participants. Participants are explicitly advised to make an initial decision about whether a trial was non-painful or painful before assigning a rating from the appropriate side of the scale, without selecting 0 on SPARS. 

Second, the participant indicates the location at which they feel the vibrotactile stimulus from the three options “ABOVE”, “BELOW”, and “SIDE”. This is only used to confirm that the participants are identifying the location of the stimuli correctly. Given that discrimination of the vibrotactile stimuli is necessary for differential learning, participants who fail to identify the location of the stimulus correctly in at least 75\\\\% of the trials are excluded and replaced by additional participants.

\\\\subsection{Effect Size Measure and Test Statistic}

We are interested in calculating whether the participants judged trials of CS+/ US\\\\textsubscript{test} and CS-/ US\\\\textsubscript{test} as painful or non-painful differently for baseline and test trials. For this purpose, we first convert the SPARS ratings to a binary variable: 0 for non-painful (-50 to -1 on SPARS) and 1 for painful (1 to 50 on SPARS). A rating of 0 on SPARS can neither be classified as painful nor as non-painful, therefore these are considered indeterminate and were marked as missing. Then, we pair two trials, a CS+/ US\\\\textsubscript{test} and a CS-/ US\\\\textsubscript{test} and calculate the difference between the corresponding binary variables. The resulting difference indicates whether the participant is rating CS+/ US\\\\textsubscript{test} and CS-/ US\\\\textsubscript{test} differently. The difference can result in three different values: 1 when the CS+/ US\\\\textsubscript{test} trial is rated as painful while the corresponding CS-/ US\\\\textsubscript{test} trial is rated as non-painful; -1 when the CS+/ US\\\\textsubscript{test} trial is rated as non-painful while the corresponding CS-/ US\\\\textsubscript{test} trial is rated as painful; and finally, 0 when both CS+/ US\\\\textsubscript{test} and CS-/ US\\\\textsubscript{test} trials are rated as painful or both are rated as non-painful. This difference value, calculated from a pair of trials, constitutes one measurement in our SCE. A simple mean difference (MD) effect size measure is calculated as the difference between the means of the difference values derived from the test trial pairs and the difference values derived from the baseline trial pairs. Due to the flexibility of RTs, this effect size measure can also be used as the test statistic \\\\parencite{Heyvaert2014a}. 

\\\\subsection{Single-Case Design }

In this section, we describe our considerations regarding which SCE design to use in our experiment. We discuss several initial design possibilities that were chosen by trial and error and conclude with a final design.

\\\\subsubsection{Initial Design Options}

Randomized Block Design. Since each of our measurements requires a pair of trials, we immediately considered a randomized block design (RBD) for the experiment. In an RBD SCE, similar to an RBD in traditional group designs, the measurement occasions are divided into small blocks, with each block containing administrations of all treatment conditions \\\\parencite{Onghena2005}. For our study, a possible block consists of the two baseline (or test) trials, a CS+/ US\\\\textsubscript{test} and a CS-/ US\\\\textsubscript{test}, in random order. Hence, the experiment for a participant can consist of several blocks of baseline trial pairs, followed by a period of acquisition trials to condition the participants, followed by several blocks of test trial pairs. However, this design is immediately rejected, as an RBD SCE requires all treatment conditions to be applied inside a block. Since the effects of conditioning are acquired over a period of time and are expected to carry over to future trials, true alternation of treatment conditions is not possible in this experiment. 

AB Phase Design with In-Phase Acquisition. When we rejected the RBD, we realized that the experiment should consist of periods of baseline trial pairs and periods of test trial pairs. The simplest method to achieve this is using an AB phase design, with an A phase as the baseline condition and a subsequent B phase as the test condition \\\\parencite{Barlow2009}. In favor of internal validity, the phase transition is preferably randomized. Each phase consists of several blocks of trials, each of which yields one measurement. Each measurement block in the baseline phase consists of \\\\emph{k} irrelevant trial pairs (two CS\\\\textsubscript{neutral}/ US\\\\textsubscript{test}) and a baseline trial pair (a CS+/ US\\\\textsubscript{test} and a CS-/ US\\\\textsubscript{test} in random order). Similarly, each measurement block in the test phase consists of \\\\emph{k} acquisition trial pairs (a CS+/ US\\\\textsubscript{high} and a CS-/ US\\\\textsubscript{low} in random order) followed by a test trial pair (a CS+/ US\\\\textsubscript{test} and a CS-/ US\\\\textsubscript{test} in random order). The number of irrelevant or acquisition trial pairs in each block, or \\\\emph{k}, is set based on the required level of acquisition. A lower \\\\emph{k} would mean we would need a lower number of trials to achieve a certain number of measurements, but would also typically result in weaker acquisition of associations, and vice versa for a higher \\\\emph{k}. Unfortunately, this design has low acquisition of the associations as there is no learning period. Additionally, RTs for AB phase designs require a large number of measurements to achieve sufficient statistical power \\\\parencite{Michiels2019, Ferron1995}. As a result, the experiment for a participant would need a very large number of trials over a significantly long time to ensure both high acquisition and enough measurements. As a result, this design is rejected in favor of a slightly modified AB phase design. A similar ABAB phase design is also rejected due to the potentially large number of trials required and possibility of carry-over effects between phases. 

\\\\subsubsection{Final Design}

The final design combines elements from both previous designs: an AB phase design with both out-of-phase and in-phase learning. The baseline phase for this design contains several pairs of baseline trial pairs (a CS+/ US\\\\textsubscript{test} and a CS-/ US\\\\textsubscript{test} in random order), followed by a period of learning with only acquisition trial pairs (a CS+/ US\\\\textsubscript{high} and a CS-/ US\\\\textsubscript{low} in random order). Finally, the test phase includes test trial pairs (a CS+/ US\\\\textsubscript{test} and a CS-/ US\\\\textsubscript{test} in random order) with a few acquisition trial pairs in between at regular intervals to reinforce the associations and hence prevent extinction. The time of onset of the test phase is randomized. The experiment starts with a few training trials before the baseline phase. 

The number of trials and the number of participants are to be decided based on a power study and some pilot experiments. However, the guidelines for phase designs by Kratochwill et al. \\\\parencite{Kratochwill2010a} recommend at least five measurements in both baseline and test phases. Since we are also curious about any increase or decrease in acquisition over time, we decide to include at least 15 measurements in the test phase. 

Due to the use of specialized equipment and individual calibration, multiple participants cannot be tested at the same time. Hence, simultaneous replication using a multiple baseline design (MBD), which is able to control for environmental confounding factors, is not possible \\\\parencite{Barlow2009, Kazdin2011}. Instead, the experiment is to be run as a sequentially replicated AB phase design experiment. 

\\\\subsection{Randomization Scheme and RT}

The design is randomized using intervention start point randomization for each participant \\\\parencite{Edgington1975}. In this scheme, the total number of measurements and the minimum number of measurements in each phase is decided beforehand, and the intervention can start at any time point that satisfies these restrictions. Therefore, if the number of measurements is \\\\emph{N}, and the minimum number of measurements in A and B phase are \\\\emph{a} and \\\\emph{b} respectively, the number of possible randomizations is \\\\emph{r} = \\\\emph{N} -- \\\\emph{a} -- \\\\emph{b} + 1. For \\\\emph{P} participants with the same randomization scheme, the total number of randomizations for the replicated experiment is \\\\emph{r}\\\\textsuperscript{\\\\emph{P}}. 

We conduct a single RT for all participants combined based on these \\\\emph{r}\\\\textsuperscript{\\\\emph{P}} randomizations. The null hypothesis for this RT is that no difference exists between the baseline phase measurements and test phase measurements for all participants. As discussed previously, the measurements represent whether participants rate CS+/ US\\\\textsubscript{test} trials as painful more frequently than CS-/ US\\\\textsubscript{test} trials. Since the Pavlovian conditioning procedure is aimed at participants perceiving the CS+/ US\\\\textsubscript{test} as more painful, the RT is one-sided with the alternate hypothesis being that the test phase measurements are higher than the baseline phase measurements for at least one participant. This RT can be conducted with the average (across participants) of the MD effect size measure discussed previously as the combined test statistic.

We use the Shiny SCDA (Single-Case Data Analysis) web app for SCEs to randomize and analyze the experiment \\\\parencite{De2020a}. Whereas this web app does not include an option for simultaneously replicated AB phase design, it does include an MBD option. The MBD option in Shiny SCDA uses the Koehler-Levin regulated randomization procedure \\\\parencite{Levin2018}, which, when using an identical set of possible start points for all participants, is analogous to our randomization scheme. Hence, we can both randomly select test phase start points and run the RT in Shiny SCDA. Additionally, we can plot the observed data for visual analysis in Shiny SCDA. 

\\\\subsection{Pilot Tests}

We ran several pilot tests to estimate possible effect sizes and to test possible design choices. We first tested nine participants under slight variations of our initial design choice. Later, after a simulated power study and adjustments to the design, we tested another four participants. We analyzed these four tests using visual analysis and an RT in Shiny SCDA. These four tests were, however, not randomized, and the test phase for all four participants started at the tenth measurement occasion. However, for the purposes of demonstration, we ignored the assumption of randomization. We will discuss the results from these pilot tests, and the final four tests in particular in the Results section. 

There were two important takeaways from the first nine pilot tests that were very useful for the design of the power study. First, the observed MD effect sizes were extremely small. The average effect size from the first nine tests was slightly negative at -0.037, with a maximum of 0.143 and a minimum of -0.400. Second, the pilot tests also revealed difficulties in running the experiment for more than 30-35 minutes for a participant. Considering each trial took around 15 seconds, this gave us a maximum of around 140 trials.

\\\\subsection{Power Study}

To ensure sufficient statistical power for our RT, we needed to first estimate power for different values of number of measurements (\\\\emph{N}) and number of participants (\\\\emph{P}), and then choose sufficiently high values of \\\\emph{N} and \\\\emph{P} for the experiment. 

Ideally, we would want to select the maximum \\\\emph{N} possible within the limits of how long an experiment can be reasonably run. This strategy presents us with two advantages. First, increasing \\\\emph{N} should result in reduction in the variability of the estimate of effect size. Second, maximizing \\\\emph{N} should allow us to achieve sufficient power with lower \\\\emph{P}, which directly equates to lower cost for the experiment.

We used the Monte Carlo method used by Ferron and Onghena \\\\parencite{Ferron1996} to estimate power. In this method, several datasets are simulated under a set of simulation conditions. The proportion of these simulated datasets in which the RT leads to a rejection of the null hypothesis gives an estimate of statistical power for the given set of simulation conditions. A simulation study of such complexity is both difficult to program and computationally intensive to execute. Fortunately, we were able to modify and repurpose R code used by De, Michiels, Tanious, et al. \\\\parencite{De2020} for this study. 

\\\\subsubsection{Simulation Conditions}

The following three simulation conditions were varied for this power study:

Effect size: Based on the low effect sizes observed in the pilot tests, we simulated MD effect sizes of 0.1, 0.2, 0.3, 0.4, and 0.5 for the simulated observed data.

Number of measurements: We decided on a minimum of five measurements in the baseline phase and a minimum of 15 measurements in the test phase. As a result, the experiment needs more than 20 measurements. However, from the pilot tests it was evident that an experiment with more than 140 trials (70 trial pairs) was not feasible. Considering around 30 trials are required for the training and learning periods, and a few more acquisition trails for reinforcement during test phase, it was difficult to have more than 40 measurements (80 trials). Hence, we used 25, 30, 35, and 40 measurements for simulated data. 

Number of participants: Since the pilot tests revealed a small effect size, and the number of measurements is also limited, to ensure high power we considered a large range of participant count at 10, 20, 30, 40, and 50. 

\\\\subsubsection{Other Simulation Parameters}

For the power study, we wanted to simulate observed values that were similar to the experiment. For the baseline, we assumed a symmetric distribution around 0 for the SPARS rating. Therefore, the painful/non-painful ratings were expected to be 0s and 1s equally for both CS+/ US\\\\textsubscript{test} and CS-/ US\\\\textsubscript{test} trials. Hence, an observed value corresponding to a trial pair in the baseline was expected to be 1 with 25\\\\% probability, -1 with 25\\\\% probability, and 0 with 50\\\\% probability. We simulated observed values as 1, -1, and 0 with these probabilities. For the test phase, we increased the probability of 1 by half the selected effect size and decreased the probability of -1 by half the selected effect size. This resulted in an expected MD effect size equal to the selected effect size. 

Since the number of randomizations for the RT was huge, we simulated Monte Carlo RTs with 1000 randomizations \\\\parencite{Edgington1969}

The simulations were run on supercomputer nodes at the Flemish Supercomputer Center (Leuven, Belgium). This allowed testing more simulation conditions and achieve high accuracy simulating a large number of datasets for each simulation condition; however, the simulations can also be run at a smaller scale on a personal computer. 

\\\\section{Results}

\\\\subsection{Power Analysis}

The results from the power study (Table 1) revealed that due to the relatively small effect sizes and restricted number of measurements, the number of participants need to be high to achieve 80\\\\% power. If we restrict the number of measurements to 30, which allows sufficient acquisition trials for learning and reinforcement within 30 minutes, 30 participants result in sufficient power even with a moderate effect size. 





















\\\\textbf{Table 1}

\\\\emph{Estimated Power Simulated Using Different Values for Effect Size, Number of Measurements, and Number of Participants.}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c  c}

  No. of measurements & No. of participants & Effect size\\\\\\\\
0.1 & 0.2 & 0.3 & 0.4 & 0.5\\\\\\\\
25 & 10 & 10.3 & 19.0 & 32.2 & 48.6 & 66.1\\\\\\\\
  & 20 & 13.4 & 29.3 & 51.4 & 74.4 & 90.0\\\\\\\\
  & 30 & 16.4 & 38.8 & 66.1 & 87.9 & 97.7\\\\\\\\
  & 40 & 18.9 & 47.5 & 77.4 & 94.8 & 99.5\\\\\\\\
  & 50 & 22.2 & 54.7 & 85.1 & 97.9 & 99.9\\\\\\\\
30 & 10 & 13.0 & 25.9 & 45.0 & 66.1 & 83.9\\\\\\\\
  & 20 & 17.9 & 42.0 & 70.6 & 90.8 & 98.5\\\\\\\\
  & 30 & 21.9 & 54.9 & 86.0 & 97.9 & 99.9\\\\\\\\
  & 40 & 26.4 & 65.2 & 92.7 & 99.6 & 100.0\\\\\\\\
  & 50 & 30.0 & 73.4 & 96.6 & 99.9 & 100.0\\\\\\\\
35 & 10 & 14.3 & 31.4 & 55.0 & 77.4 & 92.7\\\\\\\\
  & 20 & 21.0 & 51.4 & 81.0 & 96.6 & 99.7\\\\\\\\
  & 30 & 27.4 & 65.5 & 93.3 & 99.7 & 100.0\\\\\\\\
  & 40 & 32.8 & 77.1 & 97.5 & 99.9 & 100.0\\\\\\\\
  & 50 & 37.4 & 84.7 & 99.1 & 100.0 & 100.0\\\\\\\\
40 & 10 & 15.4 & 36.0 & 63.9 & 84.9 & 96.3\\\\\\\\
  & 20 & 23.6 & 58.1 & 88.4 & 98.6 & 100.0\\\\\\\\
  & 30 & 30.7 & 74.0 & 96.8 & 99.9 & 100.0\\\\\\\\
  & 40 & 37.0 & 84.6 & 99.2 & 100.0 & 100.0\\\\\\\\
  & 50 & 42.8 & 90.4 & 99.8 & 100.0 & 100.0\\\\\\\\


\\\\end{tabular}


\\\\end{table}


Based on these results, we decided to run the final set of pilot tests with 30 measurements. We decided on six training trials (two trials for each type of CS) before the baseline phase, 24 acquisition trials between the baseline and test phases, and additionally one acquisition trial pair for reinforcement after two test trial pairs during the test phase. With a minimum of five measurements in the baseline phase, and a minimum of 15 measurements in the test phase, this design allows for 11 possible randomizations. Depending on the number of measurements in the test phase which will vary based on the test phase start point selected, the experiment could theoretically consist of 104 to 114 trials. This is the design we intend to follow in the final experiment with 30 participants (Figure 2).

\\\\textbf{Figure 2}

\\\\emph{Final Design With 30 Measurements.}

[INSERT FIGURE 2 HERE]

\\\\subsection{Pilot Tests}

As mentioned previously, the initial nine pilot tests resulted in extremely small (and a few negative) effect sizes. The average MD effect size was -0.037, with a maximum of 0.143 and a minimum of -0.400. The low effect sizes indicated that the final design would need a large number of measurements and participants to achieve sufficient power in the RT. The first seven of these pilot tests consisted of 10-20 measurements each, which seemed too few. On the other hand, the last two pilot tests out of these consisted of 238 trials each. The feedback from both the experimenters and participants was that these tests were too long. These results influenced the decision to limit the number of trails to 140, remove irrelevant trial pairs from the baseline phase, and lower the number of acquisition trail pairs in the treatment phase. 

\\\\textbf{Figure 3}

\\\\emph{Plot of Observed Scores Obtained }\\\\emph{From}\\\\emph{ the Initial Nine Participants in the Pilot Tests.}

[INSERT FIGURE 3 HERE]

The later four pilot tests were run using the design parameters we decided on after the power study. The average MD effect size for these participants was 0.057, with a maximum of 0.476 and a minimum of -0.250. Visual analysis (Figure 4) revealed that the first, third, and fourth participant did not seem to show any sign of conditioning. However, the second participant seemed to show significant conditioning effects. This is also confirmed by the MD effect size for the second participant (0.476). Finally, a Monte Carlo RT with 1000 randomizations resulted in a \\\\emph{p}-value of 0.112. Hence, the null hypothesis of the RT could not be rejected at a 5\\\\% level of significance. 

\\\\textbf{Figure 4}

\\\\emph{Plot of Observed Scores Obtained }\\\\emph{From}\\\\emph{ the Final Four Participants in the Pilot Tests.}

[INSERT FIGURE 4 HERE]

\\\\section{Discussion}

The power analysis and pilot test results confirm that the SCE design developed for this study can be effectively used to test the effect of classical conditioning on pain thresholds. The power study provides strong evidence that this design results in sufficient power if the number of measurements and participants are chosen correctly. The results from the final four pilot tests were encouraging. Even though the RT lacked power due to the small number of participants, the \\\\emph{p}-value was low. The visual analysis also seemed to suggest a large effect for at least one participant. 

The final study using this protocol was not conducted immediately, due to lack of resources at the time. However, we hope to conduct this study as soon as the opportunity arises. Meanwhile, it seemed that the discussions regarding the SCE design and preparations for the study might be useful for other researchers developing similar protocols. Therefore, we decided to prepare this manuscript.

The final design suffers from a few limitations. The first limitation is the observed variable defined by us, which only yields values of -1, 0, and 1. Unfortunately, this restricts variation in observed data and can cause duplicates in the randomization distribution, which can affect power. An alternative is to use the difference between SPARS ratings from CS+/ US\\\\textsubscript{test} and CS-/ US\\\\textsubscript{test} trial pairs. However, this would require a slightly different hypothesis, which would not clarify whether classical conditioning can affect pain thresholds specifically.

The second limitation is due to the properties of the AB phase design. RTs using randomization of intervention start points in AB phase designs are known to lack power at lower sample sizes \\\\parencite{Michiels2019}. AB phase designs do not satisfy the guidelines set by Kratochwill et al. \\\\parencite{Kratochwill2010a} without multiple replications. Since we are not sure how quickly the effect of our conditioning is reversed, we cannot use phase designs with more phase changes, such as the ABAB phase design. Due to the requirement of specialized equipment, we cannot use an MBD. Critically, we cannot increase the number of measurements due to time constraints. Therefore, we have to rely on sequential replications for both validity and statistical power. 

The power study for this design also presents certain limitations. We used only one possible distribution of the SPARS ratings to simulate our observed data. While the assumption of a symmetric distribution around 0 is not unreasonable, with more pilot data, it might be possible to simulate using a distribution that resembles the observed data. We also did not account for any variability in effect size across participants. Instead, we simulated an equal effect size for all participants. However, we believe these are reasonable assumptions given the scope of our study. 

Finally, we conducted Monte Carlo RTs for both the power study and the pilot data. As discussed previously, the number of possible randomizations for this design is \\\\emph{r}\\\\textsuperscript{\\\\emph{P}}, where \\\\emph{r} denotes the number of possible randomizations for one participant, and \\\\emph{P} denotes the number of participants. Even for the smaller scale of the pilot data, computing 11\\\\textsuperscript{4} possible randomizations would have been extremely costly. Monte Carlo RTs present a simple alternative to this computation cost while maintaining sufficient statistical power \\\\parencite{Edgington1969, Hope1968}. Hence, we intend to conduct a Monte Carlo RT in the final experiment.

As introduced earlier, this design presents certain advantages over traditional group study designs. Single-case designs are a better match for studying within-person changes, because they allow detailed insight into within-individual processes rather than assuming that the response of all individuals in a group is consistent. Additionally, these designs typically require a smaller number of participants. This allows for a lower overall cost and is particularly important for pain studies because it can be difficult to recruit participants.

\\\\section{Conclusion}

In this manuscript, we described how we used trial and error to design an SCE testing whether classical conditioning can affect pain thresholds. We used a sequentially replicated AB phase design and conducted a simulated power study to determine sample size. We decided on 30 participants and 30 measurements per participant. Finally, we ran some pilot tests using our design. While the results from the pilot tests were inconclusive, they were sufficiently encouraging that we plan to conduct the full study in the near future.

\\\\section{Acknowledgements}

[Deleted for anonymous review]

\\\\section{Data Availability}

The data and R code used in this study are openly available on Open Science Foundation at https://osf.io/d9mfn/?view\\\\_only=6b9bd4580dbf42b4952e551972f48c68.



\\\\section{References}

Adams, D. C., \\\\& Anthony, C. D. (1996). Using randomization techniques to analyse behavioural data. \\\\emph{Animal Behaviour}, \\\\emph{51}(4), 733--738. https://doi.org/https://doi.org/10.1006/anbe.1996.0077

Barlow, D. H., Nock, M. K., \\\\& Hersen, M. (2009). \\\\emph{Single case experimental designs: Strategies for studying behavior change} (3rd ed.). Pearson/Allyn and Bacon.

Bouwmeester, S., \\\\& Jongerling, J. (2020). Power of a randomization test in a single case multiple baseline AB design. \\\\emph{PLoS ONE}, \\\\emph{15}(2), 1--21. https://doi.org/10.1371/journal.pone.0228355

Breivik, H., Collett, B., Ventafridda, V., Cohen, R., \\\\& Gallacher, D. (2006). Survey of chronic pain in Europe: Prevalence, impact on daily life, and treatment. \\\\emph{European Journal of Pain (London, England)}, \\\\emph{10}(4), 287--333. https://doi.org/10.1016/j.ejpain.2005.06.009

Busk, P. L., \\\\& Marascuilo, L. A. (1988). Autocorrelation in single-subject research: A counterargument to the myth of no autocorrelation. \\\\emph{Behavioral Assessment}, \\\\emph{10}(3), 229--242.

Cohen, J. (1988). \\\\emph{Statistical power analysis for the behavioral sciences} (2nd ed.). Routledge. https://doi.org/10.4324/9780203771587

Costa, L. da C. M., Maher, C. G., McAuley, J. H., Hancock, M. J., Herbert, R. D., Refshauge, K. M., \\\\& Henschke, N. (2009). Prognosis for patients with chronic low back pain: Inception cohort study. \\\\emph{BMJ}, \\\\emph{339}, b3829. https://doi.org/10.1136/bmj.b3829

Dancer Design. (n.d.). \\\\emph{Tactor}. http://www.dancerdesign.co.uk/tactor.html

De, T. K., Michiels, B., Tanious, R., \\\\& Onghena, P. (2020). Handling missing data in randomization tests for single-case experiments: A simulation study. \\\\emph{Behavior Research Methods}, \\\\emph{52}(3), 1355--1370. https://doi.org/10.3758/s13428-019-01320-3

De, T. K., Michiels, B., Vlaeyen, J. W. S., \\\\& Onghena, P. (2020). \\\\emph{Shiny SCDA} (Version 2.7). https://ppw.kuleuven.be/mesrg/software-and-apps/shiny-scda

Digitimer Limited. (n.d.). \\\\emph{DS7A High Voltage Constant Current Stimulator}. https://www.digitimer.com/product/human-neurophysiology/peripheral-stimulators/ds7a-ds7ah-hv-current-stimulator/

Edgington, E. S. (1969). Approximate randomization tests. \\\\emph{The Journal of Psychology}, \\\\emph{72}(2), 143--149. https://doi.org/10.1080/00223980.1969.10543491

Edgington, E. S. (1975). Randomization tests for one-subject operant experiments. \\\\emph{Journal of Psychology}, \\\\emph{90}(1), 57. https://doi.org/10.1080/00223980.1975.9923926

Edgington, E. S., \\\\& Onghena, P. (2007). \\\\emph{Randomization tests} (4th ed.). Chapman \\\\& Hall/CRC.

Ferron, J., \\\\& Onghena, P. (1996). The power of randomization tests for single-case phase designs. \\\\emph{Journal of Experimental Education}, \\\\emph{64}(3), 231--239. https://doi.org/10.1080/00220973.1996.9943805

Ferron, J., \\\\& Sentovich, C. (2002). Statistical power of randomization tests used with multiple-baseline designs. \\\\emph{Journal of Experimental Education}, \\\\emph{70}(2), 165--178. https://doi.org/10.1080/00220970209599504

Ferron, J., \\\\& Ware, W. (1995). Analyzing single-case data: The power of randomization tests. \\\\emph{The Journal of Experimental Education}, \\\\emph{63}(2), 167--178.

Fisher, A. J., Medaglia, J. D., \\\\& Jeronimus, B. F. (2018). Lack of group-to-individual generalizability is a threat to human subjects research. \\\\emph{Proceedings of the National Academy of Sciences}, \\\\emph{115}(27), E6106 LP-E6115. https://doi.org/10.1073/pnas.1711978115

Foster, N. E., Anema, J. R., Cherkin, D., Chou, R., Cohen, S. P., Gross, D. P., Ferreira, P. H., Fritz, J. M., Koes, B. W., Peul, W., Turner, J. A., Maher, C. G., Buchbinder, R., Hartvigsen, J., Cherkin, D., Foster, N. E., Maher, C. G., Underwood, M., van Tulder, M., … Woolf, A. (2018). Prevention and treatment of low back pain: Evidence, challenges, and promising directions. \\\\emph{The Lancet}, \\\\emph{391}(10137), 2368--2383. https://doi.org/10.1016/S0140-6736(18)30489-6

Heyvaert, M., \\\\& Onghena, P. (2014a). Analysis of single-case data: Randomisation tests for measures of effect size. \\\\emph{Neuropsychological Rehabilitation}, \\\\emph{24}(3--4), 507--527. https://doi.org/10.1080/09602011.2013.818564

Heyvaert, M., \\\\& Onghena, P. (2014b). Randomization tests for single-case experiments: State of the art, state of the science, and state of the application. \\\\emph{Journal of Contextual Behavioral Science}, \\\\emph{3}(1), 51--64. https://doi.org/10.1016/j.jcbs.2013.10.002

Hope, A. C. A. (1968). A simplified Monte Carlo significance test procedure. \\\\emph{Journal of the Royal Statistical Society. Series B (Methodological)}, \\\\emph{30}(3), 582--598. http://www.jstor.org/stable/2984263

Horner, R. H., Carr, E. G., Halle, J., Mcgee, G., Odom, S., \\\\& Wolery, M. (2005). The use of single-subject research to identify evidence-based practice in special education. \\\\emph{Exceptional Children}, \\\\emph{71}(2), 165--179. https://doi.org/10.1177/001440290507100203

Kazdin, A. E. (2011). \\\\emph{Single-case research designs: Methods for clinical and applied settings} (2nd ed.). Oxford University Press.

Kratochwill, T. R., Hitchcock, J., Horner, R. H., Levin, J. R., Odom, S. L., Rindskopf, D. M., \\\\& Shadish, W. R. (2010). \\\\emph{Single-case design technical documentation}. https://ies.ed.gov/ncee/wwc/Docs/ReferenceResources/wwc\\\\_scd.pdf

Kratochwill, T. R., \\\\& Levin, J. R. (2010). Enhancing the scientific credibility of single-case intervention research: Randomization to the rescue. \\\\emph{Psychological Methods}, \\\\emph{15}(2), 124--144. https://doi.org/10.1037/a0017736

Levin, J. R., Ferron, J. M., \\\\& Gafurov, B. S. (2018). Comparison of randomization-test procedures for single-case multiple-baseline designs. \\\\emph{Developmental Neurorehabilitation}, \\\\emph{21}(5), 290--311. https://doi.org/10.1080/17518423.2016.1197708

Madden, V. J., Bellan, V., Russek, L. N., Camfferman, D., Vlaeyen, J. W. S., \\\\& Moseley, G. L. (2016). Pain by association? Experimental modulation of human pain thresholds using classical conditioning. \\\\emph{Journal of Pain}, \\\\emph{17}(10), 1105--1115. https://doi.org/10.1016/j.jpain.2016.06.012

Madden, V. J., Kamerman, P. R., Bellan, V., Catley, M. J., Russek, L. N., Camfferman, D., \\\\& Moseley, G. L. (2019). Was that painful or nonpainful? The Sensation and Pain Rating Scale performs well in the experimental context. \\\\emph{Journal of Pain}, \\\\emph{20}(4), 472.e1-472.e12. https://doi.org/10.1016/j.jpain.2018.10.006

Madden, V. J., Russek, L. N., Harvie, D. S., Vlaeyen, J. W. S., \\\\& Moseley, G. L. (2017). Classical conditioning fails to elicit allodynia in an experimental study with healthy humans. \\\\emph{Pain Medicine}, \\\\emph{18}(7), 1314--1325. https://doi.org/10.1093/pm/pnw221

Manolov, R., \\\\& Moeyaert, M. (2017). Recommendations for choosing single-case data analytical techniques. \\\\emph{Behavior Therapy}, \\\\emph{48}(1), 97--114. https://doi.org/10.1016/j.beth.2016.04.008

Manolov, R., \\\\& Solanas, A. (2018). Analytical options for single-case experimental designs: Review and application to brain impairment. \\\\emph{Brain Impairment}, \\\\emph{19}(1), 18--32. https://doi.org/10.1017/BrImp.2017.17

Matyas, T. A., \\\\& Greenwood, K. M. (1990). Visual analysis of single-case time series: Effects of variability, serial dependence, and magnitude of intervention effects. \\\\emph{Journal of Applied Behavior Analysis}, \\\\emph{23}(3), 341--351. https://doi.org/10.1901/jaba.1990.23-341

Michiels, B., Heyvaert, M., \\\\& Onghena, P. (2018). The conditional power of randomization tests for single-case effect sizes in designs with randomized treatment order: A Monte Carlo simulation study. \\\\emph{Behavior Research Methods}, \\\\emph{50}(2), 557--575. https://doi.org/10.3758/s13428-017-0885-7

Michiels, B., \\\\& Onghena, P. (2019). Randomized single-case AB phase designs: Prospects and pitfalls. \\\\emph{Behavior Research Methods}, \\\\emph{51}(6), 2454--2476. https://doi.org/10.3758/s13428-018-1084-x

Michiels, B., Tanious, R., De, T. K., \\\\& Onghena, P. (2020). A randomization test wrapper for synthesizing single-case experiments using multilevel models: A Monte Carlo simulation study. \\\\emph{Behavior Research Methods}, \\\\emph{52}(2), 654--666. https://doi.org/10.3758/s13428-019-01266-6

Molenaar, P. C. M., \\\\& Campbell, C. G. (2009). The new person-specific paradigm in psychology. \\\\emph{Current Directions in Psychological Science}, \\\\emph{18}(2), 112--117. https://doi.org/10.1111/j.1467-8721.2009.01619.x

Moseley, G. L., \\\\& Vlaeyen, J. W. S. (2015). Beyond nociception: The imprecision hypothesis of chronic pain. \\\\emph{Pain}, \\\\emph{156}(1), 35--38. https://doi.org/10.1016/j.pain.0000000000000014

Onghena, P. (1992). Randomization tests for extensions and variations of ABAB single-case experimental designs: A rejoinder. \\\\emph{Behavioral Assessment}, \\\\emph{14}(2), 153--171.

Onghena, P. (2005). Single-case designs. In B. Everitt \\\\& D. Howell (Eds.), \\\\emph{Encyclopedia of statistics in behavioral science} (Vol. 4, pp. 1850--1854). John Wiley \\\\& Sons, Ltd. https://doi.org/10.1002/0470013192.bsa625

Ottenbacher, K. J. (1990). When is a picture worth a thousand p values? A comparison of visual and quantitative methods to analyze single subject data. \\\\emph{The Journal of Special Education}, \\\\emph{23}(4), 436--449. https://doi.org/10.1177/002246699002300407

Pavlov, I. P. (1928). \\\\emph{Lectures on conditioned reflexes: Twenty-five years of objective study of the higher nervous activity (behaviour) of animals.} Liverwright Publishing Corporation. https://doi.org/10.1037/11081-000

Smith, J. D. (2012). Single-case experimental designs: A systematic review of published research and current standards. \\\\emph{Psychological Methods}, \\\\emph{17}(4), 510--550. https://doi.org/10.1037/a0029312

Solomon, B. G. (2014). Violations of assumptions in school-based single-case data: Implications for the selection and interpretation of effect sizes. \\\\emph{Behavior Modification}, \\\\emph{38}(4), 477--496. https://doi.org/10.1177/0145445513510931

Spruyt, A., Clarysse, J., Vansteenwegen, D., Baeyens, F., \\\\& Hermans, D. (2009). Affect 4.0: A free software package for implementing psychological and psychophysiological experiments. \\\\emph{Experimental Psychology}, \\\\emph{57}(1), 36--45. https://doi.org/10.1027/1618-3169/a000005

Traxler, J., Madden, V. J., Moseley, G. L., \\\\& Vlaeyen, J. W. S. (2019). Modulating pain thresholds through classical conditioning. \\\\emph{PeerJ}, \\\\emph{2019}(3), 1--20. https://doi.org/10.7717/peerj.6486

Treede, R. D., Rief, W., Barke, A., Aziz, Q., Bennett, M. I., Benoliel, R., Cohen, M., Evers, S., Finnerup, N. B., First, M. B., Giamberardino, M. A., Kaasa, S., Korwisi, B., Kosek, E., Lavand'Homme, P., Nicholas, M., Perrot, S., Scholz, J., Schug, S., … Wang, S. J. (2019). Chronic pain as a symptom or a disease: The IASP classification of chronic pain for the International Classification of Diseases (ICD-11). \\\\emph{Pain}, \\\\emph{160}(1), 19--27. https://doi.org/10.1097/j.pain.0000000000001384

Tsang, A., Von Korff, M., Lee, S., Alonso, J., Karam, E., Angermeyer, M. C., Borges, G. L. G., Bromet, E. J., Demytteneare, K., de Girolamo, G., de Graaf, R., Gureje, O., Lepine, J.-P., Haro, J. M., Levinson, D., Oakley Browne, M. A., Posada-Villa, J., Seedat, S., \\\\& Watanabe, M. (2008). Common chronic pain conditions in developed and developing countries: Gender and age differences and comorbidity with depression-anxiety disorders. \\\\emph{The Journal of Pain}, \\\\emph{9}(10), 883--891. https://doi.org/10.1016/j.jpain.2008.05.005

Vlaeyen, J. W. S., \\\\& Linton, S. J. (2000). Fear-avoidance and its consequences in chronic musculoskeletal pain: A state of the art. \\\\emph{Pain}, \\\\emph{85}(3), 317--332. https://doi.org/10.1016/s0304-3959(99)00242-0

Vlaeyen, J. W. S., \\\\& Linton, S. J. (2012). Fear-avoidance model of chronic musculoskeletal pain: 12 years on. \\\\emph{Pain}, \\\\emph{153}(6), 1144--1147. https://doi.org/10.1016/j.pain.2011.12.009

Vlaeyen, J. W. S., Wicksell, R. K., Simons, L. E., Gentili, C., De, T. K., Tate, R. L., Vohra, S., Punja, S., Linton, S. J., Sniehotta, F. F., \\\\& Onghena, P. (2020). From Boulder to Stockholm in 70 years: Single case experimental designs in clinical research. \\\\emph{The Psychological Record}, \\\\emph{70}, 659--670. https://doi.org/10.1007/s40732-020-00402-5

Vohra, S., Shamseer, L., Sampson, M., Bukutu, C., Schmid, C. H., Tate, R., Nikles, J., Zucker, D. R., Kravitz, R., Guyatt, G., Altman, D. G., \\\\& Moher, D. (2015). CONSORT extension for reporting N-of-1 trials (CENT) 2015 statement. \\\\emph{BMJ (Clinical Research Ed.)}, \\\\emph{350}, h1738. https://doi.org/10.1136/bmj.h1738

Willkinson, L. (1999). Statistical methods in psychology journals: Guidelines and explanations. \\\\emph{American Psychologist}, \\\\emph{54}(8), 594--604. https://doi.org/10.1037/0003-066X.54.8.594

Woolf, C. J. (1983). Evidence for a central component of post-injury pain hypersensitivity. \\\\emph{Nature}, \\\\emph{306}(5944), 686--688. https://doi.org/10.1038/306686a0

Woolf, C. J. (2011). Central sensitization: Implications for the diagnosis and treatment of pain. \\\\emph{Pain}, \\\\emph{152}(3 Suppl), S2--S15. https://doi.org/10.1016/j.pain.2010.09.030





\\\\section{Appendix}

\\\\textbf{Table 2}

\\\\emph{Observed Scores }\\\\emph{From}\\\\emph{ the Initial Nine Pilot Tests.}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c  c}

  P1 & V1 & P2 & V2 & P3 & V3 & P4 & V4 & P5 & V5 & P6 & V6 & P7 & V7 & P8 & V8 & P9 & V9\\\\\\\\
A & 0 & A & 1 & A & 1 & A & 0 & A & NA & A & -1 & A & 0 & A & 1 & A & 0\\\\\\\\
A & 1 & A & 0 & A & 0 & A & 0 & A & 0 & A & 0 & A & 0 & A & 1 & A & 0\\\\\\\\
A & 0 & A & 0 & A & 0 & A & 1 & A & 0 & A & -1 & A & 0 & A & 1 & A & 0\\\\\\\\
A & 0 & A & 0 & A & 0 & A & 1 & A & 0 & A & 1 & A & 0 & A & 1 & A & -1\\\\\\\\
A & 1 & A & 0 & A & 0 & A & -1 & A & 0 & A & 0 & A & 0 & A & 0 & A & 0\\\\\\\\
B & 1 & B & 0 & A & 0 & A & 0 & A & 0 & A & 0 & A & 0 & A & -1 & A & 0\\\\\\\\
B & 1 & B & 0 & A & NA & A & 0 & A & 0 & A & 0 & A & 0 & A & 0 & A & 0\\\\\\\\
B & 0 & B & 0 & A & 1 & A & 0 & A & 0 & B & 0 & B & 0 & A & 0 & A & 1\\\\\\\\
B & 0 & B & -1 & A & 1 & A & 1 & A & 0 & B & 0 & B & 0 & A & 0 & A & 0\\\\\\\\
B & 0 & B & 0 & A & 0 & A & -1 & A & 0 & B & 0 & B & 0 & B & 1 & B & 0\\\\\\\\
  &   &   &   & B & 0 & B & 1 & B & -1 & B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
  &   &   &   & B & NA & B & 0 & B & 0 & B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
  &   &   &   & B & NA & B & 0 & B & 0 & B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
  &   &   &   & B & 0 & B & 0 & B & 0 & B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
  &   &   &   & B & 0 & B & 0 & B & 0 & B & 0 & B & 0 & B & 1 & B & -1\\\\\\\\
  &   &   &   & B & 0 & B & -1 & B & 0 &   &   &   &   & B & 0 & B & 1\\\\\\\\
  &   &   &   & B & 0 & B & 0 & B & 0 &   &   &   &   & B & 0 & B & 0\\\\\\\\
  &   &   &   & B & 0 & B & 1 & B & 0 &   &   &   &   & B & 1 & B & 0\\\\\\\\
  &   &   &   & B & NA & B & 0 & B & 0 &   &   &   &   & B & 1 & B & -1\\\\\\\\
  &   &   &   & B & 1 & B & 1 & B & 0 &   &   &   &   & B & 1 & B & 0\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 0 & B & 1\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 0 & B & 1\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 1 & B & 0\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 1 & B & 0\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 0 & B & 0\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 1 & B & 0\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 0 & B & 0\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 0 & B & 0\\\\\\\\
  &   &   &   &   &   &   &   &   &   &   &   &   &   & B & 0 & B & 0\\\\\\\\


\\\\end{tabular}


\\\\end{table}


\\\\textbf{Table 3}

\\\\emph{Observed Scores }\\\\emph{From}\\\\emph{ the Final Four Pilot Tests Formatted for Shiny SCDA.}


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c  c  c  c}

  P10 & V10 & P11 & V11 & P12 & V12 & P13 & V13\\\\\\\\
A & 1 & A & 0 & A & 0 & A & 0\\\\\\\\
A & NA & A & 0 & A & 0 & A & 0\\\\\\\\
A & 0 & A & 0 & A & 0 & A & 0\\\\\\\\
A & 1 & A & 0 & A & 0 & A & 0\\\\\\\\
A & 0 & A & 0 & A & 0 & A & 0\\\\\\\\
A & 0 & A & 0 & A & 0 & A & 0\\\\\\\\
A & 0 & A & 0 & A & 0 & A & 0\\\\\\\\
A & 1 & A & 0 & A & 0 & A & 0\\\\\\\\
A & -1 & A & 0 & A & 0 & A & 0\\\\\\\\
B & NA & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & NA & B & 1 & B & 0 & B & 0\\\\\\\\
B & NA & B & 0 & B & 0 & B & 0\\\\\\\\
B & NA & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 1 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\
B & 0 & B & 0 & B & 0 & B & 0\\\\\\\\


\\\\end{tabular}


\\\\end{table}










\\\\end{document}
"
`;

exports[`parses correctly for endnote 1`] = `
" \\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{Brown2011,
    title       = {Medication adherence: WHO cares?},
    author      = {Brown, A.D.D.I.N.E.N.R.E.F.L.I.S.T. and T., M. and Bussell, J.K.},
    number      = {4},
    volume      = {86},
    year        = {2011},
    pages       = {304--314},
    journal     = {Mayo Clinical Proceedings}
}


@article{Jungst2019,
    title       = {Medication adherence among patients with chronic diseases: A survey-based study in pharmacies},
    author      = {Jungst, C. and Graber, S. and Simons, S. and Wedemeyer, H. and Lammert, F.},
    number      = {7},
    volume      = {112},
    year        = {2019},
    pages       = {505--512},
    journal     = {QJM: An International Journal of Medicine}
}


@article{Kini2018,
    title       = {Interventions to improve medication adherence: A review},
    author      = {Kini, V. and Ho, P.M.},
    number      = {23},
    volume      = {320},
    year        = {2018},
    pages       = {2461--2473},
    journal     = {The Journal of the American Medical Association}
}


@article{Hartman2021,
    title       = {Medication adherence in older people with rheumatoid arthritis is lower according to electronic monitoring than according to pill count},
    author      = {Hartman, L. and Cutolo, M. and Bos, R. and Opris-Belinski, D. and Kok, M.R. and Griep-Wentink, H. and Klaasen, R. and Allaart, C.F. and Bruyn, G.A.W. and Raterman, H.G. and Voshaar, M.J.H. and Gomes, N. and Pinto, R.M.A. and Klausch, L.T. and Lems, W.F. and Boers, M.},
    year        = {2021},
    journal     = {Rheumatology}
}

\\\\end{filecontents}

\\\\begin{document}

  \\\\section{The GLORIA adherence subproject: problems and randomization mistakes}

Hartman L\\\\textsuperscript{1, 2}, Kok MR\\\\textsuperscript{3}, Molenaar E\\\\textsuperscript{4}, Griep EN\\\\textsuperscript{5}, Van Laar JM\\\\textsuperscript{6}, Van Woerkom JM\\\\textsuperscript{7}, Allaart CF\\\\textsuperscript{8}, Raterman HG\\\\textsuperscript{9}, Ruiterman YPM\\\\textsuperscript{10}, Voshaar MJH\\\\textsuperscript{11}, Redol J\\\\textsuperscript{12}, Pinto RMA\\\\textsuperscript{13}, Klausch LT\\\\textsuperscript{2}, Lems WF\\\\textsuperscript{1}, Boers M\\\\textsuperscript{1, 2}.



\\\\textsuperscript{1}Amsterdam Rheumatology and Immunology Center, Amsterdam UMC, location VUmc, Amsterdam, Netherlands; \\\\textsuperscript{2}Epidemiology \\\\& Data Science, Amsterdam UMC, Vrije Universiteit, Amsterdam, Netherlands; \\\\textsuperscript{3}Department of Rheumatology and Clinical immunology, Maasstad Hospital, Rotterdam, Netherlands;\\\\textsuperscript{ 4} Department of Rheumatology, Groene Hart Hospital, Gouda, Netherlands; \\\\textsuperscript{5}Department of Rheumatology, Antonius Hospital, Sneek, Netherlands; \\\\textsuperscript{6}Department of Rheumatology and Clinical Immunology, University Medical Center Utrecht, Utrecht, Netherlands; \\\\textsuperscript{7}Department of Rheumatology, Gelre Hospitals, Apeldoorn, Netherlands; \\\\textsuperscript{8}Department of Rheumatology, Leids University Medical Center, Leiden, Netherlands; \\\\textsuperscript{9}Department of Rheumatology, Northwest Clinics, Alkmaar, Netherlands;\\\\textsuperscript{ 10}Department of Rheumatology, Haga Hospital, Den Haag, Netherlands; \\\\textsuperscript{11}Tools Patient Empowerment, Amsterdam, Netherlands; \\\\textsuperscript{12}BeyonDevices LDA, Sobral de Monte Agraço, Portugal; \\\\textsuperscript{13}Bluepharma, Indústria Farmacêutica, S.A., Coimbra, Portugal.



\\\\subsection{Take-home message}

It proved difficult to perform a subproject nested within a large investigator-initiated trial, although we expected it to be easy. We recommend keeping a nested subproject simple, maintaining active contact with study centers, and monitoring data from the beginning to resolve emerging problems immediately. 



\\\\subsection{Abstract }

Medication adherence, which is the extent to which patients take their medication as prescribed, is essential in treating chronic inflammatory diseases such as rheumatoid arthritis (RA). Therefore, we nested a subproject in the two-year multicenter Glucocorticoid Low-dose Outcome in Rheumatoid Arthritis (GLORIA) trial to add a low-dose prednisolone (5 mg/day) or placebo to the standard care in older people (≥65 years) with RA. Adherence was measured with an electronic monitoring cap that recorded bottle openings in all patients. In the subproject, we performed an adherence intervention with an advanced cap that could communicate with an application on the smart device via Bluetooth. We randomized patients with a smart device to receive or not to receive adherence reminders on the smart device for three months. Multiple problems emerged that precluded an answer to the research question: sample size (overly optimistic estimates of older patients with a smart device), logistic issues (availability of smartcaps, data extraction), randomization and treatment allocation errors (despite training of personnel), and low quality of the data in the intervention group (hardware failure, discovered too late because data was read in batches). For future trials planning to include a subproject, we recommend keeping it simple, starting with a field test before the actual study starts, and monitoring data from the beginning of the study. 



\\\\subsubsection{Keywords}

Medication adherence, electronic caps, rheumatoid arthritis, nested trial, randomization 



\\\\subsection{Purpose }

The ongoing two-year Glucocorticoid Low-dose Outcome in Rheumatoid Arthritis (GLORIA) trial examines the addition of daily low-dose (5 mg) prednisolone or placebo to the standard care in elderly patients (65+ years) with rheumatoid arthritis; adherence is measured with electronic caps and counting returned pills. A subproject was nested within the main GLORIA trial, limited to patients with a smart device who had taken the study treatment for at least three months. The objective was to test the effectiveness of adherence reminders delivered to the smart device through Bluetooth by a special cap during a three-month period. Eligible patients were randomized to the intervention group (receiving reminders) or the control group (no reminders). In the intervention group, an application was loaded onto the smart device that communicated with the adherence-monitoring device loaded into the cap of the drug bottle. The app sent a reminder message if the patient had forgotten to take the study medication. The hypothesis was that after three months, patients in the intervention group would be more adherent compared to the patients in the control group. Multiple problems prevented us from answering our research question. This paper reflects on these problems. The research group was a part of the GLORIA consortium and was comprised of rheumatologists and researchers from the Netherlands, Germany, Italy, and Portugal, and the owner of the caps and the pharmaceutical manufacturer of the study medication from Portugal.



\\\\subsection{Introduction}

Medication adherence, which is the extent to which patients take their medication as prescribed \\\\parencite{Brown2011}, is essential to treat chronic inflammatory diseases, such as rheumatoid arthritis (RA; Jungst et al., 2019). Almost half of patients with chronic diseases are non-adherent \\\\parencite{Jungst2019, Kini2018}. Non-adherence substantially increases the risk of a disease flare in RA \\\\parencite{Jungst2019}. 



In the two-year multicenter Glucocorticoid Low-dose Outcome in Rheumatoid Arthritis (GLORIA) trial, a low-dose prednisolone (5 mg/day) or placebo was added to the standard care in older people (≥65 years) with RA. We measured adherence with electronic monitoring and pill count in all patients \\\\parencite{Hartman2021}. In a subproject nested within the trial, we assessed the efficacy of an adherence intervention for the patients with a smart device. 



\\\\subsection{Methods}

The eligibility criteria for the subproject were to: be in possession of a smart device (smartphone or tablet) and be an active participant in the main GLORIA trial for at least three months. We planned to include patients with a smart device from all seven participating countries of the main trial because a pilot survey indicated that a sufficient number of patients (20\\\\%) possessed a smart device in all countries. Based on this feasibility assessment, we expected to include 50 patients. 



Before the training of the study personnel, it appeared that only Dutch patients had smart devices. Therefore, the training of the study personnel was only provided in the Netherlands.



\\\\subsubsection{Training of study personnel}

The study personnel of all participating Dutch sites received an e-mail with information about the objective of the subproject, eligibility criteria, signing of the informed consent in duplicate, and an explanation about the randomization step. In addition, the study personnel received a manual that explained the subproject procedures (assembling of the cap, installation of application) that were needed before the patient could start with the subproject. Finally, the subproject and the related procedures were explained and demonstrated during the Dutch GLORIA researchers meeting, and an English instructional movie was sent to all participating centers. One of us (LH) served as the contact person for questions about the subproject.



\\\\subsubsection{Subproject procedure}

Eligible patients were informed about the subproject by the research nurse and were asked to participate. Patients who provided written informed consent were randomly assigned to either the intervention or control group through the electronic case record form (eCRF). All patients continued taking the study medication (one pill per day) from the pill bottle as in the main trial. The opening and closing events of the pill bottle (to measure adherence) were registered by the electronic cap for all patients. Patients in the control group continued their participation in the main study without changes. For patients in the intervention group, several actions of the study personnel were needed. 

The instructions given to study personnel were as follows:

Assembling of smart adherence cap: 

Remove the regular cap from the medication bottle. 

Close the pill bottle with the plastic replacement cap.

Write the kit number of the medication bottle on a label and stick the label inside the smart adherence cap.

Remove the cover of the double-tape on the interior of the smart adherence cap.

Assemble the smart adherence cap over the plastic replacement cap on the medication bottle, correctly aligned, and press it until you reach resistance. Keep it under pressure for at least 3 seconds. 

Installation of the GLORIA app on the smart device of the patient:

Open the Google play store (Android)/AppStore (iOS) application

Search for ‘'GLORIA adherence cap''

Install the app and wait until the installation process has been finished

Open the GLORIA application

Connecting the smart adherence cap and the GLORIA app via Bluetooth by going through multiple steps in the app. (see page 13-19 of appendix for the detailed instruction)



The activated app was connected to the smart adherence cap of the medication bottle via Bluetooth. For patients, no additional actions were required. The patient only had to open the medication bottle once per day, preferably in the morning. Both the regular adherence caps in the control group and the smart adherence caps in the intervention group recorded each opening and closing event of the medication bottle. The smart adherence cap repeatedly attempted to open a connection with the GLORIA app via Bluetooth to report whether the bottle had been opened. If the bottle was not opened between 08:00 a.m. and 02:00 p.m., the app posted a notification on the opening screen to remind the patient to open the medication bottle. The patients in the control group did not receive an activated smart cap nor the reminder app; they were instructed to open the medication bottle once per day, as in the main trial. At the end of the three-month period, the bottle was returned, and the remaining capsules were counted. For patients that started the trial at six months or later, the return of the bottle was delayed by three months, because clinic visits occurred every six months. The adherence of both groups based on returned pills was calculated as follows: If the number of pills dispensed is D, the treatment period in number of days is P, and the number of pills returned is R, medication adherence (\\\\%) is calculated as: ((D-R)/P)*100. The adherence of the two groups was compared. 



Social desirability could have influenced the adherence measurements with the caps and the number of returned pills. Patients might have returned the expected number of pills or opened the medication bottle as would be expected. However, we assume that most patients were as adherent as non-trial patients, because it would be difficult to maintain social desirability during the full two years of the trial. 



\\\\subsubsection{Data registration and extraction}

Apart from the bottle closing and opening events, which were always registered if the medication bottle was opened, the smart adherence caps also registered “pairing success” events, “no communication” events, “keep alive” events and “reset” events. 

The “pairing success” events guaranteed that the pairing of the adherence cap with the app before the study started was successful. Non-registration of this event indicated that the pairing of the cap and app was unsuccessful and that the cap was not able to communicate with the smart device during the entire three months of the study (reported by “no communication” events). Therefore, caps with no “pairing success” event at the start of the study were excluded. 



\\\\subsubsection{“Opening events”}

“No communication” events were registered at 02:00 p.m. if the smart adherence cap had been unable to communicate with the app on the smart device between 08:00 a.m. and 02:00 p.m. on a given day. The time window from 08:00 a.m. until 02:00 p.m. was chosen to match the advice to take prednisolone in the morning. The registration of “no communication” events was independent of the successful or unsuccessful pairing between the app and the cap. The “keep alive” event was used to check if the cap still worked and if the battery was not empty. “Keep alive” events were registered one or more times per morning, indicating that the cap was functioning even if a patient did not open the medication bottle. A “reset” event was registered whenever a reset on the system was detected. This could be related to battery power being too low, or bad contacts on the battery power supply caused by faulty cables due to falls or abrupt movements of the cap. If more than one “reset” event was registered, the cap was excluded. 



The patients returned the regular caps and adherence caps to the research nurse, and the caps of each site were sent to the owner of the caps (BeyonDevices LDA, Sobral de Monte Agraço, Portugal). The data of the caps were read in batches and were uploaded in data files. The data files contained the registration of the events described above. The app generated a reminder message if the cap did not transmit an opening event between 08:00 a.m. and 02:00 p.m., or if no communication was established on that day (registered in the cap). 



\\\\subsection{Discussion}



\\\\subsubsection{Problems in the preparation and execution of the trial}

We had multiple misfortunes related to the preparations of the subproject, technical issues with the app and smart adherence cap, and the randomization step. Therefore, it was not possible to test the effectiveness of adherence reminders delivered via the smart device during the three month trial period. 



We want to discuss and reflect on the problems and misfortunes that prevented us from answering our research question. All aspects that influenced the success of the subproject were discussed, and we reflected on how each aspect contributed to the subproject's failure. 

The discussions and reflections are mainly related to the researchers from the Netherlands, because only Dutch patients entered the subproject. The discussions were supported by the scientific advisory committee, which was set up especially for the GLORIA trial and by the developers of the adherence caps and the GLORIA app.



\\\\subsubsection{1. Preparations}

We had a contract with a company that would deliver the adherence caps and the application for the subproject, but this company went bankrupt a few months before the study would start. We had to choose another company in a very short time frame because the main trial was almost ready to start. This choice was based on expertise, the projected time for development and implementation of the smart device reminder app, and an offer with limited costs because the budget of this investigator-initiated study was limited. Unfortunately, the chosen company needed more time than expected to develop suitable smart caps. In total, this caused a delay of 1.5 years in the delivery of the smart caps.



\\\\subsubsection{2. Sample size}

The number of potential patients for the subproject proved much lower than expected. From initial feasibility assessments among the trial centers, it appeared that around 20\\\\% of the elderly patients possessed a smart device. Assuming that patients with a smart device are technically interested, we expected that about 80\\\\% of them would be willing to participate. Thus, with a sample size of 450 patients in the main study, we expected around 72 patients in the subproject. As it turned out, smart device owners in this senior population were only located in the Netherlands. This resulted in a significant waste of paid and unpaid work hours: The app and instruction manual were translated from English into seven localized versions with the help of the patient panel of the main trial. To include enough patients in the subproject, we amended the protocol so that patients could start with the subproject at any moment during the trial instead of only at the three-months visit. 



\\\\subsubsection{3. Complexities for the participating sites}

The changed inclusion moment for the subproject (as described above) made the inclusion procedure more complex for the participating sites. 

Another potential source of confusion was that we now had two types of similar-looking caps: the regular adherence caps used by all patients throughout the whole main trial, and the smart adherence caps only intended for patients in the intervention group of the subproject. The only difference between the caps was the color of the magnetic label on the cap, which had to be removed to activate the cap. It proved difficult for the research nurses to remember the differences and objectives of the regular and smart adherence caps. 



Also, despite the instructions outlined above, for some study personnel, it was not clear that patients had to be separately randomized for participation in the subproject and that the preparations before participation were different for the patients in the intervention and control group. For the smart adherence caps belonging to the intervention group, several manual actions were needed before the cap could be used. This involved a lot of work if a patient was randomized to the intervention group compared to control patients, where no additional actions were required. 



\\\\subsubsection{4. Randomization and treatment allocation mistakes}

These complexities resulted in mistakes in the randomization and treatment allocation, despite training of the sites. A total of 126 patients in the main trial were assessed for eligibility to participate in the subproject (Figure 1). Most patients were not eligible because they were not in possession of a smart device. From the non-eligible patients, three were nevertheless randomized for the subproject by mistake. The adherence data of these patients could not be used because the patients did not meet the eligibility criteria, did not give informed consent to use their data, or both.



In addition, randomization and treatment allocation failed for many patients because of mistakes at the participating sites and technical problems related to the smart adherence cap. A total of 23 patients received the intervention (smart cap). This included 16 patients that were randomized and properly allocated to the treatment, three patients originally randomized to the control group (contamination), and four patients who received the intervention without being randomized. A total of 19 patients received the control intervention (no reminder). This included 15 patients that were randomized to the control group and were properly allocated to the treatment, one patient originally randomized to the intervention (contamination, the smart adherence cap failed to activate), and three patients who received the control intervention but were not randomized. 



The reasons for the randomization and treatment allocation mistakes are unknown. However, we have some suggestions for changes to the randomization procedure, which might decrease the chance of mistakes. In our study, patients could have been randomized easily to the subproject by first having the patient answer a few questions in a conversation (among others about the possession of a smart device), followed by one click on a button in the eCRF. Entry of ineligible patients could probably have been prevented if the answers to the questions needed to be entered correctly on the screen before randomization and allocation could proceed.



The problem of contamination, i.e., patients randomized to one group but receiving the intervention of the other group, was probably caused by confusion among the research nurses performing the allocation procedure. It is likely that the explanation given to the research nurses about the subproject was insufficient. On-site training could have been better, but this is time-consuming and costly. 



\\\\subsubsection{5. Functioning of smart adherence caps in the intervention group}

Upon delivery, we found the smart adherence caps had technical limitations, but there was no possibility to resolve this limitation by the company. The medication bottle and smart device had to be close to each other to connect and exchange information about the opening events. If the medication bottle and smart device were more than a few meters apart, they did not connect and the patient received a reminder to open the bottle as a consequence. 

Of the 23 smart adherence caps applied, only two caps functioned as expected. The other adherence caps had technical errors from the start of the subproject or within 1-4 weeks after the start, or the caps were not returned (Table 1). 

The malfunctioning of the smart adherence caps in the intervention group was also reflected in the satisfaction rates reported by 18 of the 23 patients. On a scale of 0-10, the mean reported satisfaction rate was 5.6 (range 0-10). Multiple patients gave a low satisfaction rate because they received a reminder despite taking their medication (i.e., opened the bottle). On the other hand, six patients reported a grade of 8 or higher. The malfunctioning of the caps could explain these high rates. The caps did not or rarely communicated with the app and, therefore, the app never sent reminders. This meant that these patients did not receive unnecessary reminders when they opened the bottle. 



\\\\textbf{Table 1.} Functioning of the smart adherence caps in the intervention group of the GLORIA subproject. 


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c  c}

  Functioning of smart adherence cap & Number of patients (\\\\% of patients) & ( & \\\\textbf{n} &  = 23)\\\\\\\\
Good functioning\\\\\\\\
 full 12 weeks &  2  & ( & 9)\\\\\\\\
 6 weeks &  1  & ( & 4)\\\\\\\\
 3-4 weeks &  1  & ( & 4)\\\\\\\\
 2-3 weeks &  1  & ( & 4)\\\\\\\\
 1-2 weeks &  2  & ( & 9)\\\\\\\\
 < 1 week &   & 9 ( & 39)\\\\\\\\
Pairing error  & (no pairing success event registered) &  2  & ( & 9)\\\\\\\\
Cap technical errors  & (reset event registered) &  1  & ( & 4)\\\\\\\\
Cap not returned &   & 4 ( & 17)\\\\\\\\


\\\\end{tabular}


\\\\end{table}


\\\\subsubsection{Data extraction and interpretation}

The data extraction and interpretation had limitations. The data were read in batches when the study was almost finished because it was cheaper to send the caps in batches instead of each single cap from sites in the Netherlands to the company in Portugal. This prevented early detection of errors and malfunctioning. 



The data interpretation was a complicated process. It was difficult to interpret the different events described in the methods section, and to unravel when reminders were sent by the app. This increased the risk of errors in the data interpretation. It would have been easier if the data file had only the opening and closing events, and the exact moments when reminders were sent. Additionally, we had to link the adherence data to the patient data in the eCRF. The kit number belonging to the patient had to be looked up in the eCRF, which also increased the risk of errors. 



\\\\subsection{Conclusion }

We were unable to answer our research question because of a multitude of problems. Even with the limited sample size and randomization and allocation errors, we were initially hopeful that we could compare the adherence of the two groups as a controlled trial instead of a randomized controlled trial. However, the quality of the data in the intervention group was unusable due to almost universal failure of the cap-app dyad. It turned out that it was difficult to perform a subproject nested within a large pragmatic trial, although we expected it to be easy. 



For future trials that test new devices or applications, we strongly recommend a clear plan regarding the requirements. For example, we recommend conducting preliminary field tests to resolve technical problems of the materials, optimize study procedures, and ensure that the plans are clear for all involved parties. The study monitor should also be in active contact with the study centers when the first patients start, to resolve emerging problems in real time and to emphasize the aspects that will help the study perform well. In addition, data stored in the device should be read during rather than after the study. It is also important to be aware that most seemingly “simple” studies are typically complex due to issues with people in different roles, technology, and processes.



\\\\subsection{Acknowledgements}

The GLORIA project was funded by the \\\\emph{European Union's Horizon 2020 Research and Innovation }\\\\emph{Programme} under the topic ‘'Personalizing Health and Care'' (grant number 634886). 

J. W. J. Bijlsma, R. Christensen, Y. M. Smulders and S. H. Ralston are members of the scientific advisory committee of the GLORIA trial. 



\\\\subsection{References}

Brown, M. T. \\\\& Bussell, J. K. (2011). Medication adherence: WHO cares? \\\\emph{Mayo Clinical Proceedings, }\\\\emph{86}(4), 304-314.

Hartman, L., Cutolo, M., Bos, R., Opris-Belinski, D., Kok, M. R., Griep-Wentink, H., Klaasen, R., Allaart, C. F., Bruyn, G. A. W., Raterman, H. G., Voshaar, M. J. H., Gomes, N., Pinto, R. M. A., Klausch, L.T., Lems, W. F., \\\\& Boers, M. (2021). Medication adherence in older people with rheumatoid arthritis is lower according to electronic monitoring than according to pill count. \\\\emph{Rheumatology}.

Jungst, C., Graber, S., Simons, S., Wedemeyer, H. \\\\& Lammert, F. (2019). Medication adherence among patients with chronic diseases: A survey-based study in pharmacies. \\\\emph{QJM: An International Journal of Medicine, }\\\\emph{112}(7), 505-512.

Kini, V. \\\\& Ho, P. M. (2018). Interventions to improve medication adherence: A review. The \\\\emph{Journal of the American Medical Association, }\\\\emph{320}(23), 2461-2473.



\\\\subsection{Appendix}


\\\\begin{figure}

  \\\\includegraphics{media/image1.jpg}
\\\\caption{}
\\\\label{}


\\\\end{figure}


\\\\textbf{Figure}\\\\textbf{ 1.} Flow diagram









\\\\end{document}
"
`;

exports[`parses correctly for nocites 1`] = `
"\\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{Barrington2020,
    author      = {Barrington},
    year        = {2020}
}


@article{Sindall2020,
    title       = {Fail fast, fail forward, fail openly: The need to share failures in development},
    author      = {Sindall, R.C. and Barrington, D.J.},
    number      = {1},
    volume      = {1},
    doi         = {10.36850/ed2},
    year        = {2020},
    pages       = {6--8},
    journal     = {Journal of Trial and Error}
}


@article{Holden2009,
    title       = {People or systems? To blame is human. The fix is to engineer},
    author      = {Holden, R.J.},
    number      = {12},
    volume      = {54},
    year        = {2009},
    pages       = {34--41},
    journal     = {Professional safety}
}


@article{Gilson1996,
    title       = {Coping with complex alarms: Sophisticated aircraft cockpit alarm systems demand a shift in training strategies},
    author      = {Gilson, R.D. and Deaton, J.E. and Mouloua, M.},
    number      = {4},
    volume      = {4},
    doi         = {10.1177/106480469600400404},
    year        = {1996},
    pages       = {12--18},
    journal     = {Ergonomics in Design: The Quarterly of Human Factors Applications}
}


@article{Levin2019,
    title       = {Boeing failed to predict that slew of 737 Max warning alarms would confuse pilots, investigators say},
    author      = {Levin, A.},
    year        = {2019-09-26}
}


@article{Kwok2011,
    title       = {Who would benefit from memory training? A pilot study examining the ceiling effect of concurrent cognitive stimulation},
    author      = {Kwok, T.C. and Chau, W.W. and Yuen, K.S. and Wong, A.Y. and Li, J.C. and Shiu, R.Y. and Ho, F.K.},
    volume      = {6},
    doi         = {10.2147/CIA.S16802},
    year        = {2011},
    pages       = {83--88},
    journal     = {Clinical Interventions in Aging}
}


@article{Traut2021,
    title       = {Why does cognitive training yield inconsistent benefits? A meta-analysis of individual differences in baseline cognitive abilities and training outcomes},
    author      = {Traut, H.J. and Guild, R.M. and Munakata, Y.},
    volume      = {12},
    doi         = {10.3389/fpsyg.2021.662139},
    year        = {2021},
    pages       = {1--20},
    journal     = {Frontiers in psychology}
}


@article{Bevilacqua2018,
    title       = {Human factor risk management in the process industry: A case study},
    author      = {Bevilacqua, M. and Ciarapica, F.E.},
    volume      = {169},
    doi         = {10.1016/j.ress.2017.08.013},
    year        = {2018},
    pages       = {149--159},
    journal     = {Reliability Engineering \\\\& System Safety}
}

\\\\end{filecontents}

\\\\begin{document}

  \\\\section{Systemic Problems in Academia: The Positive Publication Bias and Solutions from a Human Factors Perspective }

\\\\section{1. Introduction}

It will come as no surprise to readers of this journal that failure is systematically ignored in academia. The entire culture of academia revolves around a notion of linear progress made in leaps and bounds by great thinkers, rather than the more realistic image of science as an ongoing process of trial and error. For those already convinced that error deserves a place in scientific discussion, it is often tempting to treat the dismissal of failure as a moral failure on the part of researchers and publishers—if only we were more courageous to do the work that science demands of us, we would publish our failures all the time; if it was not for journals rejecting my work because it is not “innovative” enough, I would tell everyone of my important failures. This perspective, while understandable, misses the mark. Specifically, it neglects the \\\\emph{structure }of modern academia that perpetuates an ideal of “success-first” science on all fronts—a structure, like any structure, that severely limits researchers' and journals' ability to change it. 

This point is described superbly in a recent editorial piece by public health researchers Rebecca Sindall and Dani \\\\parencite{Barrington2020}, who point out the many barriers to sharing and promoting scholarly understandings of failure in the public health interventionist field of Water, Sanitation, and Hygiene (WASH), which they experienced personally as well. 

In their  in the Journal of Trial and Error's (JOTE) first issue, the authors argue not only for the role of researchers themselves in pursuing submission and publication of reports of what went wrong, but also of funding partners in sharing information about projects that did not \\"turn out as planned,\\" and importantly, for the responsibility of journals in welcoming such sort of publications. Critically, they argue that the widespread fixation on “novelty” contributes to a \\"culture of success-ism\\" that is \\"highly unscientific\\". In short, the outward-facing sheen of scientific success—propagated by scientists, funders, and stakeholders alike—challenges the very foundations scientific development is built on: transparency, collaboration, and trial and error.

\\\\parencite{Sindall2020} paint a compelling picture of an academic system that struggles to find a place for failure and the “multitude of sins” such a system necessarily perpetuates. Rightly so, they place the responsibility for change not only on researchers, but also funders and publication bodies. 

But the buck doesn't stop here. The same culture of success-ism that limits researchers limits individual publishers as well. The problem is diffuse and the blame cannot be laid on a single “bad actor”. Accordingly, we feel it pertinent to extend Sindall \\\\& Barrington's argument by highlighting the structural barriers that restrict the spread of failure in the sciences, even at the editorial level. To do so, we use systems theory to frame three limitations journals face when publishing failure and how these limitations cannot simply be solved by good agents engaging in good science. 



\\\\section{2. Failure and Systems }

In the field of Human Factors, and more specifically in Forensic Human Factors, it has long been recognized that failure usually occurs in the complex environment of a system. When accidents such as the Chernobyl nuclear disaster occur, it is easy to shift blame to a single individual or to a single team that was present when mistakes occurred. In response to these disasters, these employees are subsequently reprimanded and sometimes fired. A new person might fill their position and, in some cases, training protocols might be updated. However, these are often very ineffective measures. As previously indicated, mistakes are made in a complex environment. This means that mistakes can have occurred for any number of reasons, and often because of a combination of reasons. Accordingly, removing just one factor from the environment (i.e., the employee present during the disaster) is unlikely to significantly diminish the chances of similar mistakes happening in the future, because it was unlikely to be the determining factor \\\\parencite{Holden2009}. 

Fields such as the aviation industry have long recognized that there are better alternatives to simply replacing or retraining staff following a negative incident. For instance, at the beginning of the proliferation of commercial flights, it became clear that cockpits were often too complicated for pilots to understand, which lead to mistakes being made, and consequently accidents occured. Instead of firing the pilots who made mistakes and/or making small changes to training protocols, the aviation industry started making changes to the cockpits themselves. In other words, the industry transformed the environment, not the agents.

By increasing the simplicity of the cockpit, pilots were less taxed and could invest more cognitive resources towards flying the plane. An example of such an environmental change is the adaptation of cockpit alarms. In older planes, cockpits would have the same audio-visual cues for every alarm. Thus, the pilot got the same feedback from the system when the fuel was slightly low as when an important engine was malfunctioning. Pilots were then mentally taxed on two levels: they were constantly confronted with distracting alarms, some of which might not need their immediate attention; and when attending to these alarms, they had to invest great effort in distinguishing the alarm and assessing its importance. As a result, pilots learned to ignore most alarms. A research article published in 1996 summarized problems such as these at the time as follows: “The proliferation of alarms has led to the increased likelihood of false or multiple alarm events and the consequent inability of the operator to determine the underlying cause of the alarm(s)” \\\\parencite[pp. 12][]{Gilson1996, Levin2019}. 

Faced with the issue of the inattentive pilot, an airline company is presented with two solutions. On the one hand, the company could fire the pilot, hire a new one, and train them for a longer period of time, with a more experienced instructor, and with more expensive training equipment. Besides the fact that this would be very expensive, it would also be unlikely to solve the problem. Humans' cognitive abilities are limited. This is because, like all human systems, their underlying biological systems operate on limited resources. Similarly, in the realms of cognition, some cognitive scientists believe you can train people for things like working memory, sustained attention, selective attention, and other cognitive skills, but all of these will have a natural ceiling—a point beyond which it is almost impossible to progress \\\\parencite{Kwok2011, Traut2021}. 

In short, simply replacing or retraining bad agents doesn't work on its own; we cannot reduce airplane crashes by just getting new and better pilots. As in aviation, the same can be said for scientific publication. The difference, however, as Sindall and Barrington point out, is that we are already in a nosedive when it comes to recognizing and publishing failure in science. 

\\\\section{}

\\\\section{3. Obstacles to Failure}

\\\\section{\\\\textbf{As hinted at in the last section, we do not believe the issues Sandall and Barrigton (2020) bring up can be solved by simply creating better, more failure-friendly, journals. Rather, we argue that these issues are }\\\\emph{\\\\textbf{inherent }}\\\\textbf{in the }\\\\emph{\\\\textbf{structure}}\\\\textbf{ of modern scientific practice. By “structural”, we mean that science as it is currently understood is defined by success; failure is }\\\\emph{\\\\textbf{not scientific}}\\\\textbf{ under the current paradigm. Even when scientific failures are recognized, they are framed within the larger context of long-run success—”failing now to succeed later”—rather than as an integral part of the scientific process in its own right. In this regard, “structural” is quite literal, such that to displace the structure of success that builds up the modern scientific apparatus would mean challenging its integrity to the point of collapse. But where one structure collapses, another is built. The question is whether we need to be so radical. Can journals not simply reform their practices to allow for more diverse results to be published? Do we risk throwing the baby out with the bathwater?}}

\\\\section{\\\\textbf{In this section, we raise the possibility that editorial reform may not be enough, or at least, that it may be very difficult. To do so, we discuss three issues that journals, who wish to publish scientific failure in the current landscape, face. Throughout, we use our experience at JOTE as a touchstone and example for some of these issues. }}

\\\\section{\\\\textbf{}}

\\\\subsection{3.1. Funding}

It is JOTE's mission to promote and normalize the process of failure in science. However, we recognize that actually doing so comes at high costs for new and established journals. As Sindall \\\\& Barrington highlight, scientific funding is a scarce resource. This is true not only for scientists themselves, but for the journals that publish their work; and especially true for journals that are sympathetic to publishing scientific failures. Funding bodies want to support a compendium of amazing, world-changing findings, not a collection of brick-building errors. 

As a result of this scarcity, journals may turn to article processing charges (APCs) as a way to maintain their services. This business-model is effective when the journal can provide services that financially-secure journals cannot (open access, equity, less emphasis on positive results), but becomes intractable when additional social costs are added on top of the economic ones. These social costs refer both to those experienced by the journal—loss of reputation (more on this below), difficulty finding reviewers and submissions, accusations of predation—and by the submitters, who bear the brunt of the cost and, for social reasons (e.g., working at a lesser-known institution, being from a non-Western background, etc.) may be restricted in their available funds. This issue is exacerbated for journals that encourage researchers to publish their failures, which, because of the “culture of success-ism” in academia, is already perceived as a socially costly endeavor. As a result, publishers that aim to counter this culture start off in a precarious position, limited in terms of traditional funding and at a disadvantage in asking would-be authors—who themselves experience the social and professional costs of publishing null results—for support. 

Therefore, journals willing to publish and promote failure in science are left scrounging for funds, often relying on the goodwill of the editorial team to keep them afloat. Alternatively, journals can support the publicizing of failure through the publicizing of success, spinning the failure as an altruistic side-benefit of an otherwise traditional, positive-result-publishing, outlet for scientific advancement. While sometimes the only option, this “failure as an afterthought” mindset often contributes to the very culture of success-ism that the publication of failure in science aims to combat. 



\\\\subsection{3.2. Prestige }

Above and beyond financial stability, journals comfortable with the idea of publishing failure face an uphill battle with their own reputation. While science makes room for failure, a scientific method cannot be said to exist without people enacting it. This so-called scientific method is typically associated with academia, and while Sindall and Barrington are right to encourage people to be more “scientific” by sharing failure, the problem is an academic system that does not. Thus, many would-be authors are disincentivized from submitting their work to failure-friendly journals for fear that publicizing their null, negative, or unclear results would harm their reputation, decrease their chances to acquire funding in the future, and reflect poorly upon them as scientists. This reluctance to submit is a unique challenge that journals who publish failure face. Even positive-results-publishing low impact-factor journals have the benefit—if it can be called one—of researchers submitting their work there after they have exhausted more well-established outlets. In contrast, publishers that want to promote failure find themselves in the awkward position of having to convince researchers to publish their work \\\\emph{at all} (i.e., as opposed to scrapping the whole project), not to mention in their journal, for their peers to see. 

Increasing the prestige of failure would contribute to an increased willingness on the part of academics to send in their failures. Examples of initiatives and changes that can increase the prestige of failure within academia include brilliant failure awards and changes to the priority rule. Brilliant failure awards, like other awards, signal what the awarder considers to be important and/or valuable. The priority rule refers to the tendency within science to award scientists who are the first to make a discovery, usually by giving them credit—for example, in the form of naming a theory or subject matter after them. Implicitly, the priority rule indicates that only the final success is worthy of reward, although this success often hasn't been possible without the failures of others along the way. Changing these incentives can motivate more researchers to publish their failure. 

At the same time, those researchers that do already want to publish about failure often encounter unexpected hurdles in the publication process. If the journal is subscription-based, the readership of an already niche topic—failure within some field of science—is reduced further, rendering the whole exercise much less appealing to the open-minded researcher who wants their failure to be read and understood. Conversely, if the journal is open-access, it is likely to rely on APCs, requiring researchers that send in an article to a journal to pay a fee upon submission. As discussed in the previous section (3.1), with the increasing trend towards open science, APCs are sometimes seen as necessary by open access journals to cover costs. However, these charges selectively disadvantage researchers at less financially prosperous institutions. Often funding to cover high article processing charges is simply not available. This, in turn, prevents researchers in less financially secure situations from sharing their failures.

Sindall and \\\\parencite{Barrington2020} provide several examples from humanitarian aid projects which went wrong. Two relevant cases in South Africa are mentioned, where failures led to a waste of money and physical injuries. Publishing about failure could prevent this from happening again in the future, but only if the relevant people are able to access these publications. In countries with a lower quality of life, the relative difference that can be made to improving quality of life by preventing waste of money and physical injuries is larger. 

It is not only at the submission phase, however, that the culture of success-ism rears its head. Peer reviewers may also be reluctant to contribute their expertise to results that do not reveal some great discovery about their area of study. On the one hand, this is reasonable because experts are busy and unsolicited requests for reviews are often perceived as a nuisance. On the other hand, reviewers' increased willingness to respond to larger-scale positive-publishing journals over smaller-scale negative-publishing ones reflects again the equating of experimental success with prestige—a relationship that undergirds the philosophy of success-ism that journals like JOTE seek to overturn. 

Thus, in addition to battling for financial stability, publishers that seek to promote failure in science struggle to meet publication quotas or rally enthusiasm for publishing in their journal. The culture of success-ism in academia does double duty in this regard, draining failure-friendly journals' wallets and potential contributors.

\\\\subsection{3\\\\textbf{.3. }\\\\textbf{Lack of Training }}

\\\\textbf{}Despite the challenges presented so far in this article, it is clear that not all academics or funders share the same unwavering commitment to success-ism (otherwise we wouldn't be able to publish this editorial). Still, when journals that do promote failure and trial and error become operational, they face the stark realization that neither researchers nor editors nor reviewers are properly equipped to analyze and interpret failure or trial and error. 

Academic training in the sciences, whether it be in experimental design or statistical inference, focuses little on the positive interpretation of negative results. That is, scientists today are unequipped to constructively answer the question “what went wrong?” While more and more spaces are opening up to discuss failure in science, such as the WASH Failures Team created by Sindall and Barrington and others, there remains a lack of knowledge about how to critically evaluate failure in the sciences. This is reflected at all levels of the editorial process, from the submissions themselves,wherein reviewers often struggle to quantify or explain the scientific failure in question, to the peer reviews, wherein peer reviewers are used to critiquing a piece based on its positive contribution to the field rather than its negative influence on well-held ideas or techniques. 

This lack of knowledge about how to critically evaluate failure extends beyond the sciences to many other types of work such as so-called high-risk industries \\\\parencite{Bevilacqua2018}. This lack of knowledge is not due to a lack of literature on the topic. In philosophy, the process of what we have called “trial and error” has been analyzed in a wide range of contexts. In fields like evolutionary epistemology, agnotology, and within the thought experiments of intuition pumps, much attention is paid to the role of trial and error and failure in the process of gaining knowledge. Additionally, a significant part of the field of Human Factors is dedicated to the analysis and prevention of failure—taking into consideration processes of trial and error. The problem doesn't seem to be what knowledge is available, but rather what knowledge is known by the relevant actors and put into practice. 

In one sense, the novelty of interpreting failures in academic practice leads to exciting new horizons where experts are pushed outside their comfort zone and must engage in live, critical, evaluation of data. In another sense, however, this new frontier beckons for structure—structure that can only be achieved through the long-term, symbiotic, practice of conducting and interpreting failed research and the normalization of failure in science.

In the meantime however, the onus of structuring failure falls on the editorial team of any given failure-friendly journal—a difficult and daunting task that may further discourage the widespread publication of scientific failure. Although training can help, it is insufficient on its own; just like with pilots, there is only so much we can cognitively expect from academics. 

\\\\section{}

\\\\section{4\\\\textbf{. }\\\\textbf{Destined to Fail?}}

\\\\textbf{}Sindall and \\\\parencite{Barrington2020} highlight the need for “more structured ways to report on failures” in science. We could not agree more. However, there are very real, structural, limitations from a publisher's perspective that makes this goal very difficult to achieve. Thus, we argue that it is not only that “[j]ournals \\\\emph{want} to publish novel research and failure is too often not seen as novel” (italics added), but that oftentimes doing elsewise is self-destructive. 

That being said, JOTE is in a fortunate position where we have (and continue to) overcome many of the challenges discussed in this editorial. We do so by leaning into our unorthodoxy, embracing failure wholeheartedly and interdisciplinarily, and tirelessly working to draw informative conclusions from inconclusive results. Nevertheless, the question must be asked: “In the current scientific climate, is this model sustainable?” To that, we must answer with a clear “no”. The evidence is clear that failure is required for a healthy science to flourish. The fact that failure has not even yet budded in the sciences highlights the incompatibility of the current model of scientific success and the promotion of scientific failure. 

Rather than aim for a reformed system that accommodates failure, our goal is to help usher in a new system wherein failure is a necessary component in scientific progress and discourse. In other words, JOTE's goal is to become obsolete. That is, one day, we hope that our efforts contribute to the formation of a scientific mainstream that recognizes the integral role that failure plays in the scientific process and actively normalizes its publication. 

But how to achieve this goal? This piece, alongside Sindall and Barrington's, has emphasized the many obstacles that publishers and researchers alike face in the publication and promotion of failure. While it may seem like there is no way out of success-first science, we offer some suggestions here for changes in academia and publishing. In the aviation industry, a nosedived airplane leads to multiple thorough investigations into the circumstances that lead to the problem. This is then followed up with an integral solution, taking into account different factors and their relation to each other. Likewise, in academia and publishing, multiple studies have analyzed the conditions which gave rise to the problem of positive publication bias. Now is the time to start with an integral solution, where instead of tackling positive publication bias from just one angle, researchers, editors, publishers, and managers all work together to solve the problem. In an attempt to facilitate this process, JOTE is increasing its collaborations - for example, by setting up a brilliant failure award at Utrecht University together with Utrecht Young Academy (and hopefully elsewhere), and by providing lunch lectures about failure and uncertainty at University Medical Centers, which we are starting to do with the help of The New Utrecht School. To reflect this shift from mostly publishing to a broader focus, we will launch the Center of Trial and Error—a place where all our activities come together. The long-term goal is to create an academic culture where failure is an accepted part of the scientific process. 

Therefore, while we are flattered by Sindall's and Barrington's (2020) hope that the Journal of Trial and Error won't be the last “outlet for failure”, we certainly hope that we will be the last of our kind. We look forward to the day where founding a journal based only on failure is regarded as just as inane as founding one based solely on success. 

\\\\section{}

\\\\section{References }

Bevilacqua, M., \\\\& Ciarapica, F. E. (2018). Human factor risk management in the process industry: A case study. \\\\emph{Reliability Engineering \\\\& System Safety, 169}, 149-159. DOI: https://doi.org/10.1016/j.ress.2017.08.013



Gilson, R.D., Deaton, J.E., \\\\& Mouloua, M. (1996). Coping with complex alarms: Sophisticated aircraft cockpit alarm systems demand a shift in training strategies. \\\\emph{Ergonomics in Design: The Quarterly of Human Factors Applications, 4}(4), 12-18. https://doi.org/10.1177/106480469600400404



Holden, R. J. (2009). People or systems? To blame is human. The fix is to engineer. \\\\emph{Professional safety, 54}(12), 34-41. 

Kwok, T. C., Chau, W. W., Yuen, K. S., Wong, A. Y., Li, J. C., Shiu, R. Y., \\\\& Ho, F. K. (2011). Who would benefit from memory training? A pilot study examining the ceiling effect of concurrent cognitive stimulation. \\\\emph{Clinical Interventions in Aging, 6}, 83-88. https://doi.org/10.2147/CIA.S16802

Levin, A. (2019, September 26). \\\\emph{Boeing failed to predict that slew of 737 Max warning alarms would confuse pilots, investigators say}. TIME.  

Sindall, R.C., \\\\& Barrington, D.J. (2020). Fail fast, fail forward, fail openly: The need to share failures in development. \\\\emph{Journal of Trial and Error, 1}(1), 6-8. https://doi.org/10.36850/ed2 

Traut, H. J., Guild, R. M., \\\\& Munakata, Y. (2021). Why does cognitive training yield inconsistent benefits? A meta-analysis of individual differences in baseline cognitive abilities and training outcomes.\\\\emph{ Frontiers in psychology, 12}, 1-20. https://doi.org/10.3389/fpsyg.2021.662139





\\\\end{document}
"
`;

exports[`parses correctly for word 1`] = `
" \\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{Author2022,
    author      = {Author},
    year        = {2022}
}


@article{Another1000,
    author      = {Another},
    year        = {1000}
}

\\\\end{filecontents}

\\\\begin{document}

  \\\\parencite{Author2022}



 



\\\\parencite{Another1000}



\\\\section{Bibliography}

Author, A. (2022, 1 1). Title of the thing. (Editor, Ed.) \\\\emph{Journal, 1}(1), 11-12.

Another. (1000). Artikel. \\\\emph{Journal1, 2}(2), 99-104.







\\\\end{document}
"
`;

exports[`parses correctly for zotero 1`] = `
" \\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{March2020,
    author      = {March},
    year        = {2020}
}


@article{Bowden2005,
    title       = {New approaches to demystifying insight},
    author      = {Bowden, E and Jung-Beeman, Mark and Fleck, J and Kounios, J},
    number      = {7},
    volume      = {9},
    doi         = {10.1016/j.tics.2005.05.012},
    year        = {2005-07},
    pages       = {322-328},
    journal     = {Trends in Cognitive Sciences}
}


@article{Jones2003,
    title       = {Testing two cognitive theories of insight.},
    author      = {Jones, Gary},
    number      = {5},
    volume      = {29},
    doi         = {10.1037/0278-7393.29.5.1017},
    year        = {2003},
    pages       = {1017-1027},
    journal     = {Journal of Experimental Psychology: Learning, Memory, and Cognition}
}


@article{Chu2011,
    title       = {Human performance on insight problem solving: A review},
    author      = {Chu, Yun and MacGregor, James N.},
    number      = {2},
    volume      = {3},
    doi         = {10.7771/1932-6246.1094},
    year        = {2011-02-07},
    journal     = {The Journal of Problem Solving}
}


@article{Fleck2013,
    title       = {Insight versus analysis: Evidence for diverse methods in problem solving},
    author      = {Fleck, Jessica I. and Weisberg, Robert W.},
    number      = {4},
    volume      = {25},
    doi         = {10.1080/20445911.2013.779248},
    year        = {2013-06},
    pages       = {436-463},
    journal     = {Journal of Cognitive Psychology}
}


@article{Weisberg2015,
    title       = {Toward an integrated theory of insight in problem solving},
    author      = {Weisberg, Robert W.},
    number      = {1},
    volume      = {21},
    doi         = {10.1080/13546783.2014.886625},
    year        = {2015-01-02},
    pages       = {5-39},
    journal     = {Thinking \\\\& Reasoning}
}


@article{Vallée-Tourangeau2019,
    title       = {Insight out: Making creativity visible},
    author      = {Vallée-Tourangeau, Frédéric and March, Paul L.},
    doi         = {https://doi.org/10.1002/jocb.409},
    year        = {2019},
    journal     = {The Journal of Creative Behavior}
}


@article{Vallée-Tourangeau2020,
    title       = {Mapping systemic resources in problem solving},
    author      = {Vallée-Tourangeau, Frédéric and Vallée-Tourangeau, Gaëlle},
    doi         = {10.1016/j.newideapsych.2020.100812},
    year        = {2020},
    journal     = {New Ideas in Psychology}
}


@article{Vallée-Tourangeau2014,
    title       = {Diagrams, jars, and matchsticks: A systemicist's toolkit},
    author      = {Vallée-Tourangeau, Frédéric and Vallée-Tourangeau, Gaëlle},
    number      = {2},
    volume      = {22},
    doi         = {10.1075/pc.22.2.02val},
    year        = {2014-12-31},
    pages       = {187-205},
    journal     = {Pragmatics \\\\& Cognition}
}


@article{Andriani2017,
    title       = {Measuring exaptation and its impact on innovation, search, and problem Solving},
    author      = {Andriani, Pierpaolo and Ali, Ayfer and Mastrogiorgio, Mariano},
    number      = {2},
    volume      = {28},
    doi         = {10.1287/orsc.2017.1116},
    year        = {2017-04},
    pages       = {320-338},
    journal     = {Organization Science}
}


@article{Kirsh1994,
    title       = {On distinguishing epistemic from pragmatic action},
    author      = {Kirsh, David and Maglio, Paul},
    number      = {4},
    volume      = {18},
    doi         = {10.1207/s15516709cog1804\\\\_1},
    year        = {1994-10},
    pages       = {513-549},
    journal     = {Cognitive Science}
}


@book{Glaser1967,
    title       = {The discovery of grounded theory: Strategies for Qualitative Research},
    author      = {Glaser, Barney and Strauss, Anslem},
    publisher   = {Aldine Publishing Company},
    place       = {New York},
    year        = {1967}
}


@article{Vallée-Tourangeau2020a,
    author      = {Vallée-Tourangeau and March},
    year        = {2020}
}


@article{Grice1975,
    title       = {Logic and conversation},
    author      = {Grice, H.P},
    publisher   = {Aacdemic Press},
    year        = {1975},
    pages       = {41-58},
    journal     = {Speech acts [syntax and semantics 3]}
}


@article{Gozli2017,
    title       = {Behaviour versus performance: The veiled commitment of experimental psychology},
    author      = {Gozli, Davood G.},
    number      = {6},
    volume      = {27},
    doi         = {10.1177/0959354317728130},
    year        = {2017-12},
    pages       = {741-758},
    journal     = {Theory \\\\& Psychology}
}


@article{Arfini2019,
    title       = {Situated ignorance: the distribution and extension of ignorance in cognitive niches},
    author      = {Arfini, Selene},
    doi         = {10.1007/s11229-019-02328-0},
    year        = {2019-07-24},
    journal     = {Synthese}
}


@article{MacGregor2001,
    title       = {Information processing and insight: A process model of performance on the nine-dot and related problems.},
    author      = {MacGregor, James N. and Ormerod, Thomas C. and Chronicle, Edward P.},
    number      = {1},
    volume      = {27},
    doi         = {10.1037//0278-7393.27.1.176},
    year        = {2001},
    pages       = {176-201},
    journal     = {Journal of Experimental Psychology: Learning, Memory, and Cognition}
}


@article{Ormerod2013,
    title       = {Act first, think later: The presence and absence of inferential planning in problem solving},
    author      = {Ormerod, Thomas C. and MacGregor, James N. and Chronicle, Edward P. and Dewald, Andrew D. and Chu, Yun},
    number      = {7},
    volume      = {41},
    doi         = {10.3758/s13421-013-0318-5},
    year        = {2013-10},
    pages       = {1096-1108},
    journal     = {Memory \\\\& Cognition}
}


@article{Wilson2009,
    title       = {How to situate cognition},
    author      = {Wilson, Robert A. and Clark, Andy},
    publisher   = {Cambridge University Press},
    year        = {2009},
    pages       = {55 -78},
    journal     = {The Cambridge handbook of situated cognition}
}

\\\\end{filecontents}

\\\\begin{document}

  











\\\\section{Rewilding Cognition}

\\\\section{Complex Dynamics in Open Experimental Systems}





Wendy Ross\\\\textsuperscript{1,2} and Frédéric Vallée-Tourangeau\\\\textsuperscript{1}



\\\\textsuperscript{1}Kingston University

\\\\textsuperscript{2}London Metropolitan University







Author Note

Address correspondence to Wendy Ross, Psychology Department, London Metropolitan University, 166-220 Holloway Road, N7 8DB; w.ross@londonmet.ac.uk. 



\\\\section{Keywords }

Interactivity, Insight, Thought Experiments, Exaptative Actions, Mixed Methods

\\\\section{Take Home Message }

This report describes a failed experimental manipulation in object-supported problem-solving. Participant footage allows a granular analysis of the reason for this failure. On the basis of this analysis, we conclude that sequestered experimental conditions are unstable and that the environmental resources can obstruct as well as support higher cognitive processes. 

\\\\section{Abstract}

Insight problems are sometimes designed to encourage an incorrect and misleading interpretation that veils a simple answer. The socks problem is one such problem: Given black socks and brown socks in a drawer mixed in a ratio of four to five, how many socks will you have to take out to make sure that you have a pair of the same color? The ratio information is misleading since, with only two colors, pulling three socks will guarantee a matching pair. Recently, Vallée-Tourangeau and \\\\parencite{March2020} offered a distinction between first- and second-order problem-solving: The former proceeds with and through a physical model of the problem, while the latter proceeds in the absence of such interactions with the world, in other words on the basis of mental processes alone. Vallée-Tourangeau and March also proposed a thought experiment, suggesting that the ratio information in the socks problem might be quickly abandoned in a first-order environment, that is, one where participants observe the results of drawing socks out of a bag rather than imagining themselves doing so. We tested this prediction by randomly allocating participants to a low- (second-order) or high- (first-order) interactivity condition. Marginally more participants announced the correct answer within a 5-minute period in the high than in the low condition, although the difference was not significant. Detailed analysis of the video recording revealed the challenges of operationalizing a second-order condition, as participants engaged in dialogical interactions with the experimenter. In addition, the manner in which the high-interactivity condition was designed appeared to encourage the physical reification of the misleading ratio, thus anchoring that information more firmly rather than defusing it through interactivity. We close the paper with some reflections on wide, or systemic, cognition in experimental research on creative problem-solving. 



\\\\section{Purpose }

The socks problem is a riddle commonly employed in research on insight problem-solving. The riddle goes: If you have black socks and brown socks in a drawer mixed in a ratio of four to five, how many socks will you have to take out to make sure that you have a pair of the same color? The ratio information is misleading since, with only two colors, pulling three socks will guarantee a matching pair. One of us (Vallée-Tourangeau) in Vallée-Tourangeau and \\\\parencite{March2020} suggested that placing a participant in a materially rich environment rather than a sequestered one—in other words, giving her socks to test her ideas—would improve the solution rate. We aimed to translate this thought experiment into a physical one. The participants were therefore placed into two experimental conditions, one in which they could draw socks out of a bag to help them discover the answer or one in which they could not, and their performance was measured in terms of success and latency to success. We predicted that interacting with actual socks would lead to a higher level of success in a faster time. The participants were also filmed to facilitate strategy coding to assess if the different material environments prompted different strategies, as also predicted by Vallée-Tourangeau and March. 

\\\\section{Rewilding Cognition: Complex Dynamics in Open Experimental Systems}

\\\\subsection{The Socks Problem}

Insight problems are a class of problems used to investigate non-analytical problem-solving. Some insight problems are formulated in a manner that misleads participants by directing them towards an initial incorrect interpretation, therefore resisting incremental solution strategies. The solution to these problems involves abandoning this erroneous interpretation. The sock problem is a classic insight problem. The participant is asked “If you have black socks and brown socks in a drawer mixed in a ratio of 4 to 5, how many socks will you have to take out to make sure that you have a pair of the same color?” The problem masquerades as a mathematical problem—the conversational pragmatics forefronts the 4:5—but it is misleading information. The answer is three, no matter what the ratio is. It is possible to pull a pair with the first two socks but also to pull a brown and a black, however, the third sock would necessarily have to match with one or the other. The ratio of brown socks to black socks is immaterial and a distraction designed to set the participant on the wrong path. 

Bowden et al. \\\\parencite[323][]{Bowden2005} suggest that this problem is difficult if you approach it mathematically but easier if you use a “what if” strategy: “That is, if the solver asks, ‘What if I take out a black sock then a brown sock? I would only need one more sock of either color to have a pair of the same color'” (p. 323). Jones \\\\parencite[12][]{Jones2003} suggests that: “The insight here involves moving from a representation of the problem based on mathematics to a representation of the problem based on \\\\emph{imagining yourself removing the socks }[emphasis added]” (p. 12). Again, Chu and MacGregor \\\\parencite[211][]{Chu2011} suggest “[t]he problem solver may only have to run through a couple of trials in her head before arriving at the conclusion that, at most, you only need to draw three socks to match a pair” (p. 211). In a later description of Fleck and Weisberg \\\\parencite{Fleck2013}, Weisberg \\\\parencite[32][]{Weisberg2015} noticed some successful participants imagined “taking the socks out of the drawer, and considering the information available at each step” (p. 32).

In other words, while the problem invites an initial mathematical representation, the solution not only requires the participant to see the problem non-mathematically but is likely facilitated when they see themselves in a real-world environment where they can solve it in a trial-and-error way. Already there is a bridge between mental abstraction and embodied experience being posited here—the problem is hard to solve on the basis of “pure” mental processes. Therefore, it seems almost trivial to suggest that placing participants in such a real-world situation would augment problem-solving—rather than the problem-solver imagining herself drawing socks from a bag, she could actually do that. Indeed, this is what one of us predicted in Vallée-Tourangeau and March \\\\parencite[3][]{Vallée-Tourangeau2019}. 

\\\\subsubsection{Imagine a duffle bag with 40 black socks and 50 brown socks. Our participant reads the problem description and is invited to determine how many socks she will have to sample before getting a pair of matching color. She is told she can dig into the bag and pull a few socks, one at a time, to help her solve the problem. The misleading ratio information in the problem description might not attract her attention as much as it would otherwise were she only presented with the riddle without a physical model of the problem. She might not know how to solve the problem; she starts pulling a few individual socks, not strategically, not with a plan in mind, but simply exploring, interacting with the problem and observing results. The misleading ratio information quickly fails to exert any attraction; rather she's looking at the results of her sampling from the bag. She may pull two black socks from the start, tempted to say that the answer might simply be “two”, but realises that she's been lucky, pulls a third one and fourth one, and the solution dawns on her; the solution is distilled through action and results. (p. 826)}

This vignette functioned as an “intuition pump”— however, it is justified both theoretically and in light of the prior theorizing on the routes to solving this particular problem. It supported the argument in the paper that, embedding the problem-solver in an environment where she can interact with objects outside of the body (a first-order environment) is preferable to the “second-order” and sequestered environments normally found in experimental psychology \\\\parencite{Vallée-Tourangeau2020, Vallée-Tourangeau2014}). 

Much research on embedded problem-solvers has a computational focus. Under this framework, the material offloads are only seen as expanding mental workspace and so it follows that they will necessarily have an augmentative effect. However, the thought experiment outlined above introduces a novel and non-computational mechanism through which interactivity with an external representation is beneficial—that of unplanned and aimless fiddling. The sock problem does not require cognitive scaffolding, nor does it require the introduction of novel information to the system, but rather requires the repression of the distracting information. Any benefits yielded by interactivity should result from the shifting of the problem presentation through action and the transfer into a different problem space, away from an arithmetic problem towards a more mundane activity. Consequently, the evidence that could be generated by testing this would strengthen arguments that interactivity is more beneficial than simply acting as a scaffolding extension. 

In other words, in this case, the problem-solving described above does not rely on actions that strategically exploit the environment to support the mental workspace. Rather, it relies on a series of gestures that we have labeled \\\\emph{exaptative}. Exaptation describes the reuse of an existing artifact for a new purpose. It has been suggested that exaptation is an important driver of innovation because it allows for novelty to arise \\\\parencite{Andriani2017}. We borrow the term to refer to actions that have no initial purpose (for example, fiddling) but from which purpose emerges once results are seen. In other words, the purpose of the original action changes. Exaptative actions are different from epistemic or pragmatic actions \\\\parencite{Kirsh1994} because they decenter the cognitive agency—the problem-solver proceeds “not with a plan in mind” (Vallée-Tourangeau and March, \\\\parencite[3][]{Vallée-Tourangeau2019}. —and their purpose changes through action. What makes the case of the sock problem particularly interesting is that actions which have a purposeful intention (say, for example, reifying the ratio) are unlikely to be beneficial in this case. Exaptative actions such as those described in the thought experiments are very different to actions intended to scaffold computations, which are normally investigated in object-supported cognition. Therefore, the claim made in the thought experiment is perhaps stronger than the authors may realize and requires further investigation.

\\\\subsection{The Current Study}

There were two predictions made in Vallée-Tourangeau and \\\\parencite{March2020}. First, that the use of an actual bag of socks will lead to augmented performance, as measured by a higher solution rate. Second, that the way performance would be augmented would feature two components: The first being that the participant would forget the misleading ratio information, and the second being that the participant would be able to view the answer as she pulled socks out of the bag. This clear behavioral process hypothesis has a firm theoretical basis as outlined above. The current study aimed to test both the behavioral and performance hypotheses. 

Participants were presented with a bag containing black and brown socks in a 4:5 ratio (the bag contained 90 socks) and were invited to solve the problem in one of two conditions: In the high-interactivity condition, they could draw the socks from the bag as they saw fit to help them solve the problem, while participants in the low-interactivity condition could look at the bag but not interact with it or its content. The initial study reported here was intended to follow a quantitative to qualitative (QUAN QUAL) analysis plan, but was changed because the experimental manipulation failed. Specifically, we no longer had faith that the low-interactivity condition represented a sequestered environment. In this report, we present the quantitative method and results before moving onto the qualitative phase, which yielded more substantive conclusions. 

There were therefore two formal hypotheses: The first, a performance hypothesis: that a high-interactivity environment would augment problem-solving success. The second, a process hypothesis: that high interactivity would lead participants to (a) disregard the ratio, (b) observe the answer in their actions.

\\\\section{Quantitative Section}

\\\\subsection{Method}

\\\\subsubsection{Participants\\\\footnote{The initial target participant number was 60 to produce an adequate sample size. However, data collection was stopped owing to Covid-19 and the ban on in-person human psychological testing. The decision was made to analyze the quantitative data although it was still underpowered. The subsequent analysis suggests that the quantitative results would have remained broadly the same. }}

Forty-one participants (a mix of undergraduate and postgraduate psychology students) were recruited in exchange for course credits. One participant was excluded for knowing the problem, one for not adhering to the stipulations of having English as a first language, and one because of data loss. This left 38 participants (31 women) with a mean age of 26.28 years (\\\\emph{SD} = 12.14). The participants were assigned in turn to the two conditions. Eighteen participants took part in the low-interactivity condition and 20 participants took part in the high-interactivity condition. 

\\\\subsubsection{Procedure}

Participants were filmed in a purposely-built lab with three in-built cameras to facilitate coding for the behavioral hypothesis. To minimize the differences between the conditions, both high- and low-interactivity conditions had the same initial setup: In both conditions, each participant was presented with a bag of 90 socks, among which were 50 black and 40 brown, and the only difference was that participants in the high-interactivity condition were allowed to pull socks from the bag (see Figure 1). 

\\\\textbf{Figure }\\\\textbf{1}

\\\\paragraph{The Experimental Setup }


\\\\begin{figure}

  \\\\includegraphics{media/image1.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}


\\\\emph{Note.} Participants were given a bag with 50 black socks and 40 brown socks (panel a). The researcher stayed in the room to give instructions and make notes (panel b).

The original instructions ran thus: “If you have a drawer with brown socks and black socks mixed in a ratio of 4:5, how many would you have to pull out in order to guarantee a pair?” The instructions were read aloud to participants. However, after piloting, these needed to be refined and the final instructions ran thus: 

\\\\subparagraph{In this bag are brown socks and black socks in a ratio of 4 brown socks for every 5 black socks… so the ratio of brown socks to black socks is 4 to 5, \\\\emph{is that clear}? What is the minimum number of socks you think you need to take out of the bag at random to be sure you had a pair of either brown sock or back socks, so that is if you were to pull socks out at random from the bag, what is the minimum number of socks that you would need to be sure that you would have one pair, \\\\emph{that's two socks which match in color,} whether that's one pair of brown socks or one pair of black socks.}

Participants were given 5 minutes to answer the problem and they were allowed to make multiple attempts. They were not prevented from speaking to the researcher nor, however, were they requested to follow a think-aloud protocol. The researcher would only answer questions by repeating the relevant part of the instructions. The researcher kept detailed notes while observing the participants; the participants were recorded throughout the study and the videos were later watched and coded. The participants' performance was measured in terms of success and the latency to a correct solution. 

\\\\subsection{Results}

Performance was better in the high-interactivity condition in which 10 participants (or 50\\\\%) solved the problem compared to the low condition in which 7 participants (or 38\\\\%) did so. This difference was not significant, however (\\\\emph{χ²}(1, \\\\emph{N} = 38) = 0.47, \\\\emph{p }= .492, Cramer's V = 0.11). Participants were slower in the high-interactivity condition with an average latency of 116.20 seconds (\\\\emph{SD }= 78.67; although this was skewed by participant 41 who took 297 seconds) than in the low condition (\\\\emph{M} = 103.57 s, \\\\emph{SD} = 48.32, which was skewed by participant 18 who announced the answer immediately, hence with a latency of 0; see Figure 2); this difference was not significant, \\\\emph{t}(15) = 0.38, \\\\emph{p} = .713, Cohen's \\\\emph{d} = 0.19. Removing these two outlying participants, the mean latencies were 96.1 s (\\\\emph{SD} = 49.4) and 120.8 s (\\\\emph{SD} = 17.3) in the high- and low-interactivity conditions respectively (\\\\emph{t}(13) = 1.167, \\\\emph{p} = .264, Cohen's \\\\emph{d} = 0.82).

\\\\subsubsection{}

\\\\subsubsection{Figure 2}


\\\\begin{figure}

  \\\\includegraphics{media/image2.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}
\\\\emph{\\\\textbf{Latency to Solution in Seconds}}





\\\\section{Qualitative Section}

\\\\subsection{Method}

Over the course of the research, it became clear that the experimental manipulation failed and that there were significant procedural and theoretical assumptions and errors. Some were failures in experimental procedures\\\\footnote{In this respect, filming the experimental situation is a useful tool to ensure adherence to a set experimental procedure. In this instance, there was only one researcher but in other cases there may be multiple researchers. Given that we are still unclear of the contextual variables that may influence results (Leonelli, 2018), generating open-ended data is necessary to understand the complexity. } which could be rectified in a second study, but as we will see, others undermined the initial premise of the study and led to the decision to not repeat the study. 

Additionally, the video data suggested that there were underlying patterns from which new knowledge about this problem situation could be deduced beyond that contained within the strictures of the hypothetico-deductive model. In other words, theoretically valid reasons for the practical and experimental failure of the experiment could be seen in the behavior of participants throughout the experimental situation. A decision was made to employ a modified version of Grounded Theory Method (GTM; \\\\parencite{Glaser1967}) with the video data to generate novel theories about problem-solving in this task. Thus, the focus of the research shifted from an experimental manipulation to an observational study assessing qualitatively how participants solve this problem. Consequently, we abandoned the original hypotheses. 

\\\\subsubsection{Analytical Process}

The initial observations generated in vivo were followed up by a close examination of the video data with time-stamped qualitative memos. Conversations were transcribed and time stamped. These observations were then grouped into conceptual categories before the videos were reviewed a second time to substantiate these categories. This iterative process continued through initial drafts of this paper. In tandem with the data analysis carried out through watching the videos, results were discussed between both authors and conceptual categories were refined. 

\\\\subsection{Results}

The initial hypothesis of an augmentative effect of a high-interactivity environment compared to a low-interactivity environment was not sustained. The qualitative analysis detailed below pinpoints why this might be so: Excess environmental information and the encouragement to interact with it reified unhelpful representations. Additionally, a form of \\\\emph{social} and \\\\emph{linguistic} interactivity which focused on the instructions and the researcher replaced the object-based interactivity. The iterative process of discovery emerged more often in this linguistic space than in the space between object and person. This was a form of interactivity that was not accounted for in the rather narrow (and in hindsight naïve) high- and low-interactivity conditions outlined above, and yet it occurred in both experimental conditions and was in part the reason for the inconclusive results and the failed manipulation. 

\\\\subsubsection{Information in the Environment}

The socks problem is a hard one because participants get stuck on the unhelpful ratio. As suggested by \\\\parencite{Vallée-Tourangeau2020a}, ignoring the ratio should lead to participants solving the problem more often and faster because they are not tempted to use inappropriate mathematical formulae. As we have addressed above, this is not an unreasonable assumption. However, the specific hypothesis under exploration, that a high-interactivity environment would increase the number of people who disregard the ratio, was not sustained by an analysis of what people did in this condition; it appeared that the opposite was the case, that a high-interactivity reinforced the unhelpful information. 

There are two ways in which a problem-solver could approach solving a problem using interactivity: The first involves the sort of exaptative actions mentioned in the initial hypothesis, while the second involves using the world to scaffold existing representations. In the case of problems designed to elicit an unhelpful representation, it is plausible that such a representation, when reified, would be harder to disregard. A high-interactivity environment can scaffold unhelpful representations as well as helpful ones.

This reification was clearly in line with evidence in the study reported here: Interactivity allowed participants to represent the ratio in a solid form. Many of them pulled five brown socks from the bag and then four black socks and used these to structure their thoughts, so the ratio became harder to disregard. This was a sensible decision; it is not unreasonable to assume that the information in the problem is important (in terms of conversational pragmatics, it would make little sense to be informed of the ratio if it was not relevant; \\\\parencite{Grice1975}). Therefore, the strategy of reifying the ratios is on the one hand sensible, and paradoxically, on the other hand, makes the problem harder to solve.

However, in addition to allowing the reification of the information in the problem, the presentation of actual socks expanded the amount of information and the number of possible unproductive pathways. Problem-solving in this less controlled environment did not scaffold thought but rather created an additional distraction. Indeed, the concrete anchoring of the problem led people to look at the distribution of socks in the \\\\emph{actual} bag that they had in front of them rather than considering it an abstracted entity. This was true even for those who were in the low-interactivity condition who tended to return their gaze to the bag when thinking. Take for example, participant 36: Figure 3 demonstrates the extent to which she was looking at and into the bag even while not interacting with the socks in it. Throughout the course of the experiment, she looked at the bag and the accompanying finger gestures and mouthing of numbers indicate that she was trying to count the socks that were in it. 

So, rather than supporting problem-solving, the actual physical arrangements of socks added complexity. Participant 26 (low-interactivity) said “Well looking at \\\\emph{this} bag, all the black socks are at the top so it would take a while to get a brown pair” (01:36). Within a traditional problem-solving environment, participants know that they are solving a riddle and that they are in an artificial situation. In this experiment, the artificial, almost school-type problem collapsed with the far too mundane situation of finding a pair of socks. There simply is no “real-world” version of the hypothesized riddle. Somehow, the simplicity of this quotidian activity supported the intractability of the mathematical puzzle: If you want a pair of socks, you get them out of the bag.

\\\\textbf{Figure }\\\\textbf{3 }

\\\\paragraph{The First Minute of Participant 36 Considering the Problem }


\\\\begin{figure}

  \\\\includegraphics{media/image3.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}


\\\\emph{Note}: Stills were taken at the start of the task and every 10 seconds thereafter.



Additional information was deeply unhelpful in this case. When the problem is presented as a verbal riddle, the number of socks is not given; not only is there no way of knowing it, it is also irrelevant. However, when the participants are presented with a bag full of socks and a problem masquerading as a mathematical one, the total number of socks appears to take on more importance, much like the ratio information in the verbal form of the puzzle. In addition, investigating this unproductive cul-de-sac was easier for those in the high-interactivity condition and therefore harder to disregard. Take for example participant 37: After asking for clarification of the problems at 33 seconds into the task, he asked: “How many were there in total?” (00:33). After 58 seconds elapsed, he decided to empty the bag and to count the socks. It is hard to overstate what a poor decision this is (illustrated in Figure 4 where a screenshot was taken every 10 seconds over the following 220 seconds). Perhaps like participant 25, who stated “Ah, that's what I have to do, I have to know how many are in here” (02:15) before tipping the bag out, the participant thought he had solved the “trick”. Whatever the reason, the messiness of tipping out all the socks then counting them and the high time cost meant that he made no progress. This wrong route would not have been possible in a low-interactivity or second-order problem-solving environment, yet again it is important to stress that this is not an illogical decision. 




\\\\begin{figure}

  

\\\\end{figure}
Figure 4

Participant 37 Tidying Socks 




\\\\begin{figure}

  \\\\includegraphics{media/image4.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}


\\\\subsubsection{Note: \\\\emph{Stills were taken at 60 seconds and every 10 seconds thereafter}.}

\\\\subsubsection{}

\\\\subsubsection{Porous Cognitive Boundaries}

Additionally, the video data revealed versions of cognitive interactivity which were not related to the moving of the objects and hence did not feature in the original hypotheses but which which scaffolded the pathway to solution. For instance, the instructions played a critical role in this scaffolding. This was an unintended artifact of the experimental situation and, albeit subsequently serendipitous, an inelegant one. The instructions were given verbally, and the participants were allowed to ask for clarification. The clarification took the form of the experimenter repeating the relevant set of instructions. Thus, what is often unspoken (checking instructions) became a traceable experimental artifact. 

What this underscored was the importance of the instructions to the problem solution. Initially, there was a change made to the instructions, as outlined above, to ensure that all salient information was clearly presented, but this did not change the participants' need for clarification. This clarification revealed two things: First, a consistent epistemic state across participants despite consistent task instructions should not be assumed; second, it was possible to use these clarifications in a trial-and-error way to structure understanding and gain new knowledge. Indeed, the nature of the task requires restructuring the instructions rather than manipulating the visuospatial field. Therefore, it is not unreasonable that the interactivity coalesces on this linguistic plane. 

The verbal nature of the instructions also increased the interaction with the researcher. This was unanticipated in the original research design and invited the researcher into the experimental situation in a way normally avoided in experimental psychology. What these interactions revealed was the need for the participant to seek help from the outside world. Over the course of these interactions, the answer often revealed itself through a gradual recursive dialogical process. Taking for example participant 41 (Table 1), the last minute or so of her problem-solving involved a recursive, back-and-forth between extracting information from the socks that she had in her hand, the instructions, and the researcher through making guesses until she suggested the correct answer. Note how often she looked at the researcher and solicited feedback in the episodes selected. In this case, the playing with socks coupled with the information from the researcher and the redrawing of the epistemic map through the wrong guesses scaffolded the way to a solution. 



Table 1

\\\\paragraph{Participant 41 Solving the Problem }


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c  c}

  04:53 & Pulls out two more - this time both black & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image5.png}
\\\\\\\\
05:07 & \\"This is 8.....\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image6.png}
\\\\\\\\
05:08 & Looks at researcher & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image7.png}
\\\\\\\\
05:14 & Pulls through socks in hands & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image8.png}
\\\\\\\\
05:21 & \\"So I have to pull out a pair?\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image9.png}
\\\\\\\\
05:23 & Researcher repeats instructions\\\\\\\\
05:35 & \\"So I could pull out four socks and then two would be a pair\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image10.png}
\\\\\\\\
05:42 & Researcher repeats request for the  & minimum number & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image11.png}
\\\\\\\\
05:45 & Plays with socks in her hand & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image12.png}
\\\\\\\\
05:50 & \\"Three\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image13.png}
\\\\\\\\
05:57 & Correct explanation\\\\\\\\


\\\\end{tabular}


\\\\end{table}
\\\\emph{Note:} The timestamps for Figure 6 and Figure 7 refer to the time from the start of the instructions.

This was even clearer in the low-interactivity condition where the participants sought out scaffolding more obviously. Take for example, participant 26 in Table 2. This was a low-interactivity participant who uncovered the answer through a series of guesses using the feedback as a scaffold. As she stated clearly when asked if she knows why: \\"When I got to the end I did...when I said two and then I realized...\\" (02:51). The act of saying the word alongside the feedback from the environment scaffolded her understanding. Knowledge was gained when the thought was in the world; even if that realization did not take material form, it was still generated in action, this time the action of guessing. To place the results from this participant in a low-interactivity environment would be misleading even if she did not carry out any actions over objects. 



\\\\textbf{Table 2}

\\\\paragraph{Participant 26 Solving The Problem Through Incremental Guessing }


\\\\begin{table}

  
\\\\begin{tabular}{c  c  c}

  01:18 & \\"Oh what and if I get it right you'll tell me?\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image14.png}
\\\\\\\\
01:21 & \\"Hang on, I don't know how many socks are in the bag?\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image15.png}
\\\\\\\\
01:24 & Looks at researcher expectantly. & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image16.png}
\\\\\\\\
01:27 & \\"So I don't get how the ratio would matter if I don't know how many socks were in the bag....oh. it's just chance isn't it?\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image17.png}
\\\\\\\\
01:36 & \\"Well, looking at the bag actually all the black ones are on top so it might be a while to get a pair of brown ones..\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image18.png}
\\\\\\\\
01:45 & \\"I'm so confused by the question\\" Looks at researcher again & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image19.png}
\\\\\\\\
01:47 & Researcher repeats instructions\\\\\\\\
01:50 & Starts to pull socks; Researcher stops her & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image20.png}
\\\\\\\\
02:03 & Researcher ends instructions\\\\\\\\
02:11 & \\"I'd have to pick 10 socks out\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image21.png}
\\\\\\\\
02:17 & \\"I'd have to pick 8 socks outs\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image22.png}
\\\\\\\\
02:23 & \\"I'd have to pick 20 socks out\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image23.png}
\\\\\\\\
02:32 & \\"I'd have to pick 18 socks out\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image24.png}
\\\\\\\\
02:41 & \\"I'd have to pick 4 socks out\\". Said faster and more determined & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image25.png}
\\\\\\\\
02:44 & \\"2 socks\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image26.png}
\\\\\\\\
02:47 & \\"3 socks\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image27.png}
\\\\\\\\
02:49 & Researcher confirms\\\\\\\\
02:50 & Starts to laugh\\\\\\\\
02:51 & \\"When I got to the end I did...when I said 2 and then I realized....\\" & \\\\caption{}
\\\\label{}
\\\\includegraphics{media/image28.png}
\\\\\\\\


\\\\end{tabular}


\\\\end{table}
\\\\subsection{}

\\\\subsection{Discussion}

The quantitative results were inconclusive. It may be that if the study had reached the anticipated number of 60 participants, they would show a significant augmentative effect of interactivity, but it seems unlikely. Moreover, the cognitive messiness of the procedure would mean that it would be hard to trust that the results reflected the experimental manipulation, that is, one group of participants interacting with the physical model of the problem, and one group interacting with no features of the task environment, including with the researcher! Of course, the problems outlined above would cast the experiment as a failure by the standards of traditional experimental psychology. As argued by Gozli \\\\parencite{Gozli2017}, the experiment in psychology takes the form of rule-governed behavior. In the experiment reported here, the participants did not play by the rules of the experiment, namely to use only mental simulations in the low-interactivity, sequestered condition and to usefully employ the objects in the high-interactivity condition. Thus, the experimental manipulation and the experiment failed. 

It would be possible, of course, to design a low-interactivity task environment where interaction with the experimenter was completely removed beyond the initial task instructions (e.g., the experimenter could walk away from the observation lab and take their notes from the control booth). Accordingly, the high interactivity condition could be designed to force participants to take one sock at a time, instruct them to reflect on what they see, and prompt them to provide an answer to the puzzle after each draw. Such task procedures might improve the operationalization of the levels of interactivity envisaged in Vallée-Tourangeau and March's (2020) original thought experiment. Be that as it may, the data reported here unveil the affordances offered by the elements of the wider system, and the felicitous (such as soliciting feedback dialogically in the low-interactivity condition) and infelicitous outcomes (such as reifying the 4:5 ratio in the high-interactivity condition) that result from the participants' actions. Such an analysis is likely to yield a greater understanding of how problem-solving unfolds in more complex situations. 

The qualitative analysis undertaken here also offers an understanding of the detrimental role that interactivity can play alongside the traditionally-theorized augmentative role. In hindsight, such an effect is theoretically more plausible given an open cognitive system and a non-computational approach. The data presented here suggest that a cognitive system forms around any problem-solver and that once we approach cognition from this systemic perspective, we necessarily introduce multiple shifting parts. Here, when interactivity with the objects proved to be unhelpful, cognition seeped out into the wider system to encompass the interaction with the researcher via the instructions. These observations license two broader comments on the nature of experimental research in interactivity: (a) on problem-solver omniscience and (b) on the inherently contingent nature of wide cognition.

\\\\subsubsection{The Omniscient Problem-Solver}

Problem-solving is broadly the movement from a state of ignorance to a state of knowledge \\\\parencite{Arfini2019}. There are two forms this ignorance can take, ignorance of the process of problem solution or ignorance of the answer. The most efficient pathway to a solution can only be directly and easily enacted when the solution is already known and can be traced backward without the risk of a false start or a complete divergence from the path. This requires foreknowledge of the correct answer, which is a paradoxical situation and assumes an omniscient problem-solver.

For analytical problems, while the answer is unknown, the process of getting to the answer is clear and known. For example, for mental arithmetic, while the problem-solver may not know the solution, they will know the most efficient process and the simple operators to evince it.\\\\footnote{Indeed, the accuracy of the solution is not clear in itself but is predicated on an accurate following of the steps. We only trust an answer to a mental arithmetic problem not because of the answer itself but because we trust in the steps that led to the answer.} These steps will have been predetermined culturally and through personal experience. Therefore, it is likely that the agent will select the correct objects and the correct actions over those objects. This means that an agent-centric model of interactivity should yield supportive empirical data, however, it is unclear how far such a model would extend. In many ill-structured problems or non-analytical problems, the problem-solver is in double ignorance: They do not know the correct solution or the manner of approaching the correct solution. In terms of problem-solving with and through objects, this means that they will not necessarily select the correct objects or actions over them but merely those that satisfy the needs at the time (echoing the Criterion of Satisfactory Progress Theory; \\\\parencite{MacGregor2001, Ormerod2013}. Without omniscience, the problem-solver can make logical and plausible moves that lead them further from the problem solution. 

\\\\subsubsection{Wide Cognition Is Contingent}

The components in complex systems interact in complex ways and the results are emergent and contingent. Pre-specification of underlying causal mechanisms is difficult because adhering to a form of wide cognition (see \\\\parencite{Wilson2009}) means that such pre-specification is necessarily an under-specification: It is impossible to predict in advance which solution routes will be useful, especially if that problem solution is generated by unplanned and exaptative gestures which is more likely in materially rich environments. It suggests that in insight tasks where there is a double ignorance—ignorance of the solution and ignorance of the path to the solution—both the finding of the solution and the path taken become important. 

Interactivity posits that a dynamic relationship with the external world is not only augmentative to cognition processes but necessary. However, experimental research in interactivity does so by paradoxically setting up a low-interactivity condition which admits non-interactive thinking. In this way, it assumes that there is an easy way to compare non-systemic and systemic cognition and that non-systemic cognition can be meaningfully isolated in an experimental psychologist's lab. We suggest that the dualistic assumptions underlying this approach are misguided, as they assume an ideal type of experimental participant can be generated in sequestered experimental conditions. Rather, the evidence we present here suggests a cognitive leakage across both experimental conditions. In the process of operationalizing the so-called low-interactivity condition, the presence of the experimenter offered an external resource with which to scaffold the problem-solving process. The participant naturally transformed a solo and ostensibly unaided effort into a dyadic one. Clearly, the experimenter qua interlocutor was an unrequited conversational partner. Still, in the absence of hard physical or instructional constraints, the participant naturally availed themselves of this resource, bootstrapping the cognitive effort through a dialogue with their reluctant partner. And it is through this dialogue that the participant's hunch underwent many different forms until it was eventually translated into the normative one. These ersatz dialogues offer a telling window on the distributed nature of thinking, in this instance, the distribution over time and the gradual sedimentation through iterative dialogical cycles. The reification of the solution was the product of interactivity despite the experimental procedure.

A systematic approach to cognition requires that every thoughtful (and arguably every non-thoughtful) encounter should be analyzed as part of a system; however, what constitutes part of the system is rarely specified. Vallée-Tourangeau and \\\\parencite{March2020} suggest that a cognitive ecosystem is configured by “the reasoner, the physical reality of the problem, and the action possibilities offered by the external environment” (p. 826). We argue that the data here suggest “the action possibilities offered by the external environment” (p. 826) are broader than whether the problem is represented in movable artifacts or not. Rather, participants actively recruit beyond the resources of interest in the experimental conditions. This means a more granular approach needs to be considered. 

\\\\subsubsection{Conclusion}

The data presented here are not the clean data typically seen in psychological reports of experimental situations. Over the course of the study, a more ethnographic approach to the whole experimental situation provided rich data about different types of interactions that emerged in either a so-called low- or high-interactivity condition. Some aspects are unique to the situation of an exploratory, quasi-pilot study in problem-solving and others are broader reflections on the nature of research in psychology. As we have seen above, the transformation from a sequestered condition to a more “real-life” situation does not necessarily occur without cost and the nature of that cost deserves to be explored. Additionally, it casts doubt on the possibility of creating a fully sequestered condition. Rather, the data presented here suggest that both conditions are porous. 

The failure of the experimental procedure here revealed the difficulty of doing research in open cognitive systems. Traditional methods of assessing embedded or extended cognition are still rooted in a cognitive and computational model of mind and contrast low- and high-interactivity environments to demonstrate an augmentative effect of interactivity. The research presented here suggests that the reality of experimenting in an open system is more complex than is believed. The target problem here was designed as a mental riddle and its transposition to an interactive space offered a telling window onto the disconnect between first- and second-order problem-solving: The task only “works” as a second-order task.

It is tempting to question whether the mental tasks used in traditional cognitive psychology experiments are diagnostic of problem-solving outside of the sequestered laboratory environments in which they are commonly operationalized. We propose, rather, that a research program should develop in parallel to examine the solving of problems which rendered complex not because of their structure but because of their situation. When it comes to problem-solving, we need a wider range of outcome measures to even begin to understand how it unfolds across a range of contexts which requires a combination of qualitative and quantitative work. What we can see here is that the genesis of a new idea involves a transformation, which in turn involves resources; these resources come with a cost, and these transactions leave physical traces which can be mapped. To understand the transformations and transactions, that is, the process through which new ideas are constructed, the analysis must be local and granular. It is our belief that turning to the qualitative in cognitive psychology to complement the quantitative will yield great benefits.

\\\\textbf{}

\\\\textbf{References}

Andriani, P., Ali, A., \\\\& Mastrogiorgio, M. (2017). Measuring exaptation and its impact on innovation, search, and problem solving. \\\\emph{Organization Science}, \\\\emph{28}(2), 320--338. https://doi.org/10.1287/orsc.2017.1116

Arfini, S. (2019). Situated ignorance: The distribution and extension of ignorance in cognitive niches. \\\\emph{Synthese, 198}(12). https://doi.org/10.1007/s11229-019-02328-0

Bowden, E., Jung-Beeman, M., Fleck, J., \\\\& Kounios, J. (2005). New approaches to demystifying insight. \\\\emph{Trends in Cognitive Sciences}, \\\\emph{9}(7), 322--328. https://doi.org/10.1016/j.tics.2005.05.012

Chu, Y., \\\\& MacGregor, J. N. (2011). Human performance on insight problem solving: A review. \\\\emph{Journal of Problem Solving}, \\\\emph{3}(2). https://doi.org/10.7771/1932-6246.1094

Fleck, J. I., \\\\& Weisberg, R. W. (2013). Insight versus analysis: Evidence for diverse methods in problem solving. \\\\emph{Journal of Cognitive Psychology}, \\\\emph{25}(4), 436--463. https://doi.org/10.1080/20445911.2013.779248

Glaser, B., \\\\& Strauss, A. (1967). \\\\emph{The discovery of grounded theory: Strategies for qualitative research}. Aldine Publishing Company.

Gozli, D. G. (2017). Behaviour versus performance: The veiled commitment of experimental psychology. \\\\emph{Theory \\\\& Psychology}, \\\\emph{27}(6), 741--758. https://doi.org/10.1177/0959354317728130

Grice, H. P. (1975). Logic and conversation. In P. Cole \\\\& J. Morgan (Eds.), \\\\emph{Syntax and semantics: Speech acts} (pp. 41--58). Academic Press.

Jones, G. (2003). Testing two cognitive theories of insight. \\\\emph{Journal of Experimental Psychology: Learning, Memory, and Cognition}, \\\\emph{29}(5), 1017--1027. https://doi.org/10.1037/0278-7393.29.5.1017

Kirsh, D., \\\\& Maglio, P. (1994). On distinguishing epistemic from pragmatic action. \\\\emph{Cognitive Science}, \\\\emph{18}(4), 513--549. https://doi.org/10.1207/s15516709cog1804\\\\_1

MacGregor, J. N., Ormerod, T. C., \\\\& Chronicle, E. P. (2001). Information processing and insight: A process model of performance on the nine-dot and related problems. \\\\emph{Journal of Experimental Psychology: Learning, Memory, and Cognition}, \\\\emph{27}(1), 176--201. https://doi.org/10.1037//0278-7393.27.1.176

Ormerod, T. C., MacGregor, J. N., Chronicle, E. P., Dewald, A. D., \\\\& Chu, Y. (2013). Act first, think later: The presence and absence of inferential planning in problem solving. \\\\emph{Memory \\\\& Cognition}, \\\\emph{41}(7), 1096--1108. https://doi.org/10.3758/s13421-013-0318-5

Vallée-Tourangeau, F., \\\\& March, P. L. (2020). Insight out: Making creativity visible. \\\\emph{Journal of Creative Behavior, 54}(4), 824--842. https://doi.org/10.1002/jocb.409

Vallée-Tourangeau, F., \\\\& Vallée-Tourangeau, G. (2014). Diagrams, jars, and matchsticks: A systemicist's toolkit. \\\\emph{Pragmatics \\\\& Cognition}, \\\\emph{22}(2), 187--205. https://doi.org/10.1075/pc.22.2.02val

Vallée-Tourangeau, F., \\\\& Vallée-Tourangeau, G. (2020). Mapping systemic resources in problem solving. \\\\emph{New Ideas in Psychology, 59}. https://doi.org/10.1016/j.newideapsych.2020.100812

Weisberg, R. W. (2015). Toward an integrated theory of insight in problem solving. \\\\emph{Thinking \\\\& Reasoning}, \\\\emph{21}(1), 5--39. https://doi.org/10.1080/13546783.2014.886625

Wilson, R. A., \\\\& Clark, A. (2009). How to situate cognition. In P. Robbins \\\\& M. Ayede (Eds.), \\\\emph{The Cambridge handbook of situated cognition} (pp. 55--78). Cambridge University Press.





\\\\end{document}
"
`;

exports[`parses correctly for zotero-2 1`] = `
" \\\\documentclass{article}
\\\\usepackage[style=apa]{biblatex}
\\\\addbibresource{bibliography.bib}\\\\usepackage{graphicx}\\\\usepackage{hyperref}



\\\\begin{filecontents}{bibliography.bib}

  @article{Gladwin2017,
    title       = {Carryover effects in spatial attentional bias tasks and their relationship to subclinical PTSD symptoms.},
    author      = {Gladwin, Thomas E.},
    number      = {4},
    volume      = {23},
    doi         = {10.1037/trm0000121},
    year        = {2017},
    pages       = {303},
    journal     = {Traumatology}
}


@article{Gladwin2019,
    title       = {Anticipation-specific reliability and trial-to-trial carryover of anticipatory attentional bias for threat},
    author      = {Gladwin, Thomas E. and Figner, Bernd and Vink, Matthijs},
    number      = {7},
    volume      = {31},
    doi         = {10.1080/20445911.2019.1659801},
    year        = {2019-10-03},
    pages       = {750-759},
    journal     = {Journal of Cognitive Psychology}
}


@article{Gladwin2020,
    title       = {Attentional bias for negative expressions depends on previous target location: replicable effect but unreliable measures},
    author      = {Gladwin, Thomas E. and Jewiss, Matt and Vink, Matthijs},
    doi         = {10.1080/20445911.2020.1805453},
    year        = {2020-08-12},
    pages       = {1-11},
    journal     = {Journal of Cognitive Psychology}
}


@article{Gladwin2019a,
    title       = {Trial-to-trial carryover effects on spatial attentional bias},
    author      = {Gladwin, T.E. and Figner, B.},
    volume      = {196},
    doi         = {10.1016/j.actpsy.2019.04.006},
    year        = {2019},
    pages       = {51--55},
    journal     = {Acta Psychologica}
}


@article{Becker2017,
    title       = {The capture of attention and gaze in the search for emotional photographic faces},
    author      = {Becker, Stefanie I. and Dutt, Neelam and Vromen, Joyce M. G. and Horstmann, Gernot},
    number      = {1-3},
    volume      = {25},
    doi         = {10.1080/13506285.2017.1333182},
    year        = {2017-03-16},
    pages       = {241-261},
    journal     = {Visual Cognition}
}


@article{Schubö2006,
    title       = {Detecting emotional faces and features in a visual search paradigm: Are faces special?},
    author      = {Schubö, Anna and Gendolla, Guido H. E. and Meinecke, Cristina and Abele, Andrea E.},
    number      = {2},
    volume      = {6},
    doi         = {10.1037/1528-3542.6.2.246},
    year        = {2006},
    pages       = {246-256},
    journal     = {Emotion}
}


@article{Desimone1995,
    title       = {Neural Mechanisms of Selective Visual Attention},
    author      = {Desimone, Robert and Duncan, John},
    year        = {1995},
    pages       = {30}
}


@article{Anderson2019,
    title       = {On the automaticity of attentional orienting to threatening stimuli.},
    author      = {Anderson, Brian A. and Britton, Mark K.},
    doi         = {10.1037/emo0000596},
    year        = {2019-03-14},
    journal     = {Emotion}
}


@article{MacLeod1986,
    title       = {Attentional bias in emotional disorders.},
    author      = {MacLeod, Colin and Mathews, Andrew and Tata, Philip},
    number      = {1},
    volume      = {95},
    doi         = {10.1037/0021-843X.95.1.15},
    year        = {1986},
    pages       = {15-20},
    journal     = {Journal of Abnormal Psychology}
}


@article{Carretié2014,
    title       = {Exogenous (automatic) attention to emotional stimuli: a review},
    author      = {Carretié, Luis},
    number      = {4},
    volume      = {14},
    doi         = {10.3758/s13415-014-0270-2},
    year        = {2014-12},
    pages       = {1228-1258},
    journal     = {Cognitive, Affective, \\\\& Behavioral Neuroscience}
}


@article{Imhoff2019,
    title       = {Identification and location tasks rely on different mental processes: a diffusion model account of validity effects in spatial cueing paradigms with emotional stimuli},
    author      = {Imhoff, Roland and Lange, Jens and Germar, Markus},
    number      = {2},
    volume      = {33},
    doi         = {10.1080/02699931.2018.1443433},
    year        = {2019-02-17},
    pages       = {231-244},
    journal     = {Cognition and Emotion}
}


@article{Kruijt2018,
    title       = {A Meta-Analysis of Bias at Baseline in RCTs of Attention Bias Modification: No Evidence for Dot-Probe Bias Towards Threat in Clinical Anxiety and PTSD},
    author      = {Kruijt, Anne-Wil and Parsons, Sam and Fox, Elaine},
    year        = {2018},
    pages       = {11},
    journal     = {Journal of Abnormal Psychology}
}


@article{Mogg2017,
    title       = {Attention Bias Modification (ABM): Review of Effects of Multisession ABM Training on Anxiety and Threat-Related Attention in High-Anxious Individuals},
    author      = {Mogg, Karin and Waters, Allison M. and Bradley, Brendan P.},
    number      = {4},
    volume      = {5},
    doi         = {10.1177/2167702617696359},
    year        = {2017-07},
    pages       = {698-717},
    journal     = {Clinical Psychological Science}
}


@article{Schmukle2005,
    title       = {Unreliability of the dot probe task},
    author      = {Schmukle, Stefan C.},
    number      = {7},
    volume      = {19},
    doi         = {10.1002/per.554},
    year        = {2005-12},
    pages       = {595-605},
    journal     = {European Journal of Personality}
}


@article{Staugaard2009,
    title       = {Reliability of two versions of the dot-probe task using photographic faces},
    author      = {Staugaard, Søren Risløv},
    number      = {3},
    volume      = {51},
    year        = {2009},
    pages       = {339-350},
    journal     = {Psychological Science Quarterly}
}


@article{Hedge2018,
    title       = {The reliability paradox: Why robust cognitive tasks do not produce reliable individual differences},
    author      = {Hedge, Craig and Powell, Georgina and Sumner, Petroc},
    number      = {3},
    volume      = {50},
    doi         = {10.3758/s13428-017-0935-1},
    year        = {2018-06},
    pages       = {1166-1186},
    journal     = {Behavior Research Methods}
}


@article{Zvielli2015,
    title       = {Temporal Dynamics of Attentional Bias},
    author      = {Zvielli, Ariel and Bernstein, Amit and Koster, Ernst H. W.},
    number      = {5},
    volume      = {3},
    doi         = {10.1177/2167702614551572},
    year        = {2015-09},
    pages       = {772-788},
    journal     = {Clinical Psychological Science}
}


@article{Carlson2020,
    title       = {The stability and reliability of attentional bias measures in the dot-probe task: Evidence from both traditional mean bias scores and trial-level bias scores},
    author      = {Carlson, Joshua M and Fang, Lin},
    year        = {2020},
    pages       = {13},
    journal     = {Motivation and Emotion}
}


@article{Kruijt2016,
    title       = {Capturing Dynamics of Biased Attention: Are New Attention Variability Measures the Way Forward?},
    author      = {Kruijt, Anne-Wil and Field, Andy P. and Fox, Elaine},
    number      = {11},
    volume      = {11},
    doi         = {10.1371/journal.pone.0166600},
    year        = {2016-11-22},
    pages       = {e0166600},
    journal     = {PLOS ONE}
}


@article{Panksepp2011,
    title       = {What is Basic about Basic Emotions? Lasting Lessons from Affective Neuroscience},
    author      = {Panksepp, Jaak and Watt, Douglas},
    number      = {4},
    volume      = {3},
    doi         = {10.1177/1754073911410741},
    year        = {2011-10},
    pages       = {387-396},
    journal     = {Emotion Review}
}


@article{Carlson2014,
    title       = {Attending to the fear in your eyes: Facilitated orienting and delayed disengagement},
    author      = {Carlson, Joshua M. and Reinke, Karen S.},
    number      = {8},
    volume      = {28},
    doi         = {10.1080/02699931.2014.885410},
    year        = {2014-11},
    pages       = {1398-1406},
    journal     = {Cognition and Emotion}
}


@article{Fox2001,
    title       = {Do threatening stimuli draw or hold visual attention in subclinical anxiety?},
    author      = {Fox, Elaine and Russo, Riccardo and Bowles, Robert and Dutton, Kevin},
    number      = {4},
    volume      = {130},
    doi         = {10.1037/0096-3445.130.4.681},
    year        = {2001},
    pages       = {681-700},
    journal     = {Journal of Experimental Psychology: General}
}


@article{Cane2009,
    title       = {The addiction Stroop task: examining the fast and slow effects of smoking and marijuana-related cues},
    author      = {Cane, Je and Sharma, D and Albery, Ip},
    number      = {5},
    volume      = {23},
    doi         = {10.1177/0269881108091253},
    year        = {2009-07},
    pages       = {510-519},
    journal     = {Journal of Psychopharmacology}
}


@article{Clarke2015,
    title       = {Examining fast and slow effects for alcohol and negative emotion in problem and social drinkers},
    author      = {Clarke, Simon Paul and Sharma, Dinkar and Salter, Daniel},
    number      = {1},
    volume      = {23},
    doi         = {10.3109/16066359.2014.922961},
    year        = {2015-01-30},
    pages       = {24-33},
    journal     = {Addiction Research \\\\& Theory}
}


@article{Waters2005,
    title       = {Generalizability of carry-over effects in the emotional Stroop task},
    author      = {Waters, Andrew J. and Sayette, Michael A. and Franken, Ingmar H.A. and Schwartz, Joseph E.},
    number      = {6},
    volume      = {43},
    doi         = {10.1016/j.brat.2004.06.003},
    year        = {2005-06},
    pages       = {715-732},
    journal     = {Behaviour Research and Therapy}
}


@article{Wilson2007,
    title       = {Carry-over effects of smoking cue exposure on working memory performance},
    author      = {Wilson, Stephen J. and Sayette, Michael A. and Fiez, Julie A. and Brough, Elizabeth},
    number      = {5},
    volume      = {9},
    doi         = {10.1080/14622200701243144},
    year        = {2007-05},
    pages       = {613-619},
    journal     = {Nicotine \\\\& Tobacco Research}
}


@article{Hill2016,
    title       = {Exploring Carry-Over Effects to Elucidate Attention Bias Modification's Mixed Results},
    author      = {Hill, Mackenna and Duval, Elizabeth},
    publisher   = {Journal of Young Investigators},
    year        = {2016-09-01}
}


@article{Hedger2016,
    title       = {Are visual threats prioritized without awareness? A critical review and meta-analysis involving 3 behavioral paradigms and 2696 observers.},
    author      = {Hedger, Nicholas and Gray, Katie L. H. and Garner, Matthew and Adams, Wendy J.},
    number      = {9},
    volume      = {142},
    doi         = {10.1037/bul0000054},
    year        = {2016},
    pages       = {934-968},
    journal     = {Psychological Bulletin}
}


@article{Gladwin2020a,
    title       = {Attentional bias for negative expressions depends on previous target location: Replicable effect but unreliable measures},
    author      = {Gladwin, T.E. and Jewiss, M. and Vink, M.},
    doi         = {10.1080/20445911.2020.1805453},
    year        = {2020},
    pages       = {1--11},
    journal     = {Journal of Cognitive Psychology}
}


@article{Gur2002,
    title       = {A method for obtaining 3-dimensional facial expressions and its standardization for use in neurocognitive studies},
    author      = {Gur, Ruben C. and Sara, Radim and Hagendoorn, Michiel and Marom, Oren and Hughett, Paul and Macy, Larry and Turner, Travis and Bajcsy, Ruzena and Posner, Aaron and Gur, Raquel E.},
    number      = {2},
    volume      = {115},
    doi         = {10.1016/S0165-0270(02)00006-7},
    year        = {2002-04},
    pages       = {137-143},
    journal     = {Journal of Neuroscience Methods}
}


@article{Lundqvist1998,
    title       = {The Karolinska Directed Emotional Faces (KDEF)},
    author      = {Lundqvist and Flykt, A and Ohman, A},
    publisher   = {Stockholm : Department of Neurosciences Karolinska Hospital.},
    year        = {1998}
}


@article{Lang2008,
    title       = {International affective picture system (IAPS) : affective ratings of pictures and instruction manual},
    author      = {Lang, PJ},
    year        = {2008},
    journal     = {Technical Report}
}


@article{Posner1985,
    title       = {Inhibition of return: Neural basis and function},
    author      = {Posner, Michael I. and Rafal, Robert D. and Choate, Lisa S. and Vaughan, Jonathan},
    number      = {3},
    volume      = {2},
    doi         = {10.1080/02643298508252866},
    year        = {1985-08-01},
    pages       = {211-228},
    journal     = {Cognitive Neuropsychology}
}


@article{Duthoo2014,
    title       = {The heterogeneous world of congruency sequence effects: an update},
    author      = {Duthoo, Wout and Abrahamse, Elger L. and Braem, Senne and Boehler, Carsten N. and Notebaert, Wim},
    volume      = {5},
    doi         = {10.3389/fpsyg.2014.01001},
    year        = {2014-09-09},
    journal     = {Frontiers in Psychology}
}


@article{Mogg1998,
    title       = {A cognitive-motivational analysis of anxiety},
    author      = {Mogg, Karin and Bradley, Brendan P.},
    number      = {9},
    volume      = {36},
    doi         = {10.1016/S0005-7967(98)00063-1},
    year        = {1998-09-01},
    pages       = {809-848},
    journal     = {Behaviour Research and Therapy}
}


@article{Gillich2019,
    author      = {Gillich},
    year        = {2019}
}


@article{Ho2019,
    title       = {Moving beyond P values: data analysis with estimation graphics},
    author      = {Ho, Joses and Tumkaya, Tayfun and Aryal, Sameer and Choi, Hyungwon and Claridge-Chang, Adam},
    number      = {7},
    volume      = {16},
    doi         = {10.1038/s41592-019-0470-3},
    year        = {2019-07},
    pages       = {565-566},
    journal     = {Nature Methods}
}


@article{R2020,
    author      = {R},
    year        = {2020}
}


@article{R2014,
    author      = {R},
    year        = {2014}
}

\\\\end{filecontents}

\\\\begin{document}

  \\\\section{Title}

Carryover Effects for Threat in the Dot-Probe Task



\\\\section{Abstract}

Threatening stimuli are often thought to have sufficient potency to bias attention, relative to neutral stimuli. Researchers and clinicians opt for frequently used paradigms to measure such bias, such as the dot-probe task. Bias to threat in the dot-probe task is indicated by a congruency effect i.e., faster responses on congruent trials than incongruent trials (also referred to as attention capture). However, recent studies have found that such congruency effects are small and suffer from poor internal reliability. One explanation to low effect sizes and poor reliability is \\\\emph{carryover effects} of threat -- greater congruency effects on trials following a congruent trial relative to trials following an incongruent trial. In the current study, we investigated carryover effects of threat with two large samples of healthy undergraduate students who completed a typical dot-probe task. Although we found a small congruency effect for fearful faces (Experiment 1, \\\\emph{n} = 241, \\\\emph{d }= 0.15) and a reverse congruency effect for threatening images, (Experiment 2, \\\\emph{n }= 82, \\\\emph{d }= 0.11) whereas no carryover effects for threat were observed in either case. Bayesian analyses revealed moderate to strong evidence in favor of the null hypothesis. We conclude that carryover effects for threat do not influence attention bias for threat. 



\\\\textbf{Keywords:} dot-probe, emotional cues, carryover effects, attention bias, threat







\\\\section{Take-home message}

How is attentional bias to threat influenced by recent events? In the current study, we tested whether bias to threat (in the dot-probe task) is greater when threat cues recently appeared in a target location, relative to when they appeared in a non-target location (otherwise known as a carryover effect for threat). While we did not find carryover effects for threat, we suspect they are possible in other paradigms and that they exist in real-life scenarios. Carryover effects for threat in the dot-probe task are not likely to influence congruency effects.



\\\\section{Purpose }

The objective of this study was to assess whether carryover effects for threat would be observed in the dot-probe task. Related studies have found support for carryover effects for threat \\\\parencite{Gladwin2017, Gladwin2017, Gladwin2019, Gladwin2020, Gladwin2019a}. However, there are several unique elements to the task design and procedure used in these studies that make them difficult to compare to the commonly used dot-probe task (a task often used in applied, clinical, and basic research on emotion processing). Our purpose was to extend these previous studies of carryover effects for threat to the standard dot-probe task.











\\\\section{Do Carryover Effects Influence Attentional Bias to Threat in the Dot-Probe Task?}

Emotional stimuli are thought to receive prioritized processing. Threatening stimuli like angry and fearful facial expressions of emotion often “beat-out” neutral or innocuous objects \\\\parencite{Becker2017, Schubö2006} in the competition over spatial attentional resources \\\\parencite{Desimone1995}. Attentional bias to threat is a topic of research that intersects many domains and is an essential function for a variety of organisms \\\\parencite{Anderson2019}.

One of the most commonly used tasks to assess attentional bias to threat is the dot-probe task \\\\parencite{MacLeod1986}. In a typical dot-probe task, participants search for the location of a target dot and indicate its position (left or right side of the screen) with a corresponding keypress. Immediately prior to the presentation of the target dot, two adjacent cues (one neutral and one threatening cue) are simultaneously presented for a very brief period (e.g., 100 millisecond (ms)). On congruent trials, the dot appears at the location of the threatening cue, whereas on incongruent trials, the dot appears at the location of the neutral cue (see Figure 1A). Each cue is completely irrelevant to the current task demands. And yet, the threatening cue biases attention to a greater extent than the neutral cue, as shown by faster response times (RTs) for congruent trials relative to incongruent trials (for reviews, see \\\\parencite{Carretié2014, Imhoff2019}. This effect is known as a \\\\emph{congruency effect}, or attentional capture by threat or attentional bias to threat.

While congruency effects are often assessed by the dot-probe task \\\\parencite{Kruijt2018, Mogg2017}, they have come under scrutiny for poor internal and test-retest reliability \\\\parencite{Schmukle2005, Staugaard2009}. One root cause of these issues is that difference scores are inherently unreliable \\\\parencite{Hedge2018}. However, some studies have found that attention (and congruency effects) may fluctuate towards and away from threat during the course of an experiment (\\\\parencite{Zvielli2015}. This suggests attention bias variability could be a meaningful element of attention bias. However, these trial-to-trial variability measures appear to be strongly related to general RT variability (\\\\parencite{Carlson2020, Kruijt2016}. Identifying new sources of potential variation—like carryover effects —in the dot-probe task is beneficial because they could be accounted for in future studies.

\\\\section{Carryover Effects}

Suppose that an individual's attention was biased towards a threatening stimulus—like a fearful face—during a congruent trial of a dot-probe task. Such bias could impact the individual's internal state \\\\parencite{Panksepp2011}, priming, or increase their association between the target and the threatening cue, which could subsequently cause them to be more biased towards threat in later trials. A persistent bias for threatening stimuli is quite plausible given that threatening cues can also bring about attentional dwelling towards themselves \\\\parencite{Carlson2014, Fox2001}. In the past, others have found carryover effects in the emotional Stroop \\\\parencite{Cane2009, Clarke2015, Waters2005, Wilson2007} and diagonalized visual probe task \\\\parencite{Gladwin2019, Gladwin2020, Gladwin2019a}. In these tasks, attentional bias to an emotional cue (i.e., difference in RTs between congruent and incongruent trials) is greater when the previous trial is congruent, otherwise known as a \\\\emph{carryover effect , Gladwin2019}.

As for dot-probe studies, however, there is not yet a clear answer on this topic given the very limited number of studies. In one dot-probe study that used threatening faces, no carryover effects were observed \\\\parencite{Hill2016}. In another study, carryover effects were only observed for accuracy measures, and not RTs (for non-face stimuli, \\\\parencite{Gladwin2017}. But these two studies have serious limitations: one used a small sample \\\\parencite{Gladwin2017}, and the other measured carryover effects after attention training was administered \\\\parencite{Hill2016}. Here we improve upon these limitations by examining the same question with a large sample of healthy undergraduate students who completed a typical dot-probe task.

\\\\section{The Current Study}

In the current study, we sought to test carryover effects for threat in the dot-probe task. To test this question, we performed a secondary data analysis on two dot-probe experiments with fearful facial stimuli (Experiment 1) and threatening pictorial stimuli (Experiment 2; AUTHOR, 2020). We consider fearful faces and pictorial images of threat to be threatening because a recent meta-analysis on threat detection examined both of them \\\\parencite{Hedger2016}. Based on previous research \\\\parencite{Gladwin2019a, Gladwin2020a}, we hypothesized that there would be such an influence (as indicated by an interaction between previous trial congruency and current trial congruency). More specifically, we expected that current trial congruency effects would be larger when the previous trial was congruent, relative to when it was incongruent (see Figure 1B). If our hypothesis was confirmed, we would have identified an important source of variability in the dot-probe task. On the other hand, if our hypothesis was not supported, we would conclude that the influence of carryover effects on congruency effects is negligible.

\\\\section{Experiment 1}

\\\\subsection{Methods}

\\\\emph{Participants. }Participants with an overall accuracy below 90\\\\% percent (eight in total) were removed from all analyses, leaving a final sample size of 241 (\\\\emph{M}\\\\textsubscript{\\\\emph{age}} = 21.4, \\\\emph{SD}\\\\textsubscript{\\\\emph{age}} = 4.3; 178 females). The data reported here were acquired during a screening session of a larger study on attention bias modification and brain structure, funded by the National Institute of Mental Health (NCT03092609). A portion of the current sample (\\\\emph{n} = 127) were included in Experiment 1 of \\\\parencite{Carlson2020}. The study was approved by the UNIVERSITY Institutional Review Board. Participants received monetary compensation for their participation.

\\\\emph{Stimuli and Apparatus. }The procedure was administered with a PC and a 16” LCD computer monitor. Stimuli consisted of 20 fearful and neutral grayscale faces of 10 different actors (half female; \\\\parencite{Gur2002, Lundqvist1998}. Fearful faces were rated (1-9, unpleasant to pleasant) as more negative (\\\\emph{M} = 3.83, \\\\emph{SD} = 0.30) than neutral pictures (\\\\emph{M} = 4.45, \\\\emph{SD} = 0.52), \\\\emph{t}(18) = 3.23, \\\\emph{p} = .005, \\\\emph{d} = 1.48. Faces subtended a visual width and height of 5 × 7 and the distance between the center of each face subtended 14.

\\\\textbf{[Insert Figure 1 here]}

\\\\emph{Design. }The experiment consisted of five blocks of trials and each block consisted of 90 trials for a total of 450 trials. 30 congruent, 30 incongruent, and 30 baseline trials were randomly presented within each block. During baseline trials, two neutral faces were shown in the cue display and the dot was randomly presented in the same position as one of the two neutral faces (one third of all trials). Baseline trials were not included in our analyses. See Figure 1A for examples of incongruent and congruent trials.

\\\\emph{Procedure. }Each trial started with a white fixation cross (+) in the center of a black screen for 1000 ms, which was immediately followed by the cue display. The cue display was presented for 100 ms. In the cue display, there were two bilaterally presented faces. Immediately following the cue display, a single dot (the target object) was randomly presented in the central position of one of the previously shown faces in the cue display until participants responded. Participants indicated the location of the dot (left or right side of the display) by pressing a corresponding button with the pointer or middle finger of their right hand.

\\\\section{Results}

All trials with an incorrect response (2.2\\\\% of trials) or a response time outside of 3 standard deviations from the individual-wise and condition means were removed from all RT analyses (0.6\\\\% of trials). Attentional bias was measured by subtracting mean RTs for congruent trials from incongruent trials. Positive values indicate the level of attentional bias for fearful faces. All analyses were not pre-registered but were pre-planned. As shown in Figure 2A, RTs for congruent trials (\\\\emph{M = }331 ms, \\\\emph{SD} of 72 ms) were significantly shorter for incongruent trials (\\\\emph{M = }342 ms, \\\\emph{SD} of 72 ms), \\\\emph{t}(240) = 20.56, \\\\emph{p} < .001, \\\\emph{d }= 0.16. A congruency effect was also found for percent correct (1.5\\\\%), \\\\emph{t}(240) = 14.31, \\\\emph{p} < .001, \\\\emph{d }= 0.11.

As shown in Figure 2B, carryover effects are measured as the interaction between previous trial congruency (pre-congruent or pre-incongruent) and current trial congruency (congruent or incongruent). The location of the fearful face and the target could repeat from trial to trial, so we further separated carryover effects by target location repetition. We examined target location repetition for two reasons: (a) it is an exploratory approach to analyzing carryover effects and (b) previous studies on carryover effects \\\\parencite{Gladwin2019a} have deliberately prevented cue and target locations repetitions trial-to-trial. We tested for the presence of carryover effects by conducting a 2 × 2 × 2 Generalized Linear Mixed Model (GLMM) with the random effect of subject and the fixed effects of current trial congruency (congruent or incongruent), previous trial congruency (pre-congruent or pre-incongruent) and target location repetition (repeated or non-repeated) on single trial RTs using a Gamma probability distribution with a log link, which accounts for the slightly positive skew of the data\\\\footnote{We also tested a model with a random slope for congruency x previous congruency x target location repetition interaction. Although this model fit our data better (AIC\\\\textsubscript{without random slope} = -26903.474 whereas AIC\\\\textsubscript{with random slope} = -27133.846;models with smaller AIC values fit better), the significant levels of all the fixed effects for this model was very similar to the one reported in the main text, where there was no significant carryover effect.}. Target location repetition was included in the model because previous studies of carryover effects deliberately chose to prevent target locations repetition between trials \\\\parencite{Gladwin2019a}, which leaves open the possibility that target repetition may moderate carryover effects. Similar to the t-test reported above, there was a main effect of current trial type, \\\\emph{F}(1, 46115) = 348.91, \\\\emph{p }< .001: RTs were faster on congruent (\\\\emph{M }= 329, \\\\emph{SD}\\\\emph{ }= 68) relative to incongruent (\\\\emph{M }= 339, \\\\emph{SD }= 69) trials. There was also a main effect of target location repetition (\\\\emph{F}(1, 46115) = 222.06, \\\\emph{p }< .001) wherein RTs were faster for non-repeated target locations (\\\\emph{M }= 330, \\\\emph{SE }= 2.32) relative to repeated locations (\\\\emph{M }= 338, \\\\emph{SE }= 2.38). There was also an interaction between target location repetition and previous trial congruency (\\\\emph{F}(1, 46115) = 6.08, \\\\emph{p }= .01) such that RTs for non-repeated target locations were faster if the previous trial was congruent (\\\\emph{M }= 329, \\\\emph{SE }= 2.34) relative to incongruent (\\\\emph{M }= 331, \\\\emph{SE }= 2.36). Meanwhile, for repeated target location there was no statistically significant difference in RTs between trials where the previous trial was congruent (\\\\emph{M }= 339, \\\\emph{SE }= 2.42) relative to incongruent (\\\\emph{M }= 338, \\\\emph{SE }= 2.42). Critically, neither the 2-way interaction between current trial congruency and previous trial congruency (\\\\emph{F}(1, 46115) = 0.59, \\\\emph{p }= .44) nor the 3-way interaction (\\\\emph{F}(1, 46115) = 0.84, \\\\emph{p }= .36) were significant, indicating that no carryover effects were observed. No other effects were significant.

We followed up the GLMM approach with a Bayesian analysis. Given that there were no clear prior probabilities based on previous research, a diffuse (or uninformative) prior was used in SPSS to quantify evidence for the null hypothesis that there is no carryover effect for threat. A Bayes Factor analysis on a related-sample t-test indicated moderate evidence for the null hypothesis (BF01 = 5.38). In other words, the data is 5.38 times as likely under the null hypothesis than under the alternative hypothesis (i.e., that there is an influence of previous trial congruency on current trial congruency). 

\\\\section{Experiment 2}

\\\\textbf{}In Experiment 2, our goal was to replicate and extend our lack of carryover effects with another category of threatening stimuli: threatening images \\\\parencite{Lang2008}. We used data from Experiment 2 of \\\\parencite{Carlson2020}. The method for Experiment 2 is the same as Experiment 1 except for the following.

\\\\subsection{Method}

\\\\emph{Participants. }Participants with an overall accuracy below 90\\\\% percent (4 in total) were removed from all analyses, leaving a final sample size of 82 (\\\\emph{M}\\\\textsubscript{\\\\emph{age}} = 20, \\\\emph{SD}\\\\textsubscript{\\\\emph{age}} = 2.2; 61 females). 

\\\\emph{Stimuli and Apparatus. }The visual angle between the two stimuli presented in the cue display subtended a visual angle of 12°. The images used in the cue display were taken from the International Affective Picture System (IAPS; \\\\parencite[200][]{Lang2008}. 10 threatening and 10 neutral images were used, and the cue display was shown for 500 ms. 

\\\\subsection{Results}

Outlier RT trials were removed from all analyses (0.5\\\\% of trials). To test for carryover effects, we conducted the same 2 × 2 × 2 Generalized Linear Mixed Model on RTs as in Experiment 1. There was a main effect of current trial type (\\\\emph{F}(1, 15869) = 16.21, \\\\emph{p }< .001) wherein RTs were faster for incongruent (\\\\emph{M }= 345 , \\\\emph{SE }= 4.06) relative to congruent trials (\\\\emph{M }= 349, \\\\emph{SE }= 4.11). Note that this effect indicates attentional bias to neutral, not threatening images, (see Figure 2C) which also might indicate for threatening images. There was also a main effect of target location repetition, \\\\emph{F}(1, 15869 = 167.53, \\\\emph{p }< .001), wherein RTs were faster for trials with non-repeated target locations (\\\\emph{M }= 340, \\\\emph{SE }= 4.00) compared to repeated locations (\\\\emph{M }= 354, \\\\emph{SE }= 4.17). However, as in Experiment 1, neither the 2-way interaction between current trial congruency and previous trial congruency (\\\\emph{F}(1, 15869) = 0.53, \\\\emph{p }= .47) nor were the 3-way interactions (\\\\emph{F}(1, 15869) = 0.01, \\\\emph{p }= .92) significant (see Figure 2D). Thus, no carryover effects were observed. In addition, no other effects were significant. We again followed up the GLMM approach with the same Bayesian analysis. For Experiment 2, we found strong evidence for the null hypothesis (BF01 = 11.27) indicating that the data are 11.27 times more likely under the null hypothesis than under the hypothesized existence of a carryover effect for threat. 

\\\\textbf{[Insert Figure 2 Here]}

\\\\section{Discussion}

In two dot-probe experiments, we assessed whether attentional bias to fearful faces (Experiment 1) or threatening images (Experiment 2) would be influenced by carryover effects. Given that threatening stimuli are especially salient, their potential trial-to-trial influence on attention is quite plausible. However, the evidence supporting carryover effects for threat has been insufficient to rule out the influence of carryover effects \\\\parencite{Gladwin2019a, Hill2016}. In Experiment 1, while we did observe a small sized congruency effect for fearful faces, we did not find an interaction between current trial congruency and previous trial congruency. Even for non-repeating target location trials (see Figure 1B), we found no such interaction. There are multiple potential explanations for faster responses on non-repeating target location trials. One is that participants strategically attend away from the emotional cue. Another possibility is that participants avoid previous target locations, as explained by inhibition of return \\\\parencite{Posner1985}. Lastly, our non-significant carryover effects for threat were replicated in Experiment 2. The results from our Bayesian analyses showed moderate to strong evidence for this null result. 

The lack of carryover effects we observed is consistent with previous statistical findings from other dot-probe studies \\\\parencite{Gladwin2017, Hill2016, Hill2016}. These previous studies, when combined with the current findings, strongly suggest that attentional bias for threat in dot-probe tasks (congruent-incongruent) is unlikely to be moderated by carryover effects. Our study improved upon the limitations of these previous studies: we used a very large sample in Experiment 1, and did not administer any prior-experimental manipulations (like attentional training in \\\\parencite{Hill2016}. The current evidence suggests that previous studies and future research involving the dot-probe task do not need to consider whether congruency effects are influenced by carryover effects.

Carryover effects are analogous to the congruency sequence effect commonly observed in the flanker, Simon, and Stroop tasks \\\\parencite{Duthoo2014}. One difference between the dot-probe task and these other tasks is that the distractor stimulus does not directly conflict with the target. For example, in the Stroop task, the font color of the word stimulus can be incongruent with the meaning of the word, which creates conflict when the goal is to indicate the word color. Similarly, in the arrow flanker task, conflict is created on incongruent trials; the two arrows to the left and two to the right point in the direction opposite to the direction of the center target arrow, like this: < < > < <. On congruent trials, all five of the arrows point in the same direction. However, in the dot-probe task, the target does not co-occur with the conflicting cue (they are shown in different displays); they are separated in time, and they are visually distinct categories of stimuli because the cue is a face, and the target is simply a single dot. Therefore, current trial congruency effects in the dot-probe task may stem from relatively low stimulus conflict and therefore be unaffected by previous trial congruency. In sum, carryover effects, or congruency sequence effects, may only arise for specific types of stimulus conflict.

There are some notable procedural differences between the standard dot-probe task (as used here) and other studies that used a similar spatial cueing task but did observe carryover effects. For example, in the unique study design by \\\\parencite{Gladwin2019a, Gladwin2020a}, they presented their cues until the participants made a response, whereas we only presented our cues for 100 ms (Experiment 1) or 500 ms (Experiment 2). Presenting cues until a response is made increases the possibility of attentional dwelling or delayed disengagement from the cue, as opposed to the initial orienting of attention towards the cue \\\\parencite{Fox2001}. Another key difference is that \\\\parencite{Gladwin2019a, Gladwin2020a} presented a distractor (non-target object) in their search display, whereas in the classic dot-probe task, the target appears alone \\\\parencite{Mogg1998}. Inhibition of the cue that appears in the previous non-target location might explain carryover effects for the cue \\\\parencite{Gladwin2020a}. The presence of the non-target distractor might facilitate such inhibition, thereby creating a carryover effect \\\\parencite{Gillich2019, Gladwin2019a}. Future studies on carryover effects should carefully consider their task design procedure. 

\\\\section{Conclusion}

Researchers should carefully select their study design when examining congruency effects. As for studies involving the dot-probe task, however, carryover effects for threat do not appear to be a concern. The highly controlled and simple design of the dot-probe task adequately controls for sources of variance such as carryover effects. While threatening cues may bias attention to a greater extent than neutral cues, their residual influence on attention is limited when assessed with the dot-probe task. 

Data Availability Statement:\\\\emph{ }Datasets are available here: https://osf.io/7qhsj/?view\\\\_only=07b52294c1b647829644a833fc3d4883 




\\\\begin{figure}

  \\\\includegraphics{media/image1.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}

\\\\begin{figure}

  \\\\includegraphics{media/image2.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}

\\\\begin{figure}

  \\\\includegraphics{media/image2.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}

\\\\begin{figure}

  \\\\includegraphics{media/image3.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}

\\\\begin{figure}

  \\\\includegraphics{media/image4.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}


\\\\emph{Figure 1. }(A) Examples of congruent and incongruent trials in Experiment 1. (B) On the left is an example of two congruent trials—note the target (dot) appears in the location of the fearful face on the previous trial (trial \\\\emph{n-}1) and the current trial (trial \\\\emph{n}). A carryover effect occurs when there is a larger congruency effect when the current congruent trial is preceded by a congruent trial, relative to when it is preceded by an incongruent trial. On the right is an example of two sequential trials where the target appears in the same location (repeating target location). 


\\\\begin{figure}

  \\\\includegraphics{media/image5.png}
\\\\caption{}
\\\\label{}


\\\\end{figure}


\\\\emph{Figure 2. }Results from Experiment 1 are shown in A and B, Experiment 2 in C and D (\\\\emph{n} indicates participant, values are averages by participant). A and C show congruent and incongruent RTs (left) and the overall congruency effects (otherwise known as the capturing of attention, or attention bias). The top row of B and D show congruency effects by previous trial congruency and target repetition. The bottom row shows congruency effects by previous trial congruency (incongruent minus congruent), separated by target location repetition. Black error bars represent standard deviation of the mean. Gray distributions represent 95\\\\% confidence intervals \\\\parencite{Ho2019}. 



\\\\section{References}

AUTHO\\\\parencite{R2020}. 

AUTHO\\\\parencite{R2014}. 

Anderson, B. A., \\\\& Britton, M. K. (2019). On the automaticity of attentional orienting to threatening stimuli. \\\\emph{Emotion}. https://doi.org/10.1037/emo0000596

Becker, S. I., Dutt, N., Vromen, J. M. G., \\\\& Horstmann, G. (2017). The capture of attention and gaze in the search for emotional photographic faces. \\\\emph{Visual Cognition}, \\\\emph{25}(1--3), 241--261. https://doi.org/10.1080/13506285.2017.1333182

Cane, J., Sharma, D., \\\\& Albery, I. (2009). The addiction Stroop task: Examining the fast and slow effects of smoking and marijuana-related cues. \\\\emph{Journal of Psychopharmacology}, \\\\emph{23}(5), 510--519. https://doi.org/10.1177/0269881108091253

Carlson, J. M., \\\\& Fang, L. (2020). The stability and reliability of attentional bias measures in the dot-probe task: Evidence from both traditional mean bias scores and trial-level bias scores. \\\\emph{Motivation and Emotion}, 13.

Carlson, J. M., \\\\& Reinke, K. S. (2014). Attending to the fear in your eyes: Facilitated orienting and delayed disengagement. \\\\emph{Cognition and Emotion}, \\\\emph{28}(8), 1398--1406. psyh. https://doi.org/10.1080/02699931.2014.885410

Carretié, L. (2014). Exogenous (automatic) attention to emotional stimuli: A review. \\\\emph{Cognitive, Affective, \\\\& Behavioral Neuroscience}, \\\\emph{14}(4), 1228--1258. https://doi.org/10.3758/s13415-014-0270-2

Clarke, S. P., Sharma, D., \\\\& Salter, D. (2015). Examining fast and slow effects for alcohol and negative emotion in problem and social drinkers. \\\\emph{Addiction Research \\\\& Theory}, \\\\emph{23}(1), 24--33. https://doi.org/10.3109/16066359.2014.922961

Desimone, R., \\\\& Duncan, J. (1995). \\\\emph{Neural Mechanisms of Selective Visual Attention}. 30.

Duthoo, W., Abrahamse, E. L., Braem, S., Boehler, C. N., \\\\& Notebaert, W. (2014). The heterogeneous world of congruency sequence effects: An update. \\\\emph{Frontiers in Psychology}, \\\\emph{5}. https://doi.org/10.3389/fpsyg.2014.01001

Fox, E., Russo, R., Bowles, R., \\\\& Dutton, K. (2001). Do threatening stimuli draw or hold visual attention in subclinical anxiety? \\\\emph{Journal of Experimental Psychology: General}, \\\\emph{130}(4), 681--700. https://doi.org/10.1037/0096-3445.130.4.681

Gladwin, T. E. (2017a). Carryover effects in spatial attentional bias tasks and their relationship to subclinical PTSD symptoms. \\\\emph{Traumatology}, \\\\emph{23}(4), 303. https://doi.org/10.1037/trm0000121

Gladwin, T. E. (2017b). Carryover effects in spatial attentional bias tasks and their relationship to subclinical PTSD symptoms. \\\\emph{Traumatology}, \\\\emph{23}(4), 303--308. psyh. https://doi.org/10.1037/trm0000121

Gladwin, T. E., \\\\& Figner, B. (2019). Trial-to-trial carryover effects on spatial attentional bias. \\\\emph{Acta Psychologica}, \\\\emph{196}, 51--55. https://doi.org/10.1016/j.actpsy.2019.04.006

Gladwin, T. E., Figner, B., \\\\& Vink, M. (2019). Anticipation-specific reliability and trial-to-trial carryover of anticipatory attentional bias for threat. \\\\emph{Journal of Cognitive Psychology}, \\\\emph{31}(7), 750--759. https://doi.org/10.1080/20445911.2019.1659801

Gladwin, T. E., Jewiss, M., \\\\& Vink, M. (2020). Attentional bias for negative expressions depends on previous target location: Replicable effect but unreliable measures. \\\\emph{Journal of Cognitive Psychology}, 1--11. https://doi.org/10.1080/20445911.2020.1805453

Gur, R. C., Sara, R., Hagendoorn, M., Marom, O., Hughett, P., Macy, L., Turner, T., Bajcsy, R., Posner, A., \\\\& Gur, R. E. (2002). A method for obtaining 3-dimensional facial expressions and its standardization for use in neurocognitive studies. \\\\emph{Journal of Neuroscience Methods}, \\\\emph{115}(2), 137--143. https://doi.org/10.1016/S0165-0270(02)00006-7

Hedge, C., Powell, G., \\\\& Sumner, P. (2018). The reliability paradox: Why robust cognitive tasks do not produce reliable individual differences. \\\\emph{Behavior Research Methods}, \\\\emph{50}(3), 1166--1186. https://doi.org/10.3758/s13428-017-0935-1

Hedger, N., Gray, K. L. H., Garner, M., \\\\& Adams, W. J. (2016). Are visual threats prioritized without awareness? A critical review and meta-analysis involving 3 behavioral paradigms and 2696 observers. \\\\emph{Psychological Bulletin}, \\\\emph{142}(9), 934--968. https://doi.org/10.1037/bul0000054

Hill, M., \\\\& Duval, E. (2016). \\\\emph{Exploring Carry-Over Effects to Elucidate Attention Bias Modification's Mixed Results}. Journal of Young Investigators. https://doi.org/10.22186/jyi.31.3.9-14

Ho, J., Tumkaya, T., Aryal, S., Choi, H., \\\\& Claridge-Chang, A. (2019). Moving beyond P values: Data analysis with estimation graphics. \\\\emph{Nature Methods}, \\\\emph{16}(7), 565--566. https://doi.org/10.1038/s41592-019-0470-3

Imhoff, R., Lange, J., \\\\& Germar, M. (2019). Identification and location tasks rely on different mental processes: A diffusion model account of validity effects in spatial cueing paradigms with emotional stimuli. \\\\emph{Cognition and Emotion}, \\\\emph{33}(2), 231--244. https://doi.org/10.1080/02699931.2018.1443433

Kruijt, A.-W., Field, A. P., \\\\& Fox, E. (2016). Capturing Dynamics of Biased Attention: Are New Attention Variability Measures the Way Forward? \\\\emph{PLOS ONE}, \\\\emph{11}(11), e0166600. https://doi.org/10.1371/journal.pone.0166600

Kruijt, A.-W., Parsons, S., \\\\& Fox, E. (2018). A Meta-Analysis of Bias at Baseline in RCTs of Attention Bias Modification: No Evidence for Dot-Probe Bias Towards Threat in Clinical Anxiety and PTSD. \\\\emph{Journal of Abnormal Psychology}, 11.

Lang, P. (2008). International affective picture system (IAPS): Affective ratings of pictures and instruction manual. \\\\emph{Technical Report}. https://ci.nii.ac.jp/naid/20001061266/

Lundqvist, Flykt, A., \\\\& Ohman, A. (1998). \\\\emph{The Karolinska Directed Emotional Faces (KDEF)}. Stockholm : Department of Neurosciences Karolinska Hospital.

MacLeod, C., Mathews, A., \\\\& Tata, P. (1986). Attentional bias in emotional disorders. \\\\emph{Journal of Abnormal Psychology}, \\\\emph{95}(1), 15--20. https://doi.org/10.1037/0021-843X.95.1.15

Mogg, K., \\\\& Bradley, B. P. (1998). A cognitive-motivational analysis of anxiety. \\\\emph{Behaviour Research and Therapy}, \\\\emph{36}(9), 809--848. https://doi.org/10.1016/S0005-7967(98)00063-1

Mogg, K., Waters, A. M., \\\\& Bradley, B. P. (2017). Attention Bias Modification (ABM): Review of Effects of Multisession ABM Training on Anxiety and Threat-Related Attention in High-Anxious Individuals. \\\\emph{Clinical Psychological Science}, \\\\emph{5}(4), 698--717. https://doi.org/10.1177/2167702617696359

Panksepp, J., \\\\& Watt, D. (2011). What is Basic about Basic Emotions? Lasting Lessons from Affective Neuroscience. \\\\emph{Emotion Review}, \\\\emph{3}(4), 387--396. https://doi.org/10.1177/1754073911410741

Posner, M. I., Rafal, R. D., Choate, L. S., \\\\& Vaughan, J. (1985). Inhibition of return: Neural basis and function. \\\\emph{Cognitive Neuropsychology}, \\\\emph{2}(3), 211--228. https://doi.org/10.1080/02643298508252866

Schmukle, S. C. (2005). Unreliability of the dot probe task. \\\\emph{European Journal of Personality}, \\\\emph{19}(7), 595--605. https://doi.org/10.1002/per.554

Schubö, A., Gendolla, G. H. E., Meinecke, C., \\\\& Abele, A. E. (2006). Detecting emotional faces and features in a visual search paradigm: Are faces special? \\\\emph{Emotion}, \\\\emph{6}(2), 246--256. https://doi.org/10.1037/1528-3542.6.2.246

Staugaard, S. R. (2009). Reliability of two versions of the dot-probe task using photographic faces. \\\\emph{Psychological Science Quarterly}, \\\\emph{51}(3), 339--350.

Waters, A. J., Sayette, M. A., Franken, I. H. A., \\\\& Schwartz, J. E. (2005). Generalizability of carry-over effects in the emotional Stroop task. \\\\emph{Behaviour Research and Therapy}, \\\\emph{43}(6), 715--732. https://doi.org/10.1016/j.brat.2004.06.003

Wilson, S. J., Sayette, M. A., Fiez, J. A., \\\\& Brough, E. (2007). Carry-over effects of smoking cue exposure on working memory performance. \\\\emph{Nicotine \\\\& Tobacco Research}, \\\\emph{9}(5), 613--619. https://doi.org/10.1080/14622200701243144

Zvielli, A., Bernstein, A., \\\\& Koster, E. H. W. (2015). Temporal Dynamics of Attentional Bias. \\\\emph{Clinical Psychological Science}, \\\\emph{3}(5), 772--788. https://doi.org/10.1177/2167702614551572





\\\\end{document}
"
`;
